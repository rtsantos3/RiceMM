{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03a656bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T11:08:41.205406Z",
     "start_time": "2023-03-23T11:08:39.074105Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "import cobra\n",
    "import libsbml\n",
    "import pandas as pd\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import memote\n",
    "import csv\n",
    "import pytest\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xlsxwriter\n",
    "import path \n",
    "import datetime\n",
    "import scipy.sparse as sp\n",
    "import warnings\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from functools import partial  \n",
    "from parallelbar import progress_map\n",
    "\n",
    "\n",
    "from cobra import sampling\n",
    "from cobra import Reaction\n",
    "\n",
    "#Change working dir first, ty ChatGPT, much loves\n",
    "cwd = os.getcwd()\n",
    "# Split the path into a list of directories\n",
    "directories = cwd.split(os.sep)\n",
    "# Remove the last two directories from the list\n",
    "directories = directories[:-2]\n",
    "# Join the directories back into a path\n",
    "new_cwd = os.sep.join(directories)\n",
    "# Change the current working directory to the new path\n",
    "os.chdir(new_cwd)\n",
    "\n",
    "sys.path.append(\"./src\")\n",
    "\n",
    "import model_manipulation  as mm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19cbcb9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T11:14:41.725034Z",
     "start_time": "2023-03-23T11:11:53.801Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-05-09\n"
     ]
    }
   ],
   "source": [
    "#This codeblock is to define some of the functions used for modelling\n",
    "\n",
    "\n",
    "#Set solver to gurobi\n",
    "config = cobra.Configuration()\n",
    "config.solver = 'gurobi'\n",
    "\n",
    "#Read 2-cell model\n",
    "wt_model = cobra.io.read_sbml_model(\"./model/ios2164_2cell.xml\")\n",
    "trans_model = cobra.io.read_sbml_model(\"./model/ios2164_2cell.xml\")\n",
    "#Estimate inf\n",
    "inf = 1e6\n",
    "\n",
    "\n",
    "\n",
    "#Define linear relationship between PPFD and Cellular maintainance costs\n",
    "#This formula comes from Topfer et al (2020) where she defined NGAM in a linear relationship with incident light\n",
    "\n",
    "\n",
    "def generate_constraint(model,reaction, name, lb, ub):\n",
    "    reaction_fex = model.reactions.get_by_id(name).flux_expression\n",
    "    constraint = model.problem.Constraint(reaction_fex, lb=lb, ub=ub)\n",
    "    constraint.name = name + '_constraint'\n",
    "    model.add_cons_vars\n",
    "\n",
    "def compute_ngam_atp(ppfd):\n",
    "    v_atp = 0.0049*ppfd + 2.7851\n",
    "    return v_atp\n",
    "\n",
    "\n",
    "#This function is used to set the inputs to the model used. \n",
    "def define_model_medium(model, co2, o2, ppfd, \n",
    "                        medium_dir='./misc/photo_medium.csv', no3=inf, h2o=inf, h=inf, \n",
    "                        nh4=inf, pi=inf):\n",
    "    model_photo_media = mm.read_medium_csv(medium_dir, model)\n",
    "    model_photo_media['EX_no3(e)'] = no3\n",
    "    model_photo_media['EX_h2o(e)'] = h2o\n",
    "    model_photo_media['EX_h(e)'] = h\n",
    "    model_photo_media['EX_nh4(e)'] = nh4\n",
    "    model_photo_media['EX_co2(e)'] = co2\n",
    "    model_photo_media['EX_o2(e)'] = o2\n",
    "    model_photo_media['EX_photonVis(e)'] = ppfd\n",
    "    model_photo_media['EX_pi(e)'] = pi\n",
    "    #Set set model medium as model\n",
    "#     print('Added model medium')\n",
    "    return model_photo_media\n",
    "\n",
    "    \n",
    "def turn_off_cofac_cycles(model, inact_dir='./misc/leaf_inactivated.tsv'):\n",
    "    file = csv.reader(open(inact_dir), delimiter='\\t')\n",
    "    leaf_inactive_rxns = list()\n",
    "    for rows in file:\n",
    "        row_m = str()\n",
    "        row_bs = str()\n",
    "        for rxns in rows:\n",
    "            row_m += str(rxns) + \"_M\"\n",
    "            row_bs += str(rxns) + \"_BS\"\n",
    "        leaf_inactive_rxns.append(row_m)\n",
    "        leaf_inactive_rxns.append(row_bs)\n",
    "        \n",
    "    for rxns in model.reactions:\n",
    "        if rxns.id in leaf_inactive_rxns:\n",
    "            rxns.bounds = (0,0)\n",
    "#     print('Successfully turned off cofactor-cycling reactions')\n",
    "\n",
    "    \n",
    "# #Add constraints to model\n",
    "#This code block contains constraints that would simulate the assimilation rates of bs and m cells in a two-cell system (such as those seen near the midvein region of rice leaves)\n",
    "# #BS photon flux must be the same/less than M flux (Adapted from B&B, 2019)\n",
    "# photon_import = model.reactions.get_by_id(\"EX_photonVis(e)\")\n",
    "def add_tissue_constraints(model):\n",
    "    #For input fluxes for light, we will set the flux ratio to 10:1 to reflect the anatomical proportions of our model ()\n",
    "    \n",
    "    BS_photon_import = model.reactions.PRISM_white_LED_BS\n",
    "    M_photon_import = model.reactions.PRISM_white_LED_M\n",
    "\n",
    "    #Set photon flux ratio to 10:1\n",
    "    photon_flux = mm.set_fix_flux_ratio({M_photon_import.id:10, BS_photon_import.id:1},model)\n",
    "    model.add_cons_vars(photon_flux)\n",
    "\n",
    "    \n",
    "    #UPDATE: Change CO2 intake to the M Cell instead rather than set a ratio, which is a better assumption overall. Assume na lang that external gasses are assimilated\n",
    "    #Via the M cell.\n",
    "    #From Morrison et al 2005 -- Lateral diffusion of Gases is unlikely to support photosynthesis due to the\n",
    "    #assimilation of diffused CO2 in tissues prior to BS//\n",
    "    model.reactions.CO2tex_BS.bounds = (0,0)\n",
    "    model.reactions.O2tex_BS.bounds = (0,0)\n",
    "    \n",
    "    #UPDATE: This assumption does not hold considering that recent transcriptomic analysis confirms that \n",
    "    #the bundle sheath is involved in the assimilation of inorganic nutrients, including nitrogen (nitrates/ammonia), and \n",
    "    #Sulfates. In turn, this will be implemented by simply setting the exchanges to the M cell to 0. (Hua et al, 2021)\n",
    "    model.reactions.SO3tex_M.bounds = (0,0)\n",
    "    model.reactions.SO4tex_M.bounds = (0,0)\n",
    "    model.reactions.NH4tex_M.bounds = (0,0)\n",
    "    model.reactions.NO3tex_M.bounds = (0,0)\n",
    "    \n",
    "    #Model will also constraint H2O input to BS cell only as it is also assumed that BS tissue in rice is specialized for H2O transport (Hua et al. 2021)\n",
    "    #There is a demand reaction naman for H2O for the M cell which is not connected to the BS H2Otex\n",
    "    #Restrict H2O transport to be unidirectional from the BS cell\n",
    "    model.reactions.H2Otex_M.bounds = (0, 0)\n",
    "    model.reactions.h2o_pd.bounds = (-inf, 0)\n",
    "    \n",
    "    #need to turn off HCO import as the model incorrectly transfers fixed HCO to the BS cell via the common pool compartment\n",
    "    model.reactions.HCO3tex_M.bounds = (0,0)\n",
    "    model.reactions.HCO3tex_BS.bounds = (0,0)\n",
    "    \n",
    "    #No constraints will be implemented for H+ availability allowing the model to use protons on-demand.\n",
    "    \n",
    "    #Turn off other Demand reactions that may serve as sinks for the model except DM_Phloem_BS (Which represents the output of photoassimilate thru the BS cell\n",
    "    model.reactions.DM_Phloem_M.bounds = (0,0)\n",
    "    model.reactions.Straw_Biomass_M.bounds = (0,0)\n",
    "    model.reactions.Straw_Biomass_BS.bounds = (0,0)\n",
    "    model.reactions.Coleoptile_Biomass_M.bounds = (0,0)\n",
    "    model.reactions.Coleoptile_Biomass_BS.bounds = (0,0)\n",
    "    model.reactions.DM_Phloem_BS.bounds = (0, inf)\n",
    "    \n",
    "\n",
    "def add_enzyme_constraints(model, \n",
    "                           wt_pepc = 0, \n",
    "                           wt_mdh = 11.18, \n",
    "                           wt_nadp_me = 0.14, \n",
    "                           wt_ppdk=0.31,\n",
    "                          wt_CA=7.5):\n",
    "    \n",
    "    \n",
    "    # #This code block contains constraints specific for enzyme rate constraints\n",
    "    #This approach is derived from Bogart & Myers (2016) where they constrained the enzyme rate \n",
    "    #fluxes in each of the 2-cell segments to a specific upper bound while keeping the lower bound\n",
    "    #At 0. For reversible reactions the lower bounds are set to the same value\n",
    "    \n",
    "    \n",
    "    #PEPC constraint (Reaction id: PPCc)\n",
    "    #Need to constrain it to 0 since reaction is only detected in Vascular tissue\n",
    "    pepc_BS = model.reactions.PPCc_BS\n",
    "    pepc_M = model.reactions.PPCc_M\n",
    "    \n",
    "    pepc_BS.bounds = (0,0)\n",
    "    pepc_M.bounds = (0,0)\n",
    "\n",
    "    #PPDK constraints (Reaction id: PPDKs) (note that this is found in the chloroplast?) \n",
    "    #Not detected via immunolocalization but enzyme activity is detected\n",
    "\n",
    "    ppdks_BS = model.reactions.PPDKs_BS\n",
    "    ppdks_M = model.reactions.PPDKs_M\n",
    "    ppdkc_BS = model.reactions.PPDKc_BS\n",
    "    ppdkc_M = model.reactions.PPDKc_M\n",
    "    wt_ppdks_cons = model.problem.Constraint(ppdks_BS.flux_expression \n",
    "                                             + ppdks_M.flux_expression\n",
    "                                             + ppdkc_BS.flux_expression\n",
    "                                             + ppdkc_M.flux_expression, \n",
    "                                             lb = 0, ub = wt_ppdk)\n",
    "    wt_ppdks_cons.name = 'wt_ppdks_cons'\n",
    "    model.add_cons_vars(wt_ppdks_cons)\n",
    "    #Malate Dehydrogenase \n",
    "    #Only mitochondrial in WT Rice M cells\n",
    "    mdhm_M = model.reactions.MDHm_M\n",
    "\n",
    "\n",
    "    wt_mdh_cons = model.problem.Constraint(mdhm_M.flux_expression,\n",
    "                                           lb= 0, ub=wt_mdh)\n",
    "    wt_mdh_cons.name = \"wt_mdh_cons\"\n",
    "    model.add_cons_vars(wt_mdh_cons)\n",
    "\n",
    "    #NADP-ME (Since no signal is detected in WT, no locational constraints are imposed)\n",
    "    #Let's see if I can force it to have a small amount of flux \n",
    "    nadp_me_M = model.reactions.MDHys_M\n",
    "    nadp_me_BS = model.reactions.MDHys_BS\n",
    "\n",
    "    wt_nadpme_cons = model.problem.Constraint(nadp_me_M.flux_expression\n",
    "                                             + nadp_me_BS.flux_expression,\n",
    "                                             lb= 0, ub=wt_nadp_me)\n",
    "    wt_nadpme_cons.name = \"wt_nadpme_cons\"\n",
    "    model.add_cons_vars(wt_nadpme_cons)\n",
    "\n",
    "\n",
    "    #I should add constraints for Carbonic Anhydrase\n",
    "    #I should constrain it to 0.4 ubar, which would constitute ambient CO2 partial pressure\n",
    "    #Flux is reversible so constraints are bi-directional\n",
    "    #This should be revised considering that it allows reversible reactions  and an abnormally high flux thru carbonic anhydrase, which shouldn't be the case\n",
    "\n",
    "    hco3es_m = model.reactions.HCO3Es_M.flux_expression\n",
    "    hco3ec_m = model.reactions.HCO3Ec_M.flux_expression\n",
    "    hco3em_m = model.reactions.HCO3Em_M.flux_expression\n",
    "    hco3es_bs = model.reactions.HCO3Es_BS.flux_expression\n",
    "    hco3ec_bs = model.reactions.HCO3Ec_BS.flux_expression\n",
    "    hco3em_bs = model.reactions.HCO3Em_BS.flux_expression\n",
    "\n",
    "    ca_cons = model.problem.Constraint(hco3es_m + hco3ec_m + hco3em_m \n",
    "                                       + hco3es_bs + hco3ec_bs + hco3em_bs,\n",
    "                                      lb = -wt_CA, ub = wt_CA)\n",
    "    ca_cons.name = 'Carbonic_anhydrase_constraint'\n",
    "    model.add_cons_vars(ca_cons)\n",
    "\n",
    "\n",
    "    #Rbcl constaints\n",
    "    #Retrieve flux expressions oof each RBCl reaction\n",
    "    rbpc_M = model.reactions.RBPCs_M.flux_expression\n",
    "    rbpc_BS = model.reactions.RBPCs_BS.flux_expression\n",
    "    rbpo_M = model.reactions.RBPOs_M.flux_expression\n",
    "    rbpo_BS = model.reactions.RBPOs_BS.flux_expression\n",
    "\n",
    "    #Constraint such that it is limited to 132 umol m-2 s-1\n",
    "    rbcl_vcmax_cons = model.problem.Constraint(rbpc_M + rbpc_BS, lb = 0, ub= 132)\n",
    "    rbcl_vcmax_cons.name='rbcl_vcmax_cons'\n",
    "    model.add_cons_vars(rbcl_vcmax_cons)\n",
    "    #Constraints for rbcl flux such that v_c/v_o = 3 or higher.\n",
    "    rbcl_vcvo = model.problem.Constraint(3*(rbpo_M + rbpo_BS) \n",
    "                                         - 1*(rbpc_M + rbpc_BS),\n",
    "                                         lb=0,ub=1000)\n",
    "    rbcl_vcvo.name = 'rbcl_vc/vo_ratio'\n",
    "    model.add_cons_vars(rbcl_vcvo)\n",
    "\n",
    "    #Turn off the RBPC2s reactions since we already defined the constraints above\n",
    "    model.reactions.RBPC2s_M.bounds = (0,0)\n",
    "    model.reactions.RBPC2s_BS.bounds = (0,0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #What if I simply constrained that of the M cell one to 3:1?\n",
    "    #This constraint is pretty good actually. \n",
    "    #This allows the system to be set at a specific Vc/Vo rate while still allowing local variation \n",
    "    #wherein Rubisco may act in an uncoupled fashion and may have favorable internal vc/vo rates.\n",
    "# #This code block is to set a constraint such that M-to-BS cell NGAM ratio is 10-to-1 \n",
    "# #Similar to what Moreno-Villena et al (2022) had done \n",
    "\n",
    "#This function takes two arguments: the model and the maximal  ppfd input to the system\n",
    "def add_ngam_cons(model, ppfd): \n",
    "    ngam_atp_m = mm.get_rxn(model, 'ngam_atp_c_M')\n",
    "    ngam_atp_bs = mm.get_rxn(model, 'ngam_atp_c_BS')\n",
    "    ngam_atp_m.bounds = (0,inf)\n",
    "    ngam_atp_bs.bounds = (0,inf)\n",
    "    ngam_ratio = mm.set_fix_flux_ratio({ngam_atp_m.id:10, ngam_atp_bs.id:1}, model)\n",
    "    ngam_ratio.name = 'ngam_BS/M_ratio'\n",
    "    model.add_cons_vars(ngam_ratio)\n",
    "\n",
    "    #Retrieve NGAM reactions\n",
    "    ngam_nadphox_c_M = mm.get_rxn(model, 'ngam_nadphox_c_M')\n",
    "    ngam_nadphox_s_M = mm.get_rxn(model, 'ngam_nadphox_s_M')\n",
    "    ngam_nadphox_m_M = mm.get_rxn(model, 'ngam_nadphox_m_M')\n",
    "    ngam_nadphox_c_BS = mm.get_rxn(model, 'ngam_nadphox_c_BS')\n",
    "    ngam_nadphox_s_BS = mm.get_rxn(model, 'ngam_nadphox_s_BS')\n",
    "    ngam_nadphox_m_BS = mm.get_rxn(model, 'ngam_nadphox_m_BS')\n",
    "\n",
    "\n",
    "    #Set Fixed fluxes\n",
    "    nadphox_c_s_M = mm.set_fix_flux_ratio({ngam_nadphox_c_M.id:1, ngam_nadphox_s_M.id:1},model)\n",
    "    nadphox_c_s_M.name = \"nadphox_cs_ratio_M\"\n",
    "    nadphox_s_m_M = mm.set_fix_flux_ratio({ngam_nadphox_s_M.id:1, ngam_nadphox_m_M.id:1}, model)\n",
    "    nadphox_s_m_M.name = \"nadphox_sm_ratio_M\"\n",
    "\n",
    "    nadphox_c_s_BS = mm.set_fix_flux_ratio({ngam_nadphox_c_BS.id:1, ngam_nadphox_s_BS.id:1},model)\n",
    "    nadphox_c_s_BS.name = \"nadphox_cs_ratio_BS\"\n",
    "    nadphox_s_m_BS = mm.set_fix_flux_ratio({ngam_nadphox_s_BS.id:1, ngam_nadphox_m_BS.id:1}, model)\n",
    "    nadphox_s_m_BS.name = \"nadphox_sm_ratio_BS\"\n",
    "\n",
    "    #Add constraints\n",
    "    model.add_cons_vars(nadphox_c_s_M)\n",
    "    model.add_cons_vars(nadphox_s_m_M)\n",
    "    model.add_cons_vars(nadphox_c_s_BS)\n",
    "    model.add_cons_vars(nadphox_s_m_BS)\n",
    "\n",
    "    #Retrieve flux expressionns\n",
    "    fex_nadphox_c_M =  mm.get_flux_exp(model, ngam_nadphox_c_M)\n",
    "    fex_nadphox_s_M = mm.get_flux_exp(model, ngam_nadphox_s_M)\n",
    "    fex_nadphox_m_M = mm.get_flux_exp(model, ngam_nadphox_m_M)\n",
    "\n",
    "    fex_nadphox_c_BS =  mm.get_flux_exp(model, ngam_nadphox_c_BS)\n",
    "    fex_nadphox_s_BS =  mm.get_flux_exp(model, ngam_nadphox_s_BS)\n",
    "    fex_nadphox_m_BS =  mm.get_flux_exp(model, ngam_nadphox_m_BS)\n",
    "\n",
    "    fex_atp_c_M = mm.get_flux_exp(model, ngam_atp_m)\n",
    "    fex_atp_c_BS =  mm.get_flux_exp(model, ngam_atp_bs)\n",
    "\n",
    "    #Set the constraint between ATP:NADPH NGAM to 3:1\n",
    "    nadphox_atpase = model.problem.Constraint(3*(fex_nadphox_c_M + fex_nadphox_s_M + fex_nadphox_m_M\n",
    "                                                       + fex_nadphox_c_BS + fex_nadphox_s_BS + fex_nadphox_m_BS) \n",
    "                                         - 1*(fex_atp_c_M + fex_atp_c_BS),\n",
    "                                         lb=0,ub=0)\n",
    "    nadphox_atpase.name = \"nadphox_atpase_ratio\"\n",
    "    model.add_cons_vars(nadphox_atpase)\n",
    "    #Compute NGAM value and add constraint as a lower bound/upper bound to model\n",
    "    ngam_value = compute_ngam_atp(ppfd)\n",
    "    ngam_cons = model.problem.Constraint(fex_atp_c_M + \n",
    "                                        fex_atp_c_BS, lb=ngam_value, ub=ngam_value)\n",
    "    ngam_cons.name = 'NGAM_ATP_constraint'\n",
    "    model.add_cons_vars(ngam_cons)\n",
    "    \n",
    "#This code  block gives a snapshot of the relevant fluxes on each of the cell types based on the saved sample_fluxes values above\n",
    "\n",
    "def print_summary(model, sample_fluxes_df):\n",
    "    print('rbcl M cell: ', sample_fluxes['RBPCs_M'], 'rbcl BS cell: ',sample_fluxes['RBPCs_BS'])\n",
    "    print('rbcl M cell (photorespiration)', sample_fluxes['RBPOs_M'], 'rbcl BS cell (PR)', sample_fluxes['RBPOs_BS'])\n",
    "    print('vc/vo M:', sample_fluxes['RBPCs_M']/sample_fluxes['RBPOs_M'], 'vc/vo BS:', sample_fluxes['RBPCs_BS']/sample_fluxes['RBPOs_BS'])\n",
    "    print('RBPC2s_M', sample_fluxes['RBPC2s_M'], 'RBPC2s_BS', sample_fluxes['RBPC2s_BS'])\n",
    "    print('PEPC M', sample_fluxes['PPCc_M'], 'PEPC BS', sample_fluxes['PPCc_BS'])\n",
    "    print('Carbonic Anhydrase (Cytosolic) M', sample_fluxes['HCO3Ec_M'], 'Carbonic Anhydrase (Cytosolic) BS', sample_fluxes['HCO3Ec_BS'])\n",
    "    print('NADP-ME M', sample_fluxes['MDHys_M'], 'NADP-ME BS', sample_fluxes['MDHys_BS'])\n",
    "    print('Biomass M: ', sample_fluxes['Straw_Biomass_M'], 'Biomass BS', sample_fluxes['Straw_Biomass_BS'])\n",
    "    print('Phloem M: ', sample_fluxes['DM_Phloem_M'], 'Phloem BS', sample_fluxes['DM_Phloem_BS'])\n",
    "    print('co2 consumption M', sample_fluxes['CO2tex_M'], 'co2 consumption BS', sample_fluxes['CO2tex_BS'])\n",
    "    print('o2 consumption M', sample_fluxes['O2tex_M'], 'o2 consumption BS', sample_fluxes['O2tex_BS'])\n",
    "    print('Photosystem II M', sample_fluxes['PSIINC_M'], 'PSII BS', sample_fluxes['PSIINC_BS'])\n",
    "    print('PSI M', sample_fluxes['PSIMR_M'], 'PSI BS', sample_fluxes['PSIMR_BS'])\n",
    "    print('PPFD M: ', sample_fluxes['PRISM_white_LED_M'], 'PPFD BS: ', sample_fluxes['PRISM_white_LED_BS'])\n",
    "    print('ATP synthesis (stromal) M', sample_fluxes['ATPSs_M'], 'ATP synthase (mit) M', sample_fluxes['ATPSm_M'])\n",
    "    pd_rxn = [x for x in model.reactions if \"pd\" in x.id and \"h2o\" not in x.id]\n",
    "    pd_abs_flux = 0\n",
    "    for pds in pd_rxn:\n",
    "        pd_abs_flux += abs(sample_fluxes[pds.id])\n",
    "    \n",
    "    print('pd_abs_flux: ', pd_abs_flux)\n",
    "    \n",
    "#initialize list of transgenic reactions to add  to model\n",
    "\n",
    "def add_trans_reactions(model):\n",
    "    '''\n",
    "    This function is used to add a number of new tissue-specific reactions that were not present in the\n",
    "    original model to facilitate modelling of the transgenic C4 rice\n",
    "    '''\n",
    "    trans_list = list()\n",
    "    #Transgenic PEPC copy\n",
    "    #PEPC = Chloroplastic in M & V (rxn id: PPCc)\n",
    "    trans_ppcs = Reaction('trans_PPCs_M')\n",
    "    trans_ppcs.name = \"Phosphoenolpyruvate carboxylase, plastidic (Transgenic)\"\n",
    "    \n",
    "    pep_s0 = model.metabolites.pep_s0\n",
    "    hco3_s0 = model.metabolites.hco3_s0\n",
    "    oaa_s0 = model.metabolites.oaa_s0\n",
    "    pi_s0 = model.metabolites.pi_s0\n",
    "\n",
    "\n",
    "    #Add metabolites, bounds, and subsystem\n",
    "    trans_ppcs.add_metabolites({hco3_s0:-1, pep_s0:-1, oaa_s0:1, pi_s0:1})\n",
    "    trans_ppcs.bounds= model.reactions.PPCc_M.bounds\n",
    "    trans_ppcs.subsystem = model.reactions.PPCc_M.subsystem\n",
    "\n",
    "    trans_list.append(trans_ppcs)\n",
    "\n",
    "\n",
    "    #Transgenic PPDK Copy\n",
    "    #Since it already exists I'll just copy and readd it\n",
    "    trans_ppdks_m = Reaction('trans_PPDKs_M')\n",
    "    trans_ppdks_m.add_metabolites(model.reactions.PPDKs_M.metabolites)\n",
    "    trans_ppdks_m.bounds = model.reactions.PPDKs_M.bounds\n",
    "    trans_ppdks_m.name = \"Pyruvate phosphate dikinase, plastidic (Transgenic)\"\n",
    "\n",
    "    trans_ppdks_bs = Reaction('trans_PPDKs_BS')\n",
    "    trans_ppdks_bs.add_metabolites(model.reactions.PPDKs_BS.metabolites)\n",
    "    trans_ppdks_bs.bounds = model.reactions.PPDKs_BS.bounds\n",
    "    trans_ppdks_bs.name = \"Pyruvate phosphate dikinase, plastidic (Transgenic)\"\n",
    "\n",
    "    trans_list.append(trans_ppdks_m)\n",
    "    trans_list.append(trans_ppdks_bs)\n",
    "\n",
    "\n",
    "    #Transgenic NADP-ME\n",
    "    #NADP-ME = Mitochondrial in M\n",
    "    trans_nadp_me = Reaction('trans_MDHym_M')\n",
    "\n",
    "    #retrieve reactants\n",
    "    mal_m0 = model.metabolites.get_by_id('mal-L_m0')\n",
    "    nadp_m0 = model.metabolites.nadp_m0\n",
    "    h_m0 = model.metabolites.h_m0\n",
    "    nadph_m0 = model.metabolites.nadph_m0\n",
    "    oaa_m0 = model.metabolites.oaa_m0\n",
    "\n",
    "    #Add to rxn\n",
    "    trans_nadp_me.add_metabolites({mal_m0:-1, nadp_m0:-1, h_m0:1, nadph_m0:1, oaa_m0:1})\n",
    "    #Add bounds\n",
    "    trans_nadp_me.bounds=(-inf, inf)\n",
    "\n",
    "    trans_list.append(trans_nadp_me)\n",
    "\n",
    "\n",
    "    #Malate Dehydrogenase, mitochondrial (M cell)\n",
    "    trans_MDHm_M = Reaction('trans_MDHm_M')\n",
    "    trans_MDHm_M.name = 'Malate Dehydrogenase, Mitochondrial'\n",
    "    trans_MDHm_M.add_metabolites(model.reactions.MDHm_M.metabolites)\n",
    "    trans_MDHm_M.subsystem = model.reactions.MDHm_M.subsystem\n",
    "\n",
    "    trans_list.append(trans_MDHm_M)\n",
    "\n",
    "    #Malate dehydrogenase, plastidic (M cell)\n",
    "    trans_MDHs_M = Reaction('trans_MDHs_M')\n",
    "    trans_MDHs_M.name = 'Malate Dehydrogenase, Plastidic'\n",
    "    trans_MDHs_M.add_metabolites(model.reactions.MDHs_M.metabolites)\n",
    "    trans_MDHs_M.subsystem = model.reactions.MDHs_M.subsystem\n",
    "\n",
    "    trans_list.append(trans_MDHs_M)\n",
    "\n",
    "    #Malate dehydrogenase, plastidic(BS Cell)\n",
    "    trans_MDHs_BS = Reaction('trans_MDHs_BS')\n",
    "    trans_MDHs_BS.name = 'Malate Dehydrogenase, Plastidic'\n",
    "    trans_MDHs_BS.add_metabolites(model.reactions.MDHs_BS.metabolites)\n",
    "    trans_MDHs_BS.subsystem = model.reactions.MDHs_BS.subsystem\n",
    "\n",
    "    trans_list.append(trans_MDHs_BS)\n",
    "\n",
    "\n",
    "    #Trans CA\n",
    "    #Cytosolic in M\n",
    "    trans_hco3ec_M = Reaction('trans_hco3ec_M')\n",
    "    trans_hco3ec_M.name = 'carbonic anhydrase, cytosolic'\n",
    "    trans_hco3ec_M.add_metabolites(model.reactions.HCO3Ec_M.metabolites)\n",
    "    trans_hco3ec_M.bounds = model.reactions.HCO3Ec_M.bounds\n",
    "\n",
    "    trans_hco3ec_M.subsystem = model.reactions.HCO3Ec_M.subsystem\n",
    "    trans_list.append(trans_hco3ec_M)\n",
    "\n",
    "\n",
    "    #Bulk add to model\n",
    "    model.add_reactions(trans_list)\n",
    "    \n",
    "    model.repair()\n",
    "####ADDING TRANS CONSTRAINTS\n",
    "\n",
    "def add_trans_constraints(model,\n",
    "                         trans_pepc_rates = 7.01,\n",
    "                         trans_ppdks_rates = 3.66,\n",
    "                         trans_mdh_rates = 152.87,\n",
    "                         trans_nadp_me_rates = 0.60,\n",
    "                         trans_CA_rates = 8):\n",
    "    '''\n",
    "    This function is used to add another layer of constraints to parametize model based on the\n",
    "    Enzyme reaction rates assayed from Ermakova et al (2021) where the locations are based on the \n",
    "    each of the transgenic enzyme's tissue-specific localizations. \n",
    "    '''\n",
    "    \n",
    "    #PEPC constraint\n",
    "    wt_PPCc_M = mm.get_rxn(model, 'PPCc_M')\n",
    "    wt_PPCc_BS = mm.get_rxn(model, 'PPCc_BS')\n",
    "    trans_PPCs_M = mm.get_rxn(model, 'trans_PPCs_M')                           \n",
    "    trans_PEPC_cons = model.problem.Constraint(trans_PPCs_M.flux_expression\n",
    "                                            +wt_PPCc_BS.flux_expression \n",
    "                                            + wt_PPCc_M.flux_expression, \n",
    "                                            lb = 0, ub = trans_pepc_rates)\n",
    "\n",
    "    model.add_cons_vars(trans_PEPC_cons)\n",
    "\n",
    "    #PPDK constraint\n",
    "    trans_PPDKs_M  = mm.get_rxn(model, 'trans_PPDKs_M')\n",
    "    trans_PPDKs_BS = mm.get_rxn(model, 'trans_PPDKs_BS')\n",
    "    wt_PPDKs_M = mm.get_rxn(model, 'PPDKs_M')\n",
    "    wt_PPDKs_BS = mm.get_rxn(model, 'PPDKs_BS')\n",
    "    \n",
    "    trans_PPDKs_cons = model.problem.Constraint( \n",
    "        trans_PPDKs_BS.flux_expression + trans_PPDKs_M.flux_expression \n",
    "        +wt_PPDKs_BS.flux_expression + wt_PPDKs_M.flux_expression, \n",
    "                                             lb = 0, ub = trans_ppdks_rates)\n",
    "    trans_PPDKs_cons.name = 'trans_ppdks_cons'\n",
    "    model.add_cons_vars(trans_PPDKs_cons)\n",
    "\n",
    "\n",
    "    #Malate Dehydrogenase Constraints\n",
    "    trans_MDHm_M = mm.get_rxn(model, 'trans_MDHm_M')\n",
    "    trans_MDHs_M = mm.get_rxn(model, 'trans_MDHs_M')\n",
    "    trans_MDHs_BS = mm.get_rxn(model, 'trans_MDHs_BS')\n",
    "    wt_MDHm_M =  mm.get_rxn(model, 'MDHm_M')\n",
    "    wt_MDHs_M = mm.get_rxn(model, 'MDHs_M')\n",
    "    wt_MDHs_BS = mm.get_rxn(model, 'MDHs_BS')\n",
    "    \n",
    "    trans_mdh_cons =  model.problem.Constraint(\n",
    "       trans_MDHm_M.flux_expression + \n",
    "        wt_MDHm_M.flux_expression + \n",
    "        trans_MDHs_M.flux_expression + \n",
    "        trans_MDHs_BS.flux_expression +\n",
    "        wt_MDHs_BS.flux_expression +\n",
    "        wt_MDHs_M.flux_expression, \n",
    "        lb= 0, ub=trans_mdh_rates)\n",
    "\n",
    "    trans_mdh_cons.name = \"trans_mdh_cons\"\n",
    "    model.add_cons_vars(trans_mdh_cons)\n",
    "\n",
    "    #Add NADP-ME constraints\n",
    "    trans_MDHym_M = mm.get_rxn(model, 'trans_MDHym_M')\n",
    "    wt_MDHys_M = mm.get_rxn(model, 'MDHys_M')\n",
    "    wt_MDHys_BS = mm.get_rxn(model, 'MDHys_BS')\n",
    "    \n",
    "    trans_nadpme_cons = model.problem.Constraint(\n",
    "        trans_MDHym_M.flux_expression + \n",
    "        wt_MDHys_M.flux_expression + \n",
    "        wt_MDHys_BS.flux_expression,\n",
    "        lb= 0, ub=trans_nadp_me_rates)\n",
    "    \n",
    "    trans_nadpme_cons.name = \"trans_nadpme\"\n",
    "    model.add_cons_vars(trans_nadpme_cons)\n",
    "\n",
    "    #Add carbonic anhydrase constraints\n",
    "\n",
    "    trans_hco3ec_M = mm.get_rxn(model, 'trans_hco3ec_M')\n",
    "    wt_hco3ec_M = mm.get_rxn(model, 'HCO3Ec_M')\n",
    "    wt_hco3em_M = mm.get_rxn(model, 'HCO3Em_M')\n",
    "    wt_hco3es_M = mm.get_rxn(model, 'HCO3Es_M')\n",
    "    wt_hco3ec_BS = mm.get_rxn(model, 'HCO3Ec_BS')\n",
    "    wt_hco3em_BS = mm.get_rxn(model, 'HCO3Em_BS')\n",
    "    wt_hco3es_BS = mm.get_rxn(model, 'HCO3Es_BS')\n",
    "    \n",
    "    trans_ca_cons = model.problem.Constraint(trans_hco3ec_M.flux_expression + \n",
    "                                             wt_hco3es_M.flux_expression + \n",
    "                                             wt_hco3ec_M.flux_expression + \n",
    "                                             wt_hco3em_M.flux_expression + \n",
    "                                             wt_hco3es_BS.flux_expression + \n",
    "                                             wt_hco3ec_BS.flux_expression + \n",
    "                                             wt_hco3em_BS.flux_expression,\n",
    "                                      lb = -trans_CA_rates, ub = trans_CA_rates)\n",
    "    trans_ca_cons.name = 'Trans_CA_cons'\n",
    "    model.add_cons_vars(trans_ca_cons)\n",
    "    model.repair()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d08460-95dc-4dea-ae6e-a7c85ca4122e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_flux_samples(model, num_samples, batch_size, output_filename,thinning,processes=7, nproj=0,output_dir='./flux_results/flux_sampling/'):\n",
    "    #This function is used to initialize a flux sampler and afterwards generate a csv file containing the sample solutions.\n",
    "    #default batch size is 1000\n",
    "\n",
    "    #Generate sampler\n",
    "    print(\"generating sampler for model\")\n",
    "    sampler = sampling.OptGPSampler(model, processes=processes, thinning=thinning, nproj=nproj)\n",
    "    print(\"done generating OPTGP sampler\")\n",
    "    \n",
    "    \n",
    "    #Define output file\n",
    "    output_dir = str(output_dir)\n",
    "    output_filename = str(output_filename)\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    print('saving output to ', f\"{output_dir}/{output_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(num_samples // batch_size):\n",
    "        print(f\"Generating batch {i+1}/{num_samples//batch_size}\")\n",
    "        samples = sampler.sample(n=batch_size)\n",
    "        df = pd.DataFrame(samples, columns=model.reactions.list_attr(\"id\"))\n",
    "        if i == 0:\n",
    "            df.to_csv(f\"{output_dir}/{output_filename}\", index=False)\n",
    "        else:\n",
    "            df.to_csv(f\"{output_dir}/{output_filename}\", index=False, header=False, mode=\"a\")\n",
    "        \n",
    "    \n",
    "\n",
    "def parametrize_model(model, ppfd_low, ppfd_high, co2,if_trans, loopless=False, frac_optimum=1, pruning=False, fva_bounds_file='', intermediate_fva_results=''):\n",
    "    \n",
    "    print('start time for parametrize_model(): ' ,datetime.datetime.now())\n",
    "\n",
    "    #Generates a parametrized model which returns the constrained model as a callable object.\n",
    "    \n",
    "    #Copy model \n",
    "    model_instance = model.copy()\n",
    "                                                                                                                                                                                                                                \n",
    "    model_instance.medium = define_model_medium(model_instance, co2=co2, o2=inf, ppfd=inf, h=inf, nh4=inf, no3=inf)\n",
    "    # turn_off_cofac_cycles(model_instance)\n",
    "    add_tissue_constraints(model_instance)\n",
    "    add_enzyme_constraints(model_instance)\n",
    "\n",
    "    #Adds NGAM (Computed as an average between the high and low instead of directly constraining it to the model, w/c makes the problem non-linear)\n",
    "    add_ngam_cons(model_instance, (ppfd_high+ppfd_low)/2)\n",
    "    \n",
    "    #Constrain PPFD range to indicated value\n",
    "    model_instance.reactions.get_by_id('EX_photonVis(e)').bounds = (-1*ppfd_high, -1*ppfd_low)\n",
    "    \n",
    "\n",
    "    #Check if trans then add constraints if true\n",
    "    if if_trans==True:\n",
    "        add_trans_reactions(model_instance)\n",
    "        add_trans_constraints(model_instance)\n",
    "    \n",
    "    \n",
    "    #Readd objective coefficient, maybe it'll work?\n",
    "    model_instance.reactions.get_by_id('DM_Phloem_BS').objective_coefficient = 1\n",
    "    \n",
    "    '''Run FVA to preprocess the model to fix reaction reversibilities as well as to ensure that there are no \"extreme\" fluxes in the final sampling\n",
    "     Perform Flux Variability Analysis (FVA)\n",
    "        This step constrains the upper and lower bounds to the detected \"Maximal\" and \"minimal\" fluxes given an objective\n",
    "        The default fraction of optimum will be implemented\n",
    "    Will implement pFBA factor to constrain the model to 110% of the detected lowest flux '''\n",
    "\n",
    "\n",
    "    list_infeasibles = list()\n",
    "    \n",
    "    #flux_variability_analysis produces a Pandas Dataframe that can be taken apart and applied to the model_instance as direct bounds. \n",
    "    \n",
    "    if fva_bounds_file:\n",
    "        print('reading previous FVA bounds')\n",
    "        fva_result = pd.read_csv(fva_bounds_file, index_col=0)\n",
    "        fva_result.columns = ['minimum', 'maximum']\n",
    "        \n",
    "        \n",
    "        #Add also reactions that are not in the FVA_bounds_file to the rerunning FVA\n",
    "        for rxn in model_instance.reactions:\n",
    "            if rxn.id not in fva_result.index:\n",
    "                list_infeasibles.append(rxn.id)\n",
    "\n",
    "            \n",
    "    else:\n",
    "        print('computing Loopless FVA to model')\n",
    "        fva_result = cobra.flux_analysis.flux_variability_analysis(model_instance, loopless=loopless, fraction_of_optimum=frac_optimum, pfba_factor=1.1, processes=7)\n",
    "\n",
    "    \n",
    "    # Set FVA constraints in the model\n",
    "    print('setting FVA constraints to model and checking for feasibility')\n",
    "    \n",
    "    \n",
    "    for reaction_id, bounds in fva_result.iterrows():\n",
    "        reaction = model_instance.reactions.get_by_id(reaction_id)        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #This method instead double checks the model per flux range and checks if it returns an infeasible solution/0 objective. \n",
    "        #First save old bounds \n",
    "        old_bounds = reaction.bounds\n",
    "        \n",
    "        # Check which is higher or lower to avoid Value errors\n",
    "        lower_bound = float(min(bounds['minimum'], bounds['maximum']))\n",
    "        upper_bound = float(max(bounds['minimum'], bounds['maximum']))\n",
    "        \n",
    "        #Check reaction if it is unbounded then append to list_infeasibles for rerunning\n",
    "        if lower_bound==-1e6 or upper_bound==1e6:\n",
    "            print(f'reaction {reaction_id} is unbounded. Adding to rerun list')\n",
    "            list_infeasibles.append(reaction)\n",
    "        \n",
    "        #Fix the upper and lower bounds\n",
    "        reaction.bounds = (lower_bound, upper_bound)\n",
    "        \n",
    "        #Generate solution and status for checking if reaction is \n",
    "        solution = model_instance.slim_optimize()\n",
    "        status= model_instance.optimize().status\n",
    "        \n",
    "        #Revert model to previous flux bounds in case it causes feasibility issues\n",
    "        if status=='infeasible' or solution==0: #If it causes a 0 obj. function then it's considered broke\n",
    "            print(f'{reaction_id} causes infeasible status/0 objective!')\n",
    "            reaction.bounds=old_bounds\n",
    "            list_infeasibles.append(reaction)\n",
    "            continue\n",
    "            \n",
    "        \n",
    "    \n",
    "    print('Checking done. Length of reactions that cause infeasibility issues/unbounded: ', len(list_infeasibles))\n",
    "            \n",
    "     \n",
    "    #Save intermediate FVA results (For debugging)\n",
    "    if intermediate_fva_results != '':\n",
    "        save_model_bounds(model_instance, f'{intermediate_fva_results}.csv', directory='./flux_results/flux_sampling/model_bounds/for_debugging')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    #Checks if there are any infeasible solutions in the model then reruns the non-loopless version on the NaNs list. This in turn reruns the model to use the non-loopless version of the algorithm instead. It would at least relax the bounds set by the loopless option\n",
    "    #To bounds that are still feasible but still constrained somewhat (rather than setting it to a large value). The rationale behind this is that the first LL-FVA iteration already constrains the model to remove most loops while this iteration would ensure that the model returns a feasible solution\n",
    "    \n",
    "        #Rerun FVA\n",
    "    if len(list_infeasibles) != 0:\n",
    "        print('recomputing list_infeasibles')\n",
    "        fva_non_loopless =  cobra.flux_analysis.flux_variability_analysis(model_instance, reaction_list=list_infeasibles, loopless=True ,fraction_of_optimum=frac_optimum-0.05, pfba_factor=1.1, processes=7)\n",
    "\n",
    "        for reaction_id, bounds in fva_non_loopless.iterrows():\n",
    "            reaction = model_instance.reactions.get_by_id(reaction_id)        \n",
    "            # Check which is higher or lower to avoid Value errors\n",
    "            lower_bound = float(min(bounds['minimum'], bounds['maximum']))\n",
    "            upper_bound = float(max(bounds['minimum'], bounds['maximum']))\n",
    "            print(f'setting bounds for rerun reaction {reaction_id}. Bounds: {lower_bound} | {upper_bound}')\n",
    "            reaction.bounds = (lower_bound, upper_bound)\n",
    "\n",
    "\n",
    "    print('printing model objective:')\n",
    "    print(model_instance.optimize())\n",
    "\n",
    "\n",
    "    if pruning==True:\n",
    "            blocked_reactions = cobra.flux_analysis.find_blocked_reactions(model_instance)\n",
    "            print('reactions number (before pruning): ', len(model_instance.reactions))\n",
    "            # model_instance.remove_reactions(filter_list)\n",
    "            model_instance.remove_reactions(blocked_reactions)\n",
    "            print('reactions number (after pruning): ', len(model_instance.reactions))\n",
    "\n",
    "    # Identify unneeded metabolites\n",
    "    unneeded_metabolites = []\n",
    "    for metabolite in model.metabolites:\n",
    "        if metabolite.reactions == []:\n",
    "            unneeded_metabolites.append(metabolite)\n",
    "\n",
    "    # Remove unneeded metabolites from the model\n",
    "    model.remove_metabolites(unneeded_metabolites)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #This ensures the model is feasible before passing to the solver (Infeasible models cannot generate any solutions)\n",
    "    print('final model objective (Final feasibility check):')\n",
    "    print(model_instance.optimize())\n",
    "    \n",
    "    print('end time for parametrize_model(): ' ,datetime.datetime.now())\n",
    "\n",
    "    \n",
    "    return model_instance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_model_bounds(model, filename, directory='./flux_results/flux_sampling/model_bounds/'):\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Get the bounds of each reaction in the model\n",
    "    bounds = []\n",
    "    for reaction in model.reactions:\n",
    "        bounds.append([reaction.id, reaction.bounds[0], reaction.bounds[1]])\n",
    "\n",
    "    # Create a DataFrame with the bounds\n",
    "    bounds_df = pd.DataFrame(bounds, columns=['Reaction', 'Lower Bound', 'Upper Bound'])\n",
    "\n",
    "    # Write the DataFrame to a CSV file\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    bounds_df.to_csv(filepath, index=False)\n",
    "\n",
    "    print(f\"Model bounds saved to: {filepath}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf1896b-310d-4003-83a7-ef7d537fe7d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# '''June 22, 2023\n",
    "# Let's try running this script with the following parameters in mind. Hopefully it doesn't result with infeasibility issues anymore.\n",
    "\n",
    "# '''\n",
    "\n",
    "# #Let's try running this script with the following parameters in mind. Hopwefully this doesn't result with infeasibility issues anymore\n",
    "# #I suspect that the model is overconstrained due to the frac_optimum \n",
    "# WT_250_test =  parametrize_model(wt_model, 225,275,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True)\n",
    "\n",
    "# #Generate list of models for flux sampling\n",
    "# sampling_list = [WT_250_test]\n",
    "\n",
    "# print('generating flux samples for parametrized models')\n",
    "# for model in sampling_list:\n",
    "#     print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "#     model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "#     name_for_file = str('flux_sample_'+model_name+'_relaxed_Loopless_FVA.csv')\n",
    "    \n",
    "#     #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "#     save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print('Starting OPTGP sampler:')\n",
    "#     generate_flux_samples(model, num_samples =500, batch_size=500, thinning=1, output_filename=name_for_file)\n",
    "#     del model #Deletes model instance to free up memory \n",
    "#     print('end time: ', datetime.datetime.now())\n",
    "    \n",
    "    \n",
    "# '''June 23, 2023\n",
    "# The modifications I've done works marvelously. It even fixes yung consumption ng inorganic nutrients, which was unobservable in the prior attempts. However run times are fairly large so I need to account for that.\n",
    "# Some of my modifications include the following:\n",
    "# setting the fraction optimum to 90% of optimum increasing the solution space for the inputs and outputs\n",
    "# Setting the initial run as loopless then taking into account the reactions with infeasible solutions, and afterwards setting it to non-loopless\n",
    "\n",
    "# Pruning the reaction set to account only for reactions with non-zero flux bounds\n",
    "\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca406088-5276-4af4-b78f-fbb3a3a0432c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating parametrized models for flux sampling\n",
      "start time for parametrize_model():  2023-06-30 09:29:59.187014\n",
      "Read LP format model from file /tmp/tmpc3euk71p.lp\n",
      "Reading time = 0.01 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "reading previous FVA bounds\n",
      "setting FVA constraints to model and checking for feasibility\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#Let's check if it works as a separate instance per WT and TR?\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m wt_model \u001b[38;5;28;01mas\u001b[39;00m wt_model:\n\u001b[0;32m----> 8\u001b[0m     WT_250 \u001b[38;5;241m=\u001b[39m  \u001b[43mparametrize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwt_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m225\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m275\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mco2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m29\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_trans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrac_optimum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.90\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloopless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpruning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfva_bounds_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/WT_250.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#Done\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     WT_750 \u001b[38;5;241m=\u001b[39m parametrize_model(wt_model, \u001b[38;5;241m725\u001b[39m, \u001b[38;5;241m775\u001b[39m,co2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m29\u001b[39m, if_trans\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, frac_optimum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.90\u001b[39m, loopless\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pruning\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fva_bounds_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/WT_750.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m     WT_1500 \u001b[38;5;241m=\u001b[39m parametrize_model(wt_model, \u001b[38;5;241m1475\u001b[39m, \u001b[38;5;241m1525\u001b[39m,co2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m29\u001b[39m, if_trans\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, frac_optimum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.90\u001b[39m, loopless\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pruning\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fva_bounds_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/WT_1500.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 118\u001b[0m, in \u001b[0;36mparametrize_model\u001b[0;34m(model, ppfd_low, ppfd_high, co2, if_trans, loopless, frac_optimum, pruning, fva_bounds_file, intermediate_fva_results)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m#Generate solution and status for checking if reaction is \u001b[39;00m\n\u001b[1;32m    117\u001b[0m solution \u001b[38;5;241m=\u001b[39m model_instance\u001b[38;5;241m.\u001b[39mslim_optimize()\n\u001b[0;32m--> 118\u001b[0m status\u001b[38;5;241m=\u001b[39m \u001b[43mmodel_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m#Revert model to previous flux bounds in case it causes feasibility issues\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfeasible\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m solution\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m#If it causes a 0 obj. function then it's considered broke\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/model.py:1233\u001b[0m, in \u001b[0;36mModel.optimize\u001b[0;34m(self, objective_sense, raise_error)\u001b[0m\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mdirection \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m}\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1230\u001b[0m     objective_sense, original_direction\n\u001b[1;32m   1231\u001b[0m )\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslim_optimize()\n\u001b[0;32m-> 1233\u001b[0m solution \u001b[38;5;241m=\u001b[39m \u001b[43mget_solution\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mdirection \u001b[38;5;241m=\u001b[39m original_direction\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solution\n",
      "File \u001b[0;32m~/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/solution.py:201\u001b[0m, in \u001b[0;36mget_solution\u001b[0;34m(model, reactions, metabolites, raise_error)\u001b[0m\n\u001b[1;32m    195\u001b[0m         met_index\u001b[38;5;241m.\u001b[39mappend(met\u001b[38;5;241m.\u001b[39mid)\n\u001b[1;32m    196\u001b[0m         shadow[i] \u001b[38;5;241m=\u001b[39m constr_duals[met\u001b[38;5;241m.\u001b[39mid]\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Solution(\n\u001b[1;32m    198\u001b[0m     objective_value\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39msolver\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[1;32m    199\u001b[0m     status\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39msolver\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    200\u001b[0m     fluxes\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mSeries(index\u001b[38;5;241m=\u001b[39mrxn_index, data\u001b[38;5;241m=\u001b[39mfluxes, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfluxes\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m--> 201\u001b[0m     reduced_costs\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrxn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreduced_costs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    202\u001b[0m     shadow_prices\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mSeries(index\u001b[38;5;241m=\u001b[39mmet_index, data\u001b[38;5;241m=\u001b[39mshadow, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshadow_prices\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    203\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/RiceMM/lib/python3.10/site-packages/pandas/core/series.py:399\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;66;03m# uncomment the line below when removing the FutureWarning\u001b[39;00m\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;66;03m# dtype = np.dtype(object)\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mensure_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     data \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/RiceMM/lib/python3.10/site-packages/pandas/core/indexes/base.py:7331\u001b[0m, in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   7329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m MultiIndex\u001b[38;5;241m.\u001b[39mfrom_arrays(index_like)\n\u001b[1;32m   7330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 7331\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtupleize_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   7332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   7333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Index\u001b[38;5;241m.\u001b[39m_with_infer(index_like, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/envs/RiceMM/lib/python3.10/site-packages/pandas/core/indexes/base.py:716\u001b[0m, in \u001b[0;36mIndex._with_infer\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    715\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*the Index constructor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 716\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m _dtype_obj \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_is_multi:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"maybe_convert_objects\" has incompatible type\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;66;03m# \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     values \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result\u001b[38;5;241m.\u001b[39m_values)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/RiceMM/lib/python3.10/site-packages/pandas/core/indexes/base.py:565\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m MultiIndex\u001b[38;5;241m.\u001b[39mfrom_tuples(\n\u001b[1;32m    561\u001b[0m             data, names\u001b[38;5;241m=\u001b[39mname \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    562\u001b[0m         )\n\u001b[1;32m    563\u001b[0m \u001b[38;5;66;03m# other iterable of some kind\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray_tuplesafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;66;03m# with e.g. a list [1, 2, 3] casting to numeric is _not_ deprecated\u001b[39;00m\n\u001b[1;32m    568\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m _maybe_cast_data_without_dtype(\n\u001b[1;32m    569\u001b[0m         subarr, cast_numeric_deprecated\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    570\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/RiceMM/lib/python3.10/site-packages/pandas/core/common.py:243\u001b[0m, in \u001b[0;36masarray_tuplesafe\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m [np\u001b[38;5;241m.\u001b[39mobject_, \u001b[38;5;28mobject\u001b[39m]:\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstruct_1d_object_array_from_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;66;03m# Can remove warning filter once NumPy 1.24 is min version\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "\n",
    "#Parametrize models per type by generating model instance\n",
    "\n",
    "print('Generating parametrized models for flux sampling')\n",
    "#Let's check if it works as a separate instance per WT and TR?\n",
    "with wt_model as wt_model:\n",
    "    WT_250 =  parametrize_model(wt_model, 225,275,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/WT_250.csv') #Done\n",
    "    WT_750 = parametrize_model(wt_model, 725, 775,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/WT_750.csv')\n",
    "    WT_1500 = parametrize_model(wt_model, 1475, 1525,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/WT_1500.csv')\n",
    "\n",
    "    TR_250 = parametrize_model(wt_model, 225, 275,co2=22.2, if_trans=True, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/TR_250.csv')\n",
    "    TR_750 = parametrize_model(wt_model, 725, 775,co2=22.2, if_trans=True, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/TR_750.csv')\n",
    "    TR_1500 = parametrize_model(wt_model, 1475, 1525,co2=22.2, if_trans=True, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/TR_1500.csv')\n",
    "\n",
    "# #Generate list of models for flux sampling\n",
    "# sampling_list = [WT_250, WT_750, WT_1500, TR_250, TR_750, TR_1500]\n",
    "\n",
    "# print('generating flux samples for parametrized models')\n",
    "# for model in sampling_list:\n",
    "#     print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "#     model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "#     name_for_file = str('flux_sample_'+model_name+'_Relaxed_loopless_FVA_100kT.csv')\n",
    "#     #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "#     save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "    \n",
    "#     #Parametrize OPTGP sampler\n",
    "#     num_samples =10000\n",
    "#     thinning = 100000\n",
    "    \n",
    "#     print('Starting OPTGP sampler:')\n",
    "#     print('num_samples: ', num_samples)\n",
    "#     print('Thinning coefficient: ', thinning)\n",
    "#     generate_flux_samples(model, num_samples =num_samples, nproj=1, batch_size=5000, thinning=thinning, output_filename=name_for_file)\n",
    "#     del model #Deletes model instance to free up memory \n",
    "#     print('end time: ', datetime.datetime.now())\n",
    "\n",
    "#This outputs a set of bounds that we can reuse to re-parametrize a model instead of re-running the parametrization script again.\n",
    "#June 24, 2023 \n",
    "\n",
    "#For some reason the Trans model returns an infeasible solution. I'll check specifically what the problem is \n",
    "#I checked and some reactions cause numerical issues. I can circumvent that by rerunning the loopless FVA function on the problematic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0cdc65e-133f-46a3-a87a-3bc887d52604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating parametrized models for flux sampling\n",
      "start time for parametrize_model():  2023-06-30 09:30:55.436868\n",
      "Read LP format model from file /tmp/tmp83wjsxwi.lp\n",
      "Reading time = 0.01 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "computing Loopless FVA to model\n",
      "setting FVA constraints to model and checking for feasibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPGFTs_M causes infeasible status/0 objective!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DVCHLOR590s_M causes infeasible status/0 objective!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPSII_430(u)_BS causes infeasible status/0 objective!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPSII_690(u)_BS causes infeasible status/0 objective!\n",
      "ATPAPc_BS causes infeasible status/0 objective!\n",
      "ADPAc_BS causes infeasible status/0 objective!\n",
      "GAL1PUTc_BS causes infeasible status/0 objective!\n",
      "DPCOAKc_BS causes infeasible status/0 objective!\n",
      "URIKGc_BS causes infeasible status/0 objective!\n",
      "URIKGs_BS causes infeasible status/0 objective!\n",
      "DHDHc_BS causes infeasible status/0 objective!\n",
      "BUPNc_BS causes infeasible status/0 objective!\n",
      "DHPDc_BS causes infeasible status/0 objective!\n",
      "TMDSc_BS causes infeasible status/0 objective!\n",
      "CYTDc_BS causes infeasible status/0 objective!\n",
      "GTPCYTDPTc_BS causes infeasible status/0 objective!\n",
      "GTPCYTDPTs_BS causes infeasible status/0 objective!\n",
      "DCTPDAc_BS causes infeasible status/0 objective!\n",
      "CTPRc_BS causes infeasible status/0 objective!\n",
      "UTPRc_BS causes infeasible status/0 objective!\n",
      "ATPRc_BS causes infeasible status/0 objective!\n",
      "GTPRc_BS causes infeasible status/0 objective!\n",
      "DCAHc_BS causes infeasible status/0 objective!\n",
      "UPRTs_BS causes infeasible status/0 objective!\n",
      "ALAATc_BS causes infeasible status/0 objective!\n",
      "ALAATm_BS causes infeasible status/0 objective!\n",
      "ALAATs_BS causes infeasible status/0 objective!\n",
      "AAATc_BS causes infeasible status/0 objective!\n",
      "ARGDs_BS causes infeasible status/0 objective!\n",
      "ARGDc_BS causes infeasible status/0 objective!\n",
      "ARGDm_BS causes infeasible status/0 objective!\n",
      "ASPCLc_BS causes infeasible status/0 objective!\n",
      "ICDHc_BS causes infeasible status/0 objective!\n",
      "MDHv_BS causes infeasible status/0 objective!\n",
      "PPCc_BS causes infeasible status/0 objective!\n",
      "ATPCSc_BS causes infeasible status/0 objective!\n",
      "CSx_BS causes infeasible status/0 objective!\n",
      "CSm_BS causes infeasible status/0 objective!\n",
      "ASPALc_BS causes infeasible status/0 objective!\n",
      "GLYCRORc_BS causes infeasible status/0 objective!\n",
      "HMGCOARyc_BS causes infeasible status/0 objective!\n",
      "MEVKc_BS causes infeasible status/0 objective!\n",
      "PMEVKc_BS causes infeasible status/0 objective!\n",
      "DPMVDc_BS causes infeasible status/0 objective!\n",
      "IPDDIc_BS causes infeasible status/0 objective!\n",
      "IPDDIm_BS causes infeasible status/0 objective!\n",
      "IPDDIs_BS causes infeasible status/0 objective!\n",
      "DXPRIis_BS causes infeasible status/0 objective!\n",
      "IPDPS2s_BS causes infeasible status/0 objective!\n",
      "IPDPS1s_BS causes infeasible status/0 objective!\n",
      "DMPPS2s_BS causes infeasible status/0 objective!\n",
      "DMPPS1s_BS causes infeasible status/0 objective!\n",
      "MECDPDH5s_BS causes infeasible status/0 objective!\n",
      "CDPMEKs_BS causes infeasible status/0 objective!\n",
      "MEPCTs_BS causes infeasible status/0 objective!\n",
      "MECDPSs_BS causes infeasible status/0 objective!\n",
      "DMATTs_BS causes infeasible status/0 objective!\n",
      "DMATTm_BS causes infeasible status/0 objective!\n",
      "GRTTs_BS causes infeasible status/0 objective!\n",
      "GRTTm_BS causes infeasible status/0 objective!\n",
      "FRTTs_BS causes infeasible status/0 objective!\n",
      "DMATTc_BS causes infeasible status/0 objective!\n",
      "GRTTc_BS causes infeasible status/0 objective!\n",
      "GGDRc_BS causes infeasible status/0 objective!\n",
      "LIMSs_BS causes infeasible status/0 objective!\n",
      "PSPPSc_BS causes infeasible status/0 objective!\n",
      "SQLSc_BS causes infeasible status/0 objective!\n",
      "SQLMOc_BS causes infeasible status/0 objective!\n",
      "PRIMARTSc_BS causes infeasible status/0 objective!\n",
      "SCODPSs_BS causes infeasible status/0 objective!\n",
      "PRIMARDSs_BS causes infeasible status/0 objective!\n",
      "MOMASys_BS causes infeasible status/0 objective!\n",
      "MOMASs_BS causes infeasible status/0 objective!\n",
      "STEMSs_BS causes infeasible status/0 objective!\n",
      "STEMOc_BS causes infeasible status/0 objective!\n",
      "P450MO1c_BS causes infeasible status/0 objective!\n",
      "ESANDSs_BS causes infeasible status/0 objective!\n",
      "ESANDO1c_BS causes infeasible status/0 objective!\n",
      "P450MO4c_BS causes infeasible status/0 objective!\n",
      "P450MO5c_BS causes infeasible status/0 objective!\n",
      "P450MO6c_BS causes infeasible status/0 objective!\n",
      "OZLNDO1c_BS causes infeasible status/0 objective!\n",
      "OZLNDO2c_BS causes infeasible status/0 objective!\n",
      "OZLNAOc_BS causes infeasible status/0 objective!\n",
      "OZLNBOc_BS causes infeasible status/0 objective!\n",
      "PRIMADNSs_BS causes infeasible status/0 objective!\n",
      "EIKAURSs_BS causes infeasible status/0 objective!\n",
      "EIKAUROc_BS causes infeasible status/0 objective!\n",
      "ECASDSs_BS causes infeasible status/0 objective!\n",
      "ECASDO1c_BS causes infeasible status/0 objective!\n",
      "ECASDO2c_BS causes infeasible status/0 objective!\n",
      "ECASDO3c_BS causes infeasible status/0 objective!\n",
      "ECASDATEO1c_BS causes infeasible status/0 objective!\n",
      "ECASDATEO2c_BS causes infeasible status/0 objective!\n",
      "P450MO2c_BS causes infeasible status/0 objective!\n",
      "ECASDATEO3c_BS causes infeasible status/0 objective!\n",
      "ECASD2ATEO1c_BS causes infeasible status/0 objective!\n",
      "ECASD2ATEO2c_BS causes infeasible status/0 objective!\n",
      "P450MO3c_BS causes infeasible status/0 objective!\n",
      "EKAURSs_BS causes infeasible status/0 objective!\n",
      "ECPDs_BS causes infeasible status/0 objective!\n",
      "EKAURO1c_BS causes infeasible status/0 objective!\n",
      "EKAURO2c_BS causes infeasible status/0 objective!\n",
      "EKAURO3c_BS causes infeasible status/0 objective!\n",
      "EKAURATEO1c_BS causes infeasible status/0 objective!\n",
      "EKAURATEO2c_BS causes infeasible status/0 objective!\n",
      "EKAURATEO3c_BS causes infeasible status/0 objective!\n",
      "GADO12c_BS causes infeasible status/0 objective!\n",
      "GAAKGOR1c_BS causes infeasible status/0 objective!\n",
      "GAAKGOR2c_BS causes infeasible status/0 objective!\n",
      "GAAKGOR3c_BS causes infeasible status/0 objective!\n",
      "GADO1c_BS causes infeasible status/0 objective!\n",
      "GAAKORG12c_BS causes infeasible status/0 objective!\n",
      "GAAKORG10c_BS causes infeasible status/0 objective!\n",
      "GAAKORG11c_BS causes infeasible status/0 objective!\n",
      "GAAKGOR4c_BS causes infeasible status/0 objective!\n",
      "GADO2c_BS causes infeasible status/0 objective!\n",
      "GADO3c_BS causes infeasible status/0 objective!\n",
      "GADO4c_BS causes infeasible status/0 objective!\n",
      "GADO5c_BS causes infeasible status/0 objective!\n",
      "GAAKGOR5c_BS causes infeasible status/0 objective!\n",
      "GAAKGOR6c_BS causes infeasible status/0 objective!\n",
      "GADO6c_BS causes infeasible status/0 objective!\n",
      "GAAKORG7c_BS causes infeasible status/0 objective!\n",
      "GAAKORG15c_BS causes infeasible status/0 objective!\n",
      "GAAKORG8c_BS causes infeasible status/0 objective!\n",
      "GAAKORG9c_BS causes infeasible status/0 objective!\n",
      "GADO7c_BS causes infeasible status/0 objective!\n",
      "GA3DOc_BS causes infeasible status/0 objective!\n",
      "GA2DOc_BS causes infeasible status/0 objective!\n",
      "GA4DOc_BS causes infeasible status/0 objective!\n",
      "VLXANDEOs_BS causes infeasible status/0 objective!\n",
      "ANXANDEOs_BS causes infeasible status/0 objective!\n",
      "ZXANEOys_BS causes infeasible status/0 objective!\n",
      "ZXANEOs_BS causes infeasible status/0 objective!\n",
      "ANXANEOys_BS causes infeasible status/0 objective!\n",
      "ANXANEOs_BS causes infeasible status/0 objective!\n",
      "ACAROTORs_BS causes infeasible status/0 objective!\n",
      "CAROTEMOs_BS causes infeasible status/0 objective!\n",
      "CPTXANORs_BS causes infeasible status/0 objective!\n",
      "ZNXANMOs_BS causes infeasible status/0 objective!\n",
      "PHYTDSs_BS causes infeasible status/0 objective!\n",
      "PHYTFLDSs_BS causes infeasible status/0 objective!\n",
      "BCAROTHs_BS causes infeasible status/0 objective!\n",
      "BCPTXANHs_BS causes infeasible status/0 objective!\n",
      "CAROTDSs_BS causes infeasible status/0 objective!\n",
      "ZCARTDSs_BS causes infeasible status/0 objective!\n",
      "CBGL1s_BS causes infeasible status/0 objective!\n",
      "CBGL2s_BS causes infeasible status/0 objective!\n",
      "PHYTS1s_BS causes infeasible status/0 objective!\n",
      "PHYTS2s_BS causes infeasible status/0 objective!\n",
      "NXANSs_BS causes infeasible status/0 objective!\n",
      "LYCOPEC1s_BS causes infeasible status/0 objective!\n",
      "LYCOPBC1s_BS causes infeasible status/0 objective!\n",
      "LYCOPBC2s_BS causes infeasible status/0 objective!\n",
      "LYCOPBC3s_BS causes infeasible status/0 objective!\n",
      "NXANIs_BS causes infeasible status/0 objective!\n",
      "XANXNDHs_BS causes infeasible status/0 objective!\n",
      "EPCDOs_BS causes infeasible status/0 objective!\n",
      "ABSALDOs_BS causes infeasible status/0 objective!\n",
      "ABSH1s_BS causes infeasible status/0 objective!\n",
      "ABSH2s_BS causes infeasible status/0 objective!\n",
      "ECAROTHs_BS causes infeasible status/0 objective!\n",
      "EECAROTLHs_BS causes infeasible status/0 objective!\n",
      "LYCOPEC2s_BS causes infeasible status/0 objective!\n",
      "HSTDHc_BS causes infeasible status/0 objective!\n",
      "DXCSTNMOc_BS causes infeasible status/0 objective!\n",
      "DXSTNORc_BS causes infeasible status/0 objective!\n",
      "DXTSTc_BS causes infeasible status/0 objective!\n",
      "DXTSTOc_BS causes infeasible status/0 objective!\n",
      "DXSTNOc_BS causes infeasible status/0 objective!\n",
      "DHDXSTNOc_BS causes infeasible status/0 objective!\n",
      "TSTNORc_BS causes infeasible status/0 objective!\n",
      "BRS1c_BS causes infeasible status/0 objective!\n",
      "BRS2c_BS causes infeasible status/0 objective!\n",
      "BRS3c_BS causes infeasible status/0 objective!\n",
      "CAMPSTHc_BS causes infeasible status/0 objective!\n",
      "22HCAMHc_BS causes infeasible status/0 objective!\n",
      "CAMPST43EHc_BS causes infeasible status/0 objective!\n",
      "CAMPSTLHc_BS causes infeasible status/0 objective!\n",
      "22HCAM43Rc_BS causes infeasible status/0 objective!\n",
      "CAM43Rc_BS causes infeasible status/0 objective!\n",
      "DKSTIc_BS causes infeasible status/0 objective!\n",
      "BRS5c_BS causes infeasible status/0 objective!\n",
      "BRS4c_BS causes infeasible status/0 objective!\n",
      "STR14DMc_BS causes infeasible status/0 objective!\n",
      "CAMPSTc_BS causes infeasible status/0 objective!\n",
      "STISTSc_BS causes infeasible status/0 objective!\n",
      "DHAVESTRc_BS causes infeasible status/0 objective!\n",
      "DHEPISTRc_BS causes infeasible status/0 objective!\n",
      "MERGRc_BS causes infeasible status/0 objective!\n",
      "DHAVESTSc_BS causes infeasible status/0 objective!\n",
      "DHEPISTSc_BS causes infeasible status/0 objective!\n",
      "CYEUOLSc_BS causes infeasible status/0 objective!\n",
      "AVESTSc_BS causes infeasible status/0 objective!\n",
      "METMTc_BS causes infeasible status/0 objective!\n",
      "CYARTMTc_BS causes infeasible status/0 objective!\n",
      "CSTLIc_BS causes infeasible status/0 objective!\n",
      "CASc_BS causes infeasible status/0 objective!\n",
      "CYECYCIc_BS causes infeasible status/0 objective!\n",
      "DSTRc_BS causes infeasible status/0 objective!\n",
      "IPDPT1s_BS causes infeasible status/0 objective!\n",
      "IPDPT2s_BS causes infeasible status/0 objective!\n",
      "ADMATs_BS causes infeasible status/0 objective!\n",
      "CYTTHs_BS causes infeasible status/0 objective!\n",
      "TZTNS1s_BS causes infeasible status/0 objective!\n",
      "TZTNS2s_BS causes infeasible status/0 objective!\n",
      "IPAMRPs_BS causes infeasible status/0 objective!\n",
      "TZTNS3s_BS causes infeasible status/0 objective!\n",
      "TZTNS4s_BS causes infeasible status/0 objective!\n",
      "TZTNS5s_BS causes infeasible status/0 objective!\n",
      "TZTNS6s_BS causes infeasible status/0 objective!\n",
      "IPADEDHs_BS causes infeasible status/0 objective!\n",
      "IPADETHs_BS causes infeasible status/0 objective!\n",
      "CKTHs_BS causes infeasible status/0 objective!\n",
      "ZTNRs_BS causes infeasible status/0 objective!\n",
      "P450MOc_BS causes infeasible status/0 objective!\n",
      "CKDH3c_BS causes infeasible status/0 objective!\n",
      "CKDH2c_BS causes infeasible status/0 objective!\n",
      "CKDH1c_BS causes infeasible status/0 objective!\n",
      "TRNAIPTc_BS causes infeasible status/0 objective!\n",
      "cZTNS1c_BS causes infeasible status/0 objective!\n",
      "cZTNS2c_BS causes infeasible status/0 objective!\n",
      "CKPc_BS causes infeasible status/0 objective!\n",
      "cZTNS3c_BS causes infeasible status/0 objective!\n",
      "CKGT1c_BS causes infeasible status/0 objective!\n",
      "CKGT2c_BS causes infeasible status/0 objective!\n",
      "CKGT3c_BS causes infeasible status/0 objective!\n",
      "CKGT4c_BS causes infeasible status/0 objective!\n",
      "CKGT5c_BS causes infeasible status/0 objective!\n",
      "CKGT6c_BS causes infeasible status/0 objective!\n",
      "CKGT7c_BS causes infeasible status/0 objective!\n",
      "CKGT8c_BS causes infeasible status/0 objective!\n",
      "CKOGT1c_BS causes infeasible status/0 objective!\n",
      "CKOGT2c_BS causes infeasible status/0 objective!\n",
      "CKOGT3c_BS causes infeasible status/0 objective!\n",
      "C3STDH2c_BS causes infeasible status/0 objective!\n",
      "C3STDH1c_BS causes infeasible status/0 objective!\n",
      "C3STKR2c_BS causes infeasible status/0 objective!\n",
      "C3STKR1c_BS causes infeasible status/0 objective!\n",
      "LNS14DMc_BS causes infeasible status/0 objective!\n",
      "C4STMO1c_BS causes infeasible status/0 objective!\n",
      "C4STMO2c_BS causes infeasible status/0 objective!\n",
      "LTHSTRLOc_BS causes infeasible status/0 objective!\n",
      "7DHCSRc_BS causes infeasible status/0 objective!\n",
      "C14STRc_BS causes infeasible status/0 objective!\n",
      "CHLSTRc_BS causes infeasible status/0 objective!\n",
      "CHLSTIc_BS causes infeasible status/0 objective!\n",
      "D24STR1c_BS causes infeasible status/0 objective!\n",
      "CHLSDDIc_BS causes infeasible status/0 objective!\n",
      "LNSTLSc_BS causes infeasible status/0 objective!\n",
      "SAM24MTc_BS causes infeasible status/0 objective!\n",
      "C8STIc_BS causes infeasible status/0 objective!\n",
      "LATOXc_BS causes infeasible status/0 objective!\n",
      "C22SDc_BS causes infeasible status/0 objective!\n",
      "D24STRc_BS causes infeasible status/0 objective!\n",
      "THFGLUHv_BS causes infeasible status/0 objective!\n",
      "URDGLLc_BS causes infeasible status/0 objective!\n",
      "ALTNDAc_BS causes infeasible status/0 objective!\n",
      "URDGLAHc_BS causes infeasible status/0 objective!\n",
      "PYDXSc_BS causes infeasible status/0 objective!\n",
      "PYAMPPc_BS causes infeasible status/0 objective!\n",
      "PDXPPc_BS causes infeasible status/0 objective!\n",
      "PYDXPPc_BS causes infeasible status/0 objective!\n",
      "MCOATAs_BS causes infeasible status/0 objective!\n",
      "ACOATAs_BS causes infeasible status/0 objective!\n",
      "MACPCLs_BS causes infeasible status/0 objective!\n",
      "ACMAT1s_BS causes infeasible status/0 objective!\n",
      "3OAR40s_BS causes infeasible status/0 objective!\n",
      "3HAD40s_BS causes infeasible status/0 objective!\n",
      "EAR40ys_BS causes infeasible status/0 objective!\n",
      "3OAS60s_BS causes infeasible status/0 objective!\n",
      "3OAR60s_BS causes infeasible status/0 objective!\n",
      "3HAD60s_BS causes infeasible status/0 objective!\n",
      "EAR60ys_BS causes infeasible status/0 objective!\n",
      "3OAS80s_BS causes infeasible status/0 objective!\n",
      "3OAR80s_BS causes infeasible status/0 objective!\n",
      "3HAD80s_BS causes infeasible status/0 objective!\n",
      "EAR80ys_BS causes infeasible status/0 objective!\n",
      "3OAS100s_BS causes infeasible status/0 objective!\n",
      "3OAR100s_BS causes infeasible status/0 objective!\n",
      "3HAD100s_BS causes infeasible status/0 objective!\n",
      "EAR100ys_BS causes infeasible status/0 objective!\n",
      "3OAS120s_BS causes infeasible status/0 objective!\n",
      "3OAR120s_BS causes infeasible status/0 objective!\n",
      "3HAD120s_BS causes infeasible status/0 objective!\n",
      "EAR120ys_BS causes infeasible status/0 objective!\n",
      "3OAS140s_BS causes infeasible status/0 objective!\n",
      "3OAR140s_BS causes infeasible status/0 objective!\n",
      "3HAD140s_BS causes infeasible status/0 objective!\n",
      "EAR140ys_BS causes infeasible status/0 objective!\n",
      "3OAS160s_BS causes infeasible status/0 objective!\n",
      "3OAR160s_BS causes infeasible status/0 objective!\n",
      "3HAD160s_BS causes infeasible status/0 objective!\n",
      "EAR160ys_BS causes infeasible status/0 objective!\n",
      "3OAS180s_BS causes infeasible status/0 objective!\n",
      "3OAR180s_BS causes infeasible status/0 objective!\n",
      "3HAD180s_BS causes infeasible status/0 objective!\n",
      "EAR180ys_BS causes infeasible status/0 objective!\n",
      "FAS161ACP_Ls_BS causes infeasible status/0 objective!\n",
      "FAS181ACP_Ls_BS causes infeasible status/0 objective!\n",
      "FAS182ACP_Ls_BS causes infeasible status/0 objective!\n",
      "FAS183ACP_Ls_BS causes infeasible status/0 objective!\n",
      "FA140ACPHs_BS causes infeasible status/0 objective!\n",
      "FA160ACPHs_BS causes infeasible status/0 objective!\n",
      "FA161ACPHs_BS causes infeasible status/0 objective!\n",
      "FA180ACPHs_BS causes infeasible status/0 objective!\n",
      "FA181ACPHs_BS causes infeasible status/0 objective!\n",
      "FA182ACPHs_BS causes infeasible status/0 objective!\n",
      "FA183ACPHs_BS causes infeasible status/0 objective!\n",
      "FACOAL140r_BS causes infeasible status/0 objective!\n",
      "FACOAL160r_BS causes infeasible status/0 objective!\n",
      "FACOAL161r_BS causes infeasible status/0 objective!\n",
      "FACOAL160c_BS causes infeasible status/0 objective!\n",
      "MALOAAtx_BS causes infeasible status/0 objective!\n",
      "ATPtr_BS causes infeasible status/0 objective!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DM_Phloem_BS causes infeasible status/0 objective!\n",
      "ngam_atp_c_BS causes infeasible status/0 objective!\n",
      "ngam_atp_s_BS causes infeasible status/0 objective!\n",
      "Checking done. Length of reactions that cause infeasibility issues/unbounded:  319\n",
      "Model bounds saved to: ./flux_results/flux_sampling/model_bounds/for_debugging/WT_750_no_cofac_rxns.csv.csv\n",
      "recomputing list_infeasibles\n",
      "setting bounds for rerun reaction FPGFTs_M. Bounds: 0.8206840546669774 | 2.6641450699450475\n",
      "setting bounds for rerun reaction DVCHLOR590s_M. Bounds: 0.5952161696163162 | 0.5953149178162978\n",
      "setting bounds for rerun reaction RPSII_430(u)_BS. Bounds: 0.1794964886363636 | 0.17951232996604063\n",
      "setting bounds for rerun reaction RPSII_690(u)_BS. Bounds: 0.2147564503204545 | 0.2147754034920843\n",
      "setting bounds for rerun reaction ATPAPc_BS. Bounds: 0.0 | 8.335029374180317\n",
      "setting bounds for rerun reaction ADPAc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction GAL1PUTc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction DPCOAKc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction URIKGc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction URIKGs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction DHDHc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction BUPNc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction DHPDc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction TMDSc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CYTDc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction GTPCYTDPTc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction GTPCYTDPTs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction DCTPDAc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CTPRc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction UTPRc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ATPRc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction GTPRc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction DCAHc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction UPRTs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ALAATc_BS. Bounds: -45.701321790705904 | 37.76171806934036\n",
      "setting bounds for rerun reaction ALAATm_BS. Bounds: -40.55030016376645 | 0.0\n",
      "setting bounds for rerun reaction ALAATs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction AAATc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ARGDs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ARGDc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ARGDm_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ASPCLc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ICDHc_BS. Bounds: -51.4324990980212 | 0.0\n",
      "setting bounds for rerun reaction MDHv_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction PPCc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ATPCSc_BS. Bounds: 0.0 | 17.97754267579758\n",
      "setting bounds for rerun reaction CSx_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CSm_BS. Bounds: -9.4042418709942 | 12.816963225749886\n",
      "setting bounds for rerun reaction ASPALc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction GLYCRORc_BS. Bounds: 0.0 | 65.31457471166232\n",
      "setting bounds for rerun reaction HMGCOARyc_BS. Bounds: -1.3906655320869776 | 29.02473733309742\n",
      "setting bounds for rerun reaction MEVKc_BS. Bounds: 0.0 | 1.3906655320869776\n",
      "setting bounds for rerun reaction PMEVKc_BS. Bounds: 0.0 | 1.3906655320869776\n",
      "setting bounds for rerun reaction DPMVDc_BS. Bounds: 0.0 | 1.3906655320869776\n",
      "setting bounds for rerun reaction IPDDIc_BS. Bounds: 0.0 | 1.0720505587732188\n",
      "setting bounds for rerun reaction IPDDIm_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction IPDDIs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction DXPRIis_BS. Bounds: 0.0 | 1.597863545772877\n",
      "setting bounds for rerun reaction IPDPS2s_BS. Bounds: 0.0 | 1.5090933487854894\n",
      "setting bounds for rerun reaction IPDPS1s_BS. Bounds: 0.0 | 1.509093348785495\n",
      "setting bounds for rerun reaction DMPPS2s_BS. Bounds: 0.0 | 1.145821188743699\n",
      "setting bounds for rerun reaction DMPPS1s_BS. Bounds: 0.0 | 1.145821188743699\n",
      "setting bounds for rerun reaction MECDPDH5s_BS. Bounds: 0.0 | 1.597863545772877\n",
      "setting bounds for rerun reaction CDPMEKs_BS. Bounds: 0.0 | 1.597863545772877\n",
      "setting bounds for rerun reaction MEPCTs_BS. Bounds: 0.0 | 1.5978635457727481\n",
      "setting bounds for rerun reaction MECDPSs_BS. Bounds: 0.0 | 1.597863545772877\n",
      "setting bounds for rerun reaction DMATTs_BS. Bounds: 0.0 | 1.145821188743699\n",
      "setting bounds for rerun reaction DMATTm_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction GRTTs_BS. Bounds: 0.0 | 0.7463553023008966\n",
      "setting bounds for rerun reaction GRTTm_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction FRTTs_BS. Bounds: 0.0 | 0.7463553023008966\n",
      "setting bounds for rerun reaction DMATTc_BS. Bounds: 0.0 | 0.7298657683244726\n",
      "setting bounds for rerun reaction GRTTc_BS. Bounds: 0.0 | 0.7298657683244384\n",
      "setting bounds for rerun reaction GGDRc_BS. Bounds: 0.0 | 0.2839604574422678\n",
      "setting bounds for rerun reaction LIMSs_BS. Bounds: 0.0 | 0.7989317728856051\n",
      "setting bounds for rerun reaction PSPPSc_BS. Bounds: 0.0 | 0.364932884162224\n",
      "setting bounds for rerun reaction SQLSc_BS. Bounds: 0.0 | 0.36493288416222\n",
      "setting bounds for rerun reaction SQLMOc_BS. Bounds: 0.0 | 0.36493288416222264\n",
      "setting bounds for rerun reaction PRIMARTSc_BS. Bounds: 0.0 | 0.3926740593907465\n",
      "setting bounds for rerun reaction SCODPSs_BS. Bounds: 0.0 | 0.7463553023008966\n",
      "setting bounds for rerun reaction PRIMARDSs_BS. Bounds: 0.0 | 0.3926740593907465\n",
      "setting bounds for rerun reaction MOMASys_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction MOMASs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction STEMSs_BS. Bounds: 0.0 | 0.39527028288790866\n",
      "setting bounds for rerun reaction STEMOc_BS. Bounds: 0.0 | 0.39527028288790866\n",
      "setting bounds for rerun reaction P450MO1c_BS. Bounds: 0.0 | 0.39527028288790866\n",
      "setting bounds for rerun reaction ESANDSs_BS. Bounds: 0.0 | 0.3953869853817191\n",
      "setting bounds for rerun reaction ESANDO1c_BS. Bounds: 0.0 | 0.3953869853817191\n",
      "setting bounds for rerun reaction P450MO4c_BS. Bounds: 0.0 | 0.39011590156523546\n",
      "setting bounds for rerun reaction P450MO5c_BS. Bounds: 0.0 | 0.3953869853817191\n",
      "setting bounds for rerun reaction P450MO6c_BS. Bounds: 0.0 | 0.3953869853817191\n",
      "setting bounds for rerun reaction OZLNDO1c_BS. Bounds: 0.0 | 0.39011590156523546\n",
      "setting bounds for rerun reaction OZLNDO2c_BS. Bounds: 0.0 | 0.39011590156523546\n",
      "setting bounds for rerun reaction OZLNAOc_BS. Bounds: 0.0 | 0.39011590156523546\n",
      "setting bounds for rerun reaction OZLNBOc_BS. Bounds: 0.0 | 0.39011590156523546\n",
      "setting bounds for rerun reaction PRIMADNSs_BS. Bounds: 0.0 | 0.39946588644303155\n",
      "setting bounds for rerun reaction EIKAURSs_BS. Bounds: 0.0 | 0.39732962679964773\n",
      "setting bounds for rerun reaction EIKAUROc_BS. Bounds: 0.0 | 0.39732962679964773\n",
      "setting bounds for rerun reaction ECASDSs_BS. Bounds: 0.0 | 0.3872518894499638\n",
      "setting bounds for rerun reaction ECASDO1c_BS. Bounds: 0.0 | 0.3872518894499638\n",
      "setting bounds for rerun reaction ECASDO2c_BS. Bounds: 0.0 | 0.3872518894499638\n",
      "setting bounds for rerun reaction ECASDO3c_BS. Bounds: 0.0 | 0.3872518894499638\n",
      "setting bounds for rerun reaction ECASDATEO1c_BS. Bounds: 0.0 | 0.3872518894499638\n",
      "setting bounds for rerun reaction ECASDATEO2c_BS. Bounds: 0.0 | 0.38711403994347965\n",
      "setting bounds for rerun reaction P450MO2c_BS. Bounds: 0.0 | 0.3872518894499638\n",
      "setting bounds for rerun reaction ECASDATEO3c_BS. Bounds: 0.0 | 0.3872518894499638\n",
      "setting bounds for rerun reaction ECASD2ATEO1c_BS. Bounds: 0.0 | 0.38711403994347965\n",
      "setting bounds for rerun reaction ECASD2ATEO2c_BS. Bounds: 0.0 | 0.3871140399434301\n",
      "setting bounds for rerun reaction P450MO3c_BS. Bounds: 0.0 | 0.3872518894499638\n",
      "setting bounds for rerun reaction EKAURSs_BS. Bounds: 0.0 | 0.2949357397313442\n",
      "setting bounds for rerun reaction ECPDs_BS. Bounds: 0.0 | 0.7463553023008966\n",
      "setting bounds for rerun reaction EKAURO1c_BS. Bounds: 0.0 | 0.2949357397313442\n",
      "setting bounds for rerun reaction EKAURO2c_BS. Bounds: 0.0 | 0.2949357397313442\n",
      "setting bounds for rerun reaction EKAURO3c_BS. Bounds: 0.0 | 0.2949357397313442\n",
      "setting bounds for rerun reaction EKAURATEO1c_BS. Bounds: 0.0 | 0.2949357397313442\n",
      "setting bounds for rerun reaction EKAURATEO2c_BS. Bounds: 0.0 | 0.2949357397313442\n",
      "setting bounds for rerun reaction EKAURATEO3c_BS. Bounds: 0.0 | 0.2949357397313442\n",
      "setting bounds for rerun reaction GADO12c_BS. Bounds: 0.0 | 0.2949357397313442\n",
      "setting bounds for rerun reaction GAAKGOR1c_BS. Bounds: 0.0 | 0.2949357397313442\n",
      "setting bounds for rerun reaction GAAKGOR2c_BS. Bounds: 0.0 | 0.2949357397313442\n",
      "setting bounds for rerun reaction GAAKGOR3c_BS. Bounds: 0.0 | 0.2949357397313442\n",
      "setting bounds for rerun reaction GADO1c_BS. Bounds: 0.0 | 0.25459674274359095\n",
      "setting bounds for rerun reaction GAAKORG12c_BS. Bounds: 0.0 | 0.25459674274359095\n",
      "setting bounds for rerun reaction GAAKORG10c_BS. Bounds: 0.0 | 0.25464452360944495\n",
      "setting bounds for rerun reaction GAAKORG11c_BS. Bounds: 0.0 | 0.25464452360944495\n",
      "setting bounds for rerun reaction GAAKGOR4c_BS. Bounds: 0.0 | 0.27410005186418523\n",
      "setting bounds for rerun reaction GADO2c_BS. Bounds: 0.0 | 0.25459674274359095\n",
      "setting bounds for rerun reaction GADO3c_BS. Bounds: 0.0 | 0.27410005186418523\n",
      "setting bounds for rerun reaction GADO4c_BS. Bounds: 0.0 | 0.25459674274359095\n",
      "setting bounds for rerun reaction GADO5c_BS. Bounds: 0.0 | 0.25459674274359095\n",
      "setting bounds for rerun reaction GAAKGOR5c_BS. Bounds: 0.0 | 0.25459674274359095\n",
      "setting bounds for rerun reaction GAAKGOR6c_BS. Bounds: 0.0 | 0.25459674274359095\n",
      "setting bounds for rerun reaction GADO6c_BS. Bounds: 0.0 | 0.2949357397313442\n",
      "setting bounds for rerun reaction GAAKORG7c_BS. Bounds: 0.0 | 0.2949357397313442\n",
      "setting bounds for rerun reaction GAAKORG15c_BS. Bounds: 0.0 | 0.27410005186415465\n",
      "setting bounds for rerun reaction GAAKORG8c_BS. Bounds: 0.0 | 0.23867407654151407\n",
      "setting bounds for rerun reaction GAAKORG9c_BS. Bounds: 0.0 | 0.23867407654151407\n",
      "setting bounds for rerun reaction GADO7c_BS. Bounds: 0.0 | 0.2949357397313442\n",
      "setting bounds for rerun reaction GA3DOc_BS. Bounds: 0.0 | 0.2245886336838935\n",
      "setting bounds for rerun reaction GA2DOc_BS. Bounds: 0.0 | 0.2245886336838935\n",
      "setting bounds for rerun reaction GA4DOc_BS. Bounds: 0.0 | 0.2245886336838935\n",
      "setting bounds for rerun reaction VLXANDEOs_BS. Bounds: 0.0 | 3.9792932389125295\n",
      "setting bounds for rerun reaction ANXANDEOs_BS. Bounds: 0.0 | 3.9792932389152402\n",
      "setting bounds for rerun reaction ZXANEOys_BS. Bounds: 0.0 | 3.9792932389152407\n",
      "setting bounds for rerun reaction ZXANEOs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ANXANEOys_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ANXANEOs_BS. Bounds: 0.0 | 3.9792932389152407\n",
      "setting bounds for rerun reaction ACAROTORs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CAROTEMOs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CPTXANORs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ZNXANMOs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction PHYTDSs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction PHYTFLDSs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction BCAROTHs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction BCPTXANHs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CAROTDSs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ZCARTDSs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CBGL1s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CBGL2s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction PHYTS1s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction PHYTS2s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction NXANSs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction LYCOPEC1s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction LYCOPBC1s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction LYCOPBC2s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction LYCOPBC3s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction NXANIs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction XANXNDHs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction EPCDOs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ABSALDOs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ABSH1s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ABSH2s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ECAROTHs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction EECAROTLHs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction LYCOPEC2s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction HSTDHc_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction DXCSTNMOc_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction DXSTNORc_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction DXTSTc_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction DXTSTOc_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction DXSTNOc_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction DHDXSTNOc_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction TSTNORc_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction BRS1c_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction BRS2c_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction BRS3c_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction CAMPSTHc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction 22HCAMHc_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction CAMPST43EHc_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction CAMPSTLHc_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction 22HCAM43Rc_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction CAM43Rc_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction DKSTIc_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction BRS5c_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction BRS4c_BS. Bounds: 0.0 | 0.2411427726954338\n",
      "setting bounds for rerun reaction STR14DMc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CAMPSTc_BS. Bounds: 0.0 | 0.31847016545907986\n",
      "setting bounds for rerun reaction STISTSc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction DHAVESTRc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction DHEPISTRc_BS. Bounds: 0.0 | 0.3184701654590798\n",
      "setting bounds for rerun reaction MERGRc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction DHAVESTSc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction DHEPISTSc_BS. Bounds: 0.0 | 0.3184701654590799\n",
      "setting bounds for rerun reaction CYEUOLSc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction AVESTSc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction METMTc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CYARTMTc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CSTLIc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CASc_BS. Bounds: 0.0 | 0.20752378558966003\n",
      "setting bounds for rerun reaction CYECYCIc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction DSTRc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction IPDPT1s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction IPDPT2s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ADMATs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CYTTHs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction TZTNS1s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction TZTNS2s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction IPAMRPs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction TZTNS3s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction TZTNS4s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction TZTNS5s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction TZTNS6s_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction IPADEDHs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction IPADETHs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CKTHs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ZTNRs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction P450MOc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CKDH3c_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CKDH2c_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CKDH1c_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction TRNAIPTc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction cZTNS1c_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction cZTNS2c_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CKPc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction cZTNS3c_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CKGT1c_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CKGT2c_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CKGT3c_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CKGT4c_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CKGT5c_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CKGT6c_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CKGT7c_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CKGT8c_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CKOGT1c_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CKOGT2c_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction CKOGT3c_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction C3STDH2c_BS. Bounds: 0.0 | 0.36493288416222547\n",
      "setting bounds for rerun reaction C3STDH1c_BS. Bounds: 0.0 | 0.36493288416222547\n",
      "setting bounds for rerun reaction C3STKR2c_BS. Bounds: 0.0 | 0.36493288416222525\n",
      "setting bounds for rerun reaction C3STKR1c_BS. Bounds: 0.0 | 0.36493288416221975\n",
      "setting bounds for rerun reaction LNS14DMc_BS. Bounds: 0.0 | 0.36493288416221975\n",
      "setting bounds for rerun reaction C4STMO1c_BS. Bounds: 0.0 | 0.3649328841622255\n",
      "setting bounds for rerun reaction C4STMO2c_BS. Bounds: 0.0 | 0.36493288416222525\n",
      "setting bounds for rerun reaction LTHSTRLOc_BS. Bounds: 0.0 | 0.24812462216262718\n",
      "setting bounds for rerun reaction 7DHCSRc_BS. Bounds: 0.0 | 0.24812462216262718\n",
      "setting bounds for rerun reaction C14STRc_BS. Bounds: 0.0 | 0.3649328841622251\n",
      "setting bounds for rerun reaction CHLSTRc_BS. Bounds: 0.0 | 0.24812462216262718\n",
      "setting bounds for rerun reaction CHLSTIc_BS. Bounds: 0.0 | 0.24812462216262718\n",
      "setting bounds for rerun reaction D24STR1c_BS. Bounds: 0.0 | 0.24812462216262718\n",
      "setting bounds for rerun reaction CHLSDDIc_BS. Bounds: 0.0 | 0.24812462216262718\n",
      "setting bounds for rerun reaction LNSTLSc_BS. Bounds: 0.0 | 0.3649328841622011\n",
      "setting bounds for rerun reaction SAM24MTc_BS. Bounds: 0.0 | 0.3649328841622183\n",
      "setting bounds for rerun reaction C8STIc_BS. Bounds: 0.0 | 0.3649328841622252\n",
      "setting bounds for rerun reaction LATOXc_BS. Bounds: 0.0 | 0.25013570735130497\n",
      "setting bounds for rerun reaction C22SDc_BS. Bounds: 0.0 | 0.25013570735130497\n",
      "setting bounds for rerun reaction D24STRc_BS. Bounds: 0.0 | 0.25013570735130497\n",
      "setting bounds for rerun reaction THFGLUHv_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction URDGLLc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ALTNDAc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction URDGLAHc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction PYDXSc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction PYAMPPc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction PDXPPc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction PYDXPPc_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction MCOATAs_BS. Bounds: 0.0 | 3.0735677328788835\n",
      "setting bounds for rerun reaction ACOATAs_BS. Bounds: 0.0 | 0.38419596660986066\n",
      "setting bounds for rerun reaction MACPCLs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ACMAT1s_BS. Bounds: 0.0 | 0.38419596660986066\n",
      "setting bounds for rerun reaction 3OAR40s_BS. Bounds: 0.0 | 0.38419596660986066\n",
      "setting bounds for rerun reaction 3HAD40s_BS. Bounds: 0.0 | 0.38419596660986066\n",
      "setting bounds for rerun reaction EAR40ys_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3OAS60s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3OAR60s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3HAD60s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction EAR60ys_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3OAS80s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3OAR80s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3HAD80s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction EAR80ys_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3OAS100s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3OAR100s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3HAD100s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction EAR100ys_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3OAS120s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3OAR120s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3HAD120s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction EAR120ys_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3OAS140s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3OAR140s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3HAD140s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction EAR140ys_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3OAS160s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3OAR160s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3HAD160s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction EAR160ys_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3OAS180s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3OAR180s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction 3HAD180s_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction EAR180ys_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction FAS161ACP_Ls_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction FAS181ACP_Ls_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction FAS182ACP_Ls_BS. Bounds: 0.0 | 0.38419596660986044\n",
      "setting bounds for rerun reaction FAS183ACP_Ls_BS. Bounds: 0.0 | 0.38419596660986066\n",
      "setting bounds for rerun reaction FA140ACPHs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction FA160ACPHs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction FA161ACPHs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction FA180ACPHs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction FA181ACPHs_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction FA182ACPHs_BS. Bounds: 0.0 | 53.331124613784716\n",
      "setting bounds for rerun reaction FA183ACPHs_BS. Bounds: 0.0 | 53.26552761232162\n",
      "setting bounds for rerun reaction FACOAL140r_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction FACOAL160r_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction FACOAL161r_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction FACOAL160c_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction MALOAAtx_BS. Bounds: -0.4596937754651534 | 14.230286585042258\n",
      "setting bounds for rerun reaction ATPtr_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction DM_Phloem_BS. Bounds: 0.0 | 0.0\n",
      "setting bounds for rerun reaction ngam_atp_c_BS. Bounds: 0.5872818181818181 | 0.5872818181818181\n",
      "setting bounds for rerun reaction ngam_atp_s_BS. Bounds: 0.0 | 18.446758080962283\n",
      "printing model objective:\n",
      "<Solution 0.000 at 0x7f661a8292d0>\n",
      "reactions number (before pruning):  4940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  1561\n",
      "final model objective (Final feasibility check):\n",
      "<Solution 0.000 at 0x7f661d7668c0>\n",
      "end time for parametrize_model():  2023-06-30 10:03:03.390175\n",
      "start time for parametrize_model():  2023-06-30 10:03:03.390372\n",
      "Read LP format model from file /tmp/tmp8uumz686.lp\n",
      "Reading time = 0.01 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "computing Loopless FVA to model\n",
      "setting FVA constraints to model and checking for feasibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATGDs_BS causes infeasible status/0 objective!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPTAs_BS causes infeasible status/0 objective!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPDPKs_BS causes infeasible status/0 objective!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DVCHLOR430s_BS causes infeasible status/0 objective!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCP32_BS causes infeasible status/0 objective!\n",
      "Checking done. Length of reactions that cause infeasibility issues/unbounded:  5\n",
      "Model bounds saved to: ./flux_results/flux_sampling/model_bounds/for_debugging/.WT_1500_no_cofac_rxns.csv.csv\n",
      "recomputing list_infeasibles\n",
      "setting bounds for rerun reaction ATGDs_BS. Bounds: 0.015594200636895946 | 0.015615520598463568\n",
      "setting bounds for rerun reaction ASPTAs_BS. Bounds: 2.398751129837503 | 38.73675282664125\n",
      "setting bounds for rerun reaction RPDPKs_BS. Bounds: 0.015594200636901867 | 0.026873373390163498\n",
      "setting bounds for rerun reaction DVCHLOR430s_BS. Bounds: 0.5333778079680743 | 0.5336860323371261\n",
      "setting bounds for rerun reaction TCP32_BS. Bounds: 0.0 | 0.0\n",
      "printing model objective:\n",
      "<Solution 1.612 at 0x7f6642ae52d0>\n",
      "reactions number (before pruning):  4940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  1594\n",
      "final model objective (Final feasibility check):\n",
      "<Solution 1.612 at 0x7f666100b040>\n",
      "end time for parametrize_model():  2023-06-30 10:33:23.006024\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "#Just a test to see yung bounds nung walang cofac constraints\n",
    "#Parametrize models per type by generating model instance\n",
    "\n",
    "print('Generating parametrized models for flux sampling')\n",
    "#Let's check if it works as a separate instance per WT and TR?\n",
    "with wt_model as wt_model:\n",
    "    WT_750 = parametrize_model(wt_model, 725, 775,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True, intermediate_fva_results='WT_750_no_cofac_rxns.csv')\n",
    "    WT_1500 = parametrize_model(wt_model, 1475, 1525,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True, intermediate_fva_results='.WT_1500_no_cofac_rxns.csv')\n",
    "\n",
    "\n",
    "#Apparently it causes a lot of numerical issues so I might as well not do it and follow my original protocol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c8ac6c-8ffa-44a7-892b-fbaceb9ea854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #This function is a prototype for the above and the changes are incorporated into the main parametrization function above.\n",
    "\n",
    "\n",
    "# def check_model_feasibility(model, ppfd_low, ppfd_high, co2,if_trans, pruning,frac_optimum=1, fva_bounds_file='', intermediate_fva_results=''):\n",
    "    \n",
    "#     print('start time for parametrize_model(): ' ,datetime.datetime.now())\n",
    "\n",
    "#     #Generates a parametrized model which returns the constrained model as a callable object.\n",
    "    \n",
    "#     #Copy model \n",
    "#     model_instance = model.copy()\n",
    "    \n",
    "#     model_instance.tolerance = 1e-9\n",
    "                                                                                                                                                                                                                                \n",
    "#     model_instance.medium = define_model_medium(model_instance, co2=co2, o2=inf, ppfd=inf, h=inf, nh4=inf, no3=inf)\n",
    "#     turn_off_cofac_cycles(model_instance)\n",
    "#     add_tissue_constraints(model_instance)\n",
    "#     add_enzyme_constraints(model_instance)\n",
    "\n",
    "#     #Adds NGAM (Computed as an average between the high and low instead of directly constraining it to the model, w/c makes the problem non-linear)\n",
    "#     add_ngam_cons(model_instance, (ppfd_high+ppfd_low)/2)\n",
    "    \n",
    "#     #Constrain PPFD range to indicated value\n",
    "#     model_instance.reactions.get_by_id('EX_photonVis(e)').bounds = (-1*ppfd_high, -1*ppfd_low)\n",
    "    \n",
    "\n",
    "#     #Check if trans then add constraints if true\n",
    "#     if if_trans==True:\n",
    "#         add_trans_reactions(model_instance)\n",
    "#         # add_trans_constraints(model_instance)\n",
    "    \n",
    "    \n",
    "#     #Readd objective coefficient, maybe it'll work?\n",
    "#     model_instance.reactions.get_by_id('DM_Phloem_BS').objective_coefficient = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "#     '''Run FVA to preprocess the model to fix reaction reversibilities as well as to ensure that there are no \"extreme\" fluxes in the final sampling\n",
    "#      Perform Flux Variability Analysis (FVA)\n",
    "#         This step constrains the upper and lower bounds to the detected \"Maximal\" and \"minimal\" fluxes given an objective\n",
    "#         The default fraction of optimum will be implemented\n",
    "#     Will implement pFBA factor to constrain the model to 110% of the detected lowest flux '''\n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "#     #flux_variability_analysis produces a Pandas Dataframe that can be taken apart and applied to the model_instance as direct bounds. \n",
    "    \n",
    "#     list_infeasibles = list()\n",
    "#     if fva_bounds_file:\n",
    "#         print('reading previous FVA bounds')\n",
    "#         fva_result = pd.read_csv(fva_bounds_file, index_col=0)\n",
    "#         fva_result.columns = ['minimum', 'maximum']\n",
    "        \n",
    "        \n",
    "#         #Modify the above such that it also include unbounded reactions\n",
    "        \n",
    "#     print('setting FVA bounds and checking feasibility')\n",
    "#     for reaction_id, bounds in fva_result.iterrows():\n",
    "#         reaction = model_instance.reactions.get_by_id(reaction_id)        \n",
    "        \n",
    "#         #Append the reaction to the reactions to rerun if it is not present in the FVA bounds\n",
    "#         if reaction_id not in model_instance.reactions:\n",
    "#             list_infeasibles.append()\n",
    "# #         if bounds.isnull().any():\n",
    "# #             print(f'{reaction_id} has NaNs!')\n",
    "# #             list_infeasibles.append(model_instance.reactions.get_by_id(reaction_id))\n",
    "# #             continue\n",
    "\n",
    "\n",
    "#     #Removing the NaNs breaks the model. What I should probably do instead is generate another set of fva_results (without the Loopless constraint?)\n",
    "\n",
    "#         old_bounds = reaction.bounds\n",
    "        \n",
    "#         # Check which is higher or lower to avoid Value errors\n",
    "#         lower_bound = float(min(bounds['minimum'], bounds['maximum']))\n",
    "#         upper_bound = float(max(bounds['minimum'], bounds['maximum']))\n",
    "#         reaction.bounds = (lower_bound, upper_bound)\n",
    "        \n",
    "#         solution = model_instance.slim_optimize()\n",
    "#         status= model_instance.optimize().status\n",
    "#         #Revert model to previous flux bounds\n",
    "#         if status=='infeasible' or solution==0:\n",
    "#             print(f'{reaction_id} causes infeasible status!')\n",
    "#             reaction.bounds=old_bounds\n",
    "#             list_infeasibles.append(reaction)\n",
    "#             continue\n",
    "            \n",
    "\n",
    "#         #Rerun FVA\n",
    "#     if len(list_infeasibles) != 0:\n",
    "#         print('recomputing list_infeasibles')\n",
    "#         fva_non_loopless =  cobra.flux_analysis.flux_variability_analysis(model_instance, reaction_list=list_infeasibles, loopless=True ,fraction_of_optimum=frac_optimum-0.05, pfba_factor=1.1, processes=7)\n",
    "\n",
    "#         for reaction_id, bounds in fva_non_loopless.iterrows():\n",
    "#             reaction = model_instance.reactions.get_by_id(reaction_id)        \n",
    "#             # Check which is higher or lower to avoid Value errors\n",
    "#             lower_bound = float(min(bounds['minimum'], bounds['maximum']))\n",
    "#             upper_bound = float(max(bounds['minimum'], bounds['maximum']))\n",
    "#             reaction.bounds = (lower_bound, upper_bound) #Add reaction bounds to the model from the new FVA results\n",
    "\n",
    "\n",
    "#         if pruning==True:\n",
    "#             print('Before blocked_reactions()')\n",
    "#             print(model_instance.optimize())\n",
    "#             blocked_reactions = cobra.flux_analysis.find_blocked_reactions(model_instance)\n",
    "#             print('reactions number (before pruning): ', len(model_instance.reactions))\n",
    "#         # model_instance.remove_reactions(filter_list)\n",
    "#             model_instance.remove_reactions(blocked_reactions)\n",
    "#             print('reactions number (after pruning): ', len(model_instance.reactions))\n",
    "        \n",
    "    \n",
    "    \n",
    "#     print(model_instance.optimize())\n",
    "    \n",
    "#     return(list_infeasibles)\n",
    "    \n",
    "# TR_250 = check_model_feasibility(wt_model, 225, 275,co2=22.2, pruning=True, if_trans=True,frac_optimum=0.90, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/TR_250.csv')\n",
    "# TR_750 = check_model_feasibility(wt_model, 725, 775,co2=22.2, pruning=True,if_trans=True,frac_optimum=0.90, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/TR_750.csv')\n",
    "# TR_1500 = check_model_feasibility(wt_model, 1475, 1525,co2=22.2, pruning=True, if_trans=True,frac_optimum=0.9, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/TR_1500.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48eaa1f-4bdf-49aa-abac-3916cc46f03d",
   "metadata": {},
   "source": [
    "Reactions with issues:\n",
    "- ATGDs, for some reason"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16042782-0618-482a-a861-60d2b9d755c9",
   "metadata": {},
   "source": [
    "The fix now returns a solution. Let's check if the Loopless=True works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14514c16-6e44-4b85-b092-be0439cfc79e",
   "metadata": {},
   "source": [
    "Notes: \n",
    "- Flux bounds for FVA show infeasibility for Trans parametrized models. Maybe we could instead prune to model beforehand before computing loopless FVA?\n",
    "- Other constraints \n",
    "\n",
    "-One of the Photon decomposition reactions cause infeasibility issues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b247e7-3b5d-4d11-86cf-1ef0d2341c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Parametrize model then save as Json for Escher-FBA\n",
    "\n",
    "# with wt_model as wt_model:\n",
    "#     WT_250 =  parametrize_model(wt_model, 225,275,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/WT_250.csv') #Done\n",
    "#     WT_750 = parametrize_model(wt_model, 725, 775,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/.csv')\n",
    "#     WT_1500 = parametrize_model(wt_model, 1475, 1525,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/WT_1500.csv')\n",
    "\n",
    "#     TR_250 = parametrize_model(wt_model, 225, 275,co2=22.2, if_trans=True, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/flux_sample_TR_250_Relaxed_loopless_FVA_100kT.csv')\n",
    "#     TR_750 = parametrize_model(wt_model, 725, 775,co2=22.2, if_trans=True, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/flux_sample_TR_750_Relaxed_loopless_FVA_100kT.csv')\n",
    "#     TR_1500 = parametrize_model(wt_model, 1475, 1525,co2=22.2, if_trans=True, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/flux_sample_TR_1500_Relaxed_loopless_FVA_100kT.csv')\n",
    "\n",
    "    \n",
    "# sampling_list = [WT_250, WT_750, WT_1500, TR_250, TR_750, TR_1500]\n",
    "\n",
    "# for model in sampling_list:\n",
    "#     name_for_file = str('flux_sample_'+model_name+'_Relaxed_loopless_FVA_100kT_reran.csv')\n",
    "#     model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "#     cobra.io.save_json_model(model, filename=,\n",
    "                             \n",
    "# for model in sampling_list:\n",
    "#     print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "#     model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "#     name_for_file = str('flux_sample_'+model_name+'_Relaxed_loopless_FVA_100kT_reran.csv')\n",
    "#     #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "#     save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "    \n",
    "#     #Parametrize OPTGP sampler\n",
    "#     num_samples =10000\n",
    "#     thinning = 100000\n",
    "    \n",
    "#     print('Starting OPTGP sampler:')\n",
    "#     print('num_samples: ', num_samples)\n",
    "#     print('Thinning coefficient: ', thinning)\n",
    "#     generate_flux_samples(model, num_samples =num_samples, nproj=1, batch_size=5000, thinning=thinning, output_filename=name_for_file)\n",
    "#     del model #Deletes model instance to free up memory \n",
    "#     print('end time: ', datetime.datetime.now())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c99d230-c4fc-4f05-a56e-1eb70ffd2331",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# WT_750 = parametrize_model(wt_model, 725, 775,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/WT_750.csv')\n",
    "\n",
    "\n",
    "# #Generate list of models for flux sampling\n",
    "# sampling_list = [WT_750]\n",
    "\n",
    "# print('generating flux samples for parametrized models')\n",
    "# for model in sampling_list:\n",
    "#     print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "#     model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "#     name_for_file = str('flux_sample_'+model_name+'_Relaxed_loopless_FVA_Test.csv')\n",
    "#     #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "#     save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "    \n",
    "#     #Parametrize OPTGP sampler\n",
    "#     num_samples =10000\n",
    "#     thinning = 100000\n",
    "    \n",
    "#     print('Starting OPTGP sampler:')\n",
    "#     print('num_samples: ', num_samples)\n",
    "#     print('Thinning coefficient: ', thinning)\n",
    "#     generate_flux_samples(model, num_samples =num_samples, batch_size=5000, thinning=thinning, output_filename=name_for_file)\n",
    "#     del model #Deletes model instance to free up memory \n",
    "#     print('end time: ', datetime.datetime.now())\n",
    "    \n",
    "    \n",
    "# #Apparently the pruning function causes the model to become numerically unstable. Bakit kaa?\n",
    "# #This set of functiosns work\n",
    "\n",
    "# #This outputs a set of bounds that we can reuse to re-parametrize a model instead of re-running the parametrization script again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd4bc9-740b-4566-8ffe-d8c52fb606ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # %timeit\n",
    "# # #Include the FVA bounds file\n",
    "\n",
    "# # #Parametrize models per type by generating model instance\n",
    "# # print('Generating parametrized models for flux sampling')\n",
    "# WT_250 =  parametrize_model(wt_model, 225,275,co2=29, if_trans=False, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_WT_250.csv')\n",
    "# WT_750 = parametrize_model(wt_model, 725, 775,co2=29, if_trans=False, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_WT_750.csv')\n",
    "# WT_1500 = parametrize_model(wt_model, 1475, 1525,co2=29, if_trans=False, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_WT_1500.csv')\n",
    "\n",
    "# TR_250 = parametrize_model(wt_model, 225, 275,co2=22.2, if_trans=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_TR_250.csv')\n",
    "# TR_750 = parametrize_model(wt_model, 725, 775,co2=22.2, if_trans=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_TR_750.csv')\n",
    "# TR_1500 = parametrize_model(wt_model, 1475, 1525,co2=22.2, if_trans=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_TR_1500.csv')\n",
    "\n",
    "# #Generate list of models for flux sampling\n",
    "# sampling_list = [WT_250, WT_750, WT_1500, TR_250, TR_750, TR_1500]\n",
    "\n",
    "# print('generating flux samples for parametrized models')\n",
    "# for model in sampling_list:\n",
    "#     print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "#     model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "#     name_for_file = str('flux_sample_'+model_name+'_Loopless_FVA_35kT')\n",
    "    \n",
    "#     #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "#     save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print('Starting OPTGP sampler:')\n",
    "#     generate_flux_samples(model, num_samples =5000, batch_size=2500, thinning=35000, output_filename=name_for_file)\n",
    "#     del model #Deletes model instance to free up memory \n",
    "#     print('end time: ', datetime.datetime.now())\n",
    "\n",
    "# #This outputs a set of bounds that we can reuse to re-parametrize a model instead of re-running the parametrization script again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db0e55-545d-4198-b5b6-e2e6ba7a02d4",
   "metadata": {},
   "source": [
    "The second part of this script is for post-processing the DFs obtained via flux sampling using the CycleFreeFlux algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1f6f42-2496-40eb-9a02-fa0f7a15f0f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Let's try using CCF to post-process the samples that I've already obtained \n",
    "# #First generate the model again\n",
    "\n",
    "# WT_250 =  parametrize_model(wt_model, 225,275,co2=29, if_trans=False, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_WT_250.csv')\n",
    "# WT_750 = parametrize_model(wt_model, 725, 775,co2=29, if_trans=False, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_WT_750.csv')\n",
    "# WT_1500 = parametrize_model(wt_model, 1475, 1525,co2=29, if_trans=False, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_WT_1500.csv')\n",
    "\n",
    "\n",
    "# TR_250 = parametrize_model(wt_model, 225, 275,co2=22.2, if_trans=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_TR_250.csv')\n",
    "# TR_750 = parametrize_model(wt_model, 725, 775,co2=22.2, if_trans=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_TR_750.csv')\n",
    "# TR_1500 = parametrize_model(wt_model, 1475, 1525,co2=22.2, if_trans=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_TR_1500.csv')\n",
    "# wt_250_df = pd.read_csv('./flux_results/flux_sampling/4th_iteration_35kthinning/flux_sample_WT_250.csv')\n",
    "# wt_750_df = pd.read_csv('./flux_results/flux_sampling/4th_iteration_35kthinning/flux_sample_WT_750.csv')\n",
    "# wt_1500_df = pd.read_csv('./flux_results/flux_sampling/4th_iteration_35kthinning/flux_sample_WT_1500.csv')\n",
    "# tr_250_df = pd.read_csv('./flux_results/flux_sampling/4th_iteration_35kthinning/flux_sample_TR_250.csv')\n",
    "# tr_750_df = pd.read_csv('./flux_results/flux_sampling/4th_iteration_35kthinning/flux_sample_TR_750.csv')\n",
    "# tr_1500_df = pd.read_csv('./flux_results/flux_sampling/4th_iteration_35kthinning/flux_sample_TR_1500.csv')\n",
    "\n",
    "# #Define lists\n",
    "\n",
    "\n",
    "# sampling_list = [WT_250, WT_750, WT_1500, TR_250, TR_750, TR_1500]\n",
    "\n",
    "# df_list = [wt_250_df,\n",
    "# wt_750_df,\n",
    "# wt_1500_df,\n",
    "# tr_250_df,\n",
    "# tr_750_df,\n",
    "# tr_1500_df\n",
    "# ]\n",
    "\n",
    "# model_names = ['wt_250',\n",
    "# 'wt_750',\n",
    "# 'wt_1500',\n",
    "# 'tr_250',\n",
    "# 'tr_750',\n",
    "# 'tr_1500'\n",
    "#               ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8933ed40-a293-4137-90a5-f22f91d6119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from multiprocessing import Pool\n",
    "# from tqdm import tqdm\n",
    "# import cobra.flux_analysis.loopless\n",
    "\n",
    "# def apply_loopless_sampling(dataframe, model):\n",
    "#     # Create an empty list to store the flux solutions\n",
    "#     flux_solution_list = []\n",
    "\n",
    "#     # Generate a dictionary of flux solutions for each row in the dataframe\n",
    "#     for index, row in tqdm(dataframe.iterrows(), total=len(dataframe), desc=\"Processing rows\"):\n",
    "#         flux_solutions = {}\n",
    "\n",
    "#         for col in dataframe.columns:\n",
    "#             reaction = col\n",
    "#             # Get the value of the cell in the current row and column\n",
    "#             flux = row[col]\n",
    "\n",
    "#             # Add the reaction and flux to the dictionary\n",
    "#             flux_solutions[reaction] = flux\n",
    "\n",
    "#         # Run the \"loopless_solution\" function on the flux solutions dictionary\n",
    "#         loopless = loopless_solution(model, flux_solutions)\n",
    "\n",
    "#         # Append the loopless flux solutions to the list\n",
    "#         flux_solution_list.append(loopless.fluxes)\n",
    "\n",
    "#     # Create a DataFrame from the list of flux solutions\n",
    "#     flux_solution_df = pd.DataFrame(flux_solution_list, columns=dataframe.columns)\n",
    "\n",
    "#     # Reset the indices to numeric values\n",
    "#     flux_solution_df = flux_solution_df.reset_index(drop=True)\n",
    "\n",
    "#     return flux_solution_df\n",
    "\n",
    "\n",
    "# def loopless_solution(model, flux_solutions):\n",
    "\n",
    "#     loopless = cobra.flux_analysis.loopless.loopless_solution(model, flux_solutions)\n",
    "#     return loopless\n",
    "\n",
    "# def post_process_dfs():\n",
    "\n",
    "#     for i  in range(len(sampling_list)):\n",
    "#         model = sampling_list[i]\n",
    "#         df = df_list[i]\n",
    "#         model_name = model_names[i]\n",
    "\n",
    "#         directory = './flux_results/flux_sampling/4th_iteration_35kthinning/with_CCF/'\n",
    "\n",
    "#         if not os.path.exists(directory):\n",
    "#             print('writing dir')\n",
    "#             os.makedirs(directory)\n",
    "\n",
    "\n",
    "#         name_for_file = str('flux_sample_'+model_name+'_Loopless_FVA_35kT_CCF')\n",
    "\n",
    "\n",
    "\n",
    "#         print(f'working on {model_name}')\n",
    "        \n",
    "        \n",
    "#         ccf_sampling = apply_loopless_sampling(df, model)\n",
    "\n",
    "#         #Save post-processed samples to directory\n",
    "#         filepath = os.path.join(directory, name_for_file)\n",
    "#         ccf_sampling.to_csv(filepath, index=False)\n",
    "\n",
    "#         # print(f\"postprocessed flux samples saved to: {filepath}\")\n",
    "\n",
    "#         del model, df, model_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da2c4ab-ca43-4510-87eb-5a1b58aa424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# post_process_dfs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b10e5-c885-4c13-81c9-911f892789cc",
   "metadata": {},
   "source": [
    "Notes: needed to repeat sampling due to the following:\n",
    "- sampling matrices are too large to load, compensate with the use of thinning instead. Use specifications from Hermann et al (2020) which uses instead a thinning coefficient of 10000 instead of keeping all samples. My original parameters were n = 50000, batch size = 2000 and thinning = 500. \n",
    "- Maybe I should use a thinning coefficient of 100000 instead? Since my model has a number of dimensions one exponent higher than the previously benchmarked Arnold Model\n",
    "    - I've decided to run my model with a thinning coefficient of 25000. Hopefully autocorrelation and convergence wouldn't be much of an issue. Total samples would be equal in turn to 1.25e8 individual sampling points. \n",
    "\n",
    "- I needed to reparametrize samples considering that the objective function doesn't apply in flux sampling. INstead of adding an objective coefficient all demand reactions that output biomass are turned off except for \"DM_Phloem_BS\". What I need to do instead is re-parametrize it to allow photoassimilates to exit at that reaction rather than to others.\n",
    "- I'll save the format to \".npz\" instead of \"csv\" since I'm running out of memory whenever I'm loading it out of this script. I think the output of the model is sparse enough that I can instead use this format instead.\n",
    "    - Actually I can save my csv to a normal csv once since I can just adjust the thinning number instead of keeping all samples.\n",
    "\n",
    "- It is still a question whether my samples are uncorrelated or not. I will run the diagnostic tests after I finish running the rest of the scripts.\n",
    "\n",
    "\n",
    "\n",
    "Note: May 17 2023\n",
    "Flux sampling script was interrupted @ TR750 and was rerun at that point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae799577-6b2a-444f-9f90-aa72715e0ec2",
   "metadata": {},
   "source": [
    "Notes: \n",
    "OPTGP Is shown to be faster than ACHR and also converges faster\n",
    "\n",
    "Let's try with a 10 samples first with 10 batches\n",
    "\n",
    "I think the model is too large to be loaded into the flux sampler. \n",
    "\n",
    "It initialized after 30 minutes, let's try sampling na. \n",
    "\n",
    "It takes 1-2 hours at most to generate 2000 samples with a thinning coefficient of 10000. Extrapolating from that, we need probably 4-6 hours to generate 5000 samples with a TC of 20000. To keep things tractable I'll keep the thinning coefficient at 10000. I can just add more samples if needed.\n",
    "\n",
    "\n",
    "Things to add to the paper:\n",
    "\n",
    "\n",
    "Flux sampling is another constraints-based technique used for characterizing the null space of a given stoichiometric model, providing us insights on the flux distributions of a given metabolic model without the explicit definition of a given cellular objective. Not only does this technique offer advantages over conventional FBA and FVA where it allows researchers to determine the feasibility of solutions within a given defined range, as well as the distribution of these fluxes provided the model constaints.. The latter, in turn, allows statistical analysis to determine whether any given fluxes exist within a single probability distribution or not. This, in turn, allows a more direct comparison of fluxes and to adequately sample a solution space provided the constraints implemented in the model.\n",
    "\n",
    "The same constraints have been implemented as with the previous set-ups but with a modification with regards to how the objective functions are concerned. Unlike in pFBA where we can set a particular reaction as an objective, no such setting exists for flux sampling. Thus, this setup is in turn reliant on explicitly defined constraints that would define the n reaction-dimensional solution space. To parametrize this, we have turned off all biomass-related demands such as Coleoptile Biomass, Straw_Biomass and the \"DM_Phloem_M\" reaction to force the model to output flux to the \"DM_Phloem_BS\" reaction. Additionally, the model is constrained in a similar manner as with the previous pFBA setups that we had done to benchmark and assess our model's performance.\n",
    "\n",
    "THe benefits of using Flux Sampling compared to other methods such as FVA in characterizing a solution space is that:\n",
    "a. We may establish confidence intervals with the use of statistical tests to fully characterize a given solution space and whether\n",
    "b. Rather than simply generating representative fluxes showing the maximum and minimum amount of possible flux towards a particular reaction, flux sampling allows summary statistics to be generated, including the probability distribution of each particular reaction. \n",
    "c. Lastly, flux sampling allows a detailed comparison of the interdependence of each particular reaction, showing which reactions are coupled to each other in a positive and negative fashion. This is done\n",
    "\n",
    "Three setups per parametrized model were initialized, each with a representative light treatment of 250, 750 and 1500 PPFD with a defined range of +-25, respectively. The NGAM reactions were instead set at a static value at each representative light point detailed above. A total of 6 treatments were initialized to represent both the WT and Trans models at the selected light points. \n",
    "\n",
    "The sampling algorithm used was the OPTGP (optimized general parallel) sampler from the Cobrapy.sampling package. The sampler was parametrized to generate 5000 samples with a thinning coefficient of 25000, representing 1.25x10^8 sampling points, and was multithreaded into 7 processes each. Run times varied from between 3-6 hours per model parametrized, which was expected based on the number of reactions in the parametrized model.\n",
    "\n",
    "\n",
    "After the generation of individual sampling points, convergence statistics were done to assess the level of autocorrelation as well as to assess whether the samplers have sufficiently converged to a singular value. The former is done with the use of the \"acf\" function to assess the level of autocorrelation on each given column, while the latter is assessed with the use of two specific methods -- the Gelman-Rubin and the Geweke statistics. These are two methods that we will use to assess whether the number of sampling points is sufficient to ensure adequate convergence of each reaction in the model. Reactions that have not converged sufficiently will be indicated.\n",
    "\n",
    "After the assessment of autocorrelation and convergence, each of the pairs between light treatments (225-725, 725-1475, 225-1475) and between models (WT and Trans) are subjected to pairwise Kruskal-Wallis tests to assess which reaction pairs are derived from the same distribution. It is a non-parametric rank-based test test suitable for comparing outputs where there are no assumed distributions behind a population, and has been used in a similar fashion in previous flux sampling setups that involve Plant Metabolism  (Herrmann et al., 2019).  \n",
    "\n",
    "This procedure, in turn, allows us to deduce in finer detail which reactions in particular are positively correlated with CO2 flux into the BS cell's Rubisco reaction. In the previous pFBA experiment we were able to demonstrate a similar approach to this by performing a sensitivity analysis on Glycine Decarboxylase, and had demonstrated the negative relationship between M cell GLYDHD and BS Cell GLYDHD.\n",
    "\n",
    "Lastly, we can afterwards assess which fluxes are coupled by iterating over the list of fluxes in a single flux sample matrix and computing the spearman correlations between the pairwise comparisons. From here we can assess which particular reactions are positively or negatively correlated or not. A particular focus will then be held. Further Downstream analysis includes determination of reactions that are positively or negatively coupled with each other and corroborating this fact on whether the reaction is disrupted in the \"Trans\" parametrized model.  \n",
    "\n",
    "\n",
    "\n",
    "May 19, 2023\n",
    "Some observations on the fluxes obtained from initial flux sampling runs:\n",
    "- It seems it doesn't maximize CO2 assimilation as with pFBA. \n",
    "- It features some reactions with infeasibly large fluxes, particularly those expected to have flux cycling.\n",
    "\n",
    "I asked the Gitter group on what are their thoughts on how to approach this.\n",
    "\n",
    "One solution I think is this:\n",
    "- Reparametrize a model first and generate FVA solutions to \"pre-process\" the model, and in turn add directionality and bound constraints to the model to reduce its solution space further.\n",
    "- Try readding the objective function for photoassimilate generation as well as the pfba objective, as well as add the \"cyclefreeflux\" function by Desouki et al (2015).\n",
    "\n",
    "\n",
    "\n",
    "I am currently testing the Latter.\n",
    "\n",
    "May 20, 2023\n",
    "\n",
    "The latter does not work since it applies MILP, I think. It returns the following error:\n",
    "    \n",
    "    TypeError: Sampling does not work with integer problems.\n",
    "\n",
    "I will instead to the former instead. I've also implemented pruning to remove any unused reactions and metabolites based on the find_blocked_reactions() function of FVA. This will further constrain the model to sort of \"Contextualise\" it. \n",
    "\n",
    "\n",
    "May 20, 2023\n",
    "\n",
    "Based on the Geweke Statistic, and with a z-score of 1.96 (indicating 0.95 confidence  interval) most of the samples have converged on a single statistic. Based on the Gelman Rubin statistic however all of the reactions have not converged to a singular solution. Why?\n",
    "\n",
    "I've rerun the diagnostic scripts in R using Coda and have produced a more reliable measure of convergence and autocorrelation. In both cases only \n",
    "\n",
    "I'll test 5000x25000 samples with the reduced and pFVA-constrained models. I think sampling will be faster considering that I've pruned the samples as well as reduced the solution space by a lot. \n",
    "\n",
    "\n",
    "Flux sampling convergence statistics are based on the methods highlighted by Hermmann et al (2019) and by Fallahi et al (2020). It says that we shouldn't use the normal Gelman-Rubin statistic and instead use the Brooks-Gelman formulation instead.\n",
    "\n",
    "However, for both cases I've instead used the Raftery-Lewis statistic and \n",
    "the Geweke Diagnostic to assess convergences for all parameters. I decided to re-run instead the two last samples considering that they both have significant amounts of reactions that haven't converged based on the RL statistic and the GW statistic.\n",
    "\n",
    "For the RL statistic both 250 and 750 parametrized samplers have converged, although the Geweke diagnostic only reports a convergence rate of around 70 percent. In 1500 the convergence rate falls to 40 percent only which necessitates the re-run scenario. AFterwards I can simply re-run the scripts and re-assess my results. In the meantime however I can analyze both 250 and 750 scenarios as well the highb light scenarios particularly those with significantly varying distributions\n",
    "\n",
    "\n",
    "June 13, 2023\n",
    "\n",
    "I have rerun both WT andTR 1500 to validate if both have converged. If it hasn't I'll report the results as-is and include it in the discussion.\n",
    "\n",
    "June 15, 2023\n",
    "\n",
    "I have an idea in order to ensure convergence as well as to reduce runtimes.\n",
    "My idea is to remove all reactions that are not foundd in the model to 0 in order to reduce the nullspace of the model. This will be based on the initial runs for the flux sampling runs. \n",
    "\n",
    "Afterwards I need to compare their distributions based dun sa mga previous runs to determine if pareho yung distribution. If it is the same or virtually the samme I will use it because I can ensure that it has a higher convergence rate than the one with lower samples.\n",
    "\n",
    "If in case this works then it should return the same distribution and my samples would've converged faster. Furthermore there isn't need to go for breadth considering that my parametrizations are already fixed. Hopefully it can converge faster but since I've changed the thinning constant to 100k it may change the distribution.\n",
    "\n",
    "June 15 2023\n",
    "\n",
    "    Filtering and Increasing the thinning doesn't work apparently. It reduced the convergence rate of my reactions by almost 20 percent -- very alarming. What I should do instead is to increase the thinning coefficient to something more ok (around 35000) while still being relatively fast enough.\n",
    "\n",
    "    However I'll be re-running my sampling attempt in order to fix some errors with H2O cycling. (Change H2O flux to be unidirectional towards M cell to reflect transpiration mechanism. Before what happened was that )\n",
    "\n",
    "    Furthermore I fixed the flux bounds for Photon flux. Apparently I had a typo dun sa upper bounds nung TR_1500 which caused it to have 25 lesser flux than normal.\n",
    "\n",
    "    Hopefully at the end of this ok na siya. Wala na kong problem after nito -- analysis na lang.\n",
    "\n",
    "\n",
    "June 17, 2023\n",
    "\n",
    "I just discovered how inflated the flux values are for high light conditions, which indicate that there is significant looping in some of my solutions, which I need to reassess considering how central they are to my model, particularly yung reactions involving Malate.\n",
    "\n",
    "I can try to add Loopless FVA then compare the results with the normal runs. Kahit paspasan lang.\n",
    "\n",
    "\n",
    "# #Notes: June 17\n",
    "# #Adding the \"Loopless FVA\" parameter to the pre-processing step does not work and generates an infeasible solution. It causes the solver to become stuck.\n",
    "\n",
    "# #Note: it takes 30 minutes to implement Loopless FVA to the model. Upon checking yung mga flux bounds it reduces the max and min values to something closer to their pFBA counterparts. \n",
    "# #I'll try to rerun my pipeline to accomodate that.\n",
    "# #Note: Loopless FVA produces NaNs in the flux bounds of some reactions. Need to remove that.\n",
    "\n",
    "\n",
    "June 19, 2023:\n",
    "\n",
    "I think I've finally optimized my Sampling runs. I just need to rerun my scripts kahit 25000 thinning lang since increasing it didn't really affect yung convergence rates.\n",
    "\n",
    "\n",
    "Things I have tested (So far)\n",
    "- Filtering out reactions before sampling -- Convergence rates lower almost 20 percent accorss the board.\n",
    "- 10000 Thinning\n",
    "- 25000 Thinning\n",
    "- 35000 Thinning -- little improvement in convergence rates, in fact it lessened percent converged \n",
    "- Using add_loopless() function -- doesn't work, turns the model to an MILP problem which breaks Sampling\n",
    "- Loopless FVA to define reaction bounds == works so far but it breaks during actual sampling (cannot generate warmup points due to overconstrained model).\n",
    "- Using _add_cyclefree_flux() -- doesn't work, breaks the model and causes numerical instability.\n",
    "- LOopless FVA with \"relaxed option\" for NaNs --- I think this method works. Wala na kong nakikitang loops. However this method runs really slow (~2 hours)\n",
    "\n",
    "June 20, 2023\n",
    "- I have problems regarding sampling right now. Sigh. I don't even know the issue behind it rn it just breaks\n",
    "- I know now -- apparently using the loopless option overconstrains the model and prevents it from generating warmup points using the sampler. I didn't see that it works. Maybe it'll work if I modify the parametrization to a fraction of the optima instead?\n",
    "- What I can do is probably to post-process my flux samples using the \"loopless_solution\" method highlighted in Desouki et al's paper.\n",
    "    - This method works. I checked the values for CSm_M and it does deflate the values significantly.\n",
    "    - It looks like it might work -- however it is fairly slow when run in series. I'll try to run them in parallel\n",
    "        - Multiprocess now works but it keeps doing i/o operations on the models. Can it be modified to just do a single I/O operation?\n",
    "            It becomes stuck if I try it\n",
    "            \n",
    "                It's such a hassle to use multiprocess. I'll just run it on a single thread tutal mabilis lang naman. I'm wasting time on how to run it on a multithread e kaya naman ng isang thread.\n",
    "\n",
    "\n",
    "June 22, 2023\n",
    "\n",
    "- CycleFreeFlux destroys the uniform distribution of my flux solutions, preventing me from inferring any information based dun sa distributions nung fluxes. Therefore this shoul \n",
    "Pipeline breakdown:\n",
    "\n",
    "\n",
    "June 24, 2023\n",
    "\n",
    "I've revised the script so that it properly bypasses infeasibility issues now. Apparently the previous iteration didn't exactly resolve it. However, I've already computed the samples for WT_250 so I can skip that now -- it didn't have too many feasibility issues so I could skip over that.,\n",
    "\n",
    "Load CSVs to a memory saving format first\n",
    "\n",
    "1.\n",
    "Run convergence statistics on each and generate plots to assess total convergence stats for each CSV. These will include tests such as the \n",
    "Raftery-Lewis statistic and the Geweke statistics to assess both autocorrelation as well as assess convergence.\n",
    "\n",
    "Afterwards get only the flux names of those reactions that have converged\n",
    "Run pairwise Kruskal-wallis tests per CSV using the above list of converged reactions\n",
    "Identify each reaction with significant and non-significant distributions each\n",
    "\n",
    "June 28, 2023\n",
    "\n",
    "Need to rerun WT_750 and WT1500 due to numerical isseus. I'm not sure why it wasn't caught by the script but I have modified it \n",
    "\n",
    "\n",
    "\n",
    "Generate histograms/probability densities for relevant reactions with significantly different distributions with WT and Trans models.\n",
    "2. Flux coupling analysis\n",
    "Check which fluxes are coupled with each otehr and identify which fluxes are then related to each other, particularly Carbon Fixation reactions in the BS cell such as Rubisco and the DM_Phloem reactions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b412192-58d7-4665-b013-58b6a313e2fa",
   "metadata": {},
   "source": [
    "June 23, 2023\n",
    "Model still returns infeasible solution for the trans parametrized models. What to do?\n",
    "\n",
    "Implemented a solution that would catch all exceptions in the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
