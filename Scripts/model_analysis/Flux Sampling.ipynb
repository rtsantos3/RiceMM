{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03a656bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T11:08:41.205406Z",
     "start_time": "2023-03-23T11:08:39.074105Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "import cobra\n",
    "import libsbml\n",
    "import pandas as pd\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import memote\n",
    "import csv\n",
    "import pytest\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xlsxwriter\n",
    "import path \n",
    "import datetime\n",
    "import scipy.sparse as sp\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "\n",
    "from cobra import sampling\n",
    "from cobra import Reaction\n",
    "\n",
    "#Change working dir first, ty ChatGPT, much loves\n",
    "cwd = os.getcwd()\n",
    "# Split the path into a list of directories\n",
    "directories = cwd.split(os.sep)\n",
    "# Remove the last two directories from the list\n",
    "directories = directories[:-2]\n",
    "# Join the directories back into a path\n",
    "new_cwd = os.sep.join(directories)\n",
    "# Change the current working directory to the new path\n",
    "os.chdir(new_cwd)\n",
    "\n",
    "sys.path.append(\"./src\")\n",
    "\n",
    "import model_manipulation  as mm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19cbcb9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T11:14:41.725034Z",
     "start_time": "2023-03-23T11:11:53.801Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-05-09\n"
     ]
    }
   ],
   "source": [
    "#This codeblock is to define some of the functions used for modelling\n",
    "\n",
    "\n",
    "#Set solver to gurobi\n",
    "config = cobra.Configuration()\n",
    "config.solver = 'gurobi'\n",
    "\n",
    "#Read 2-cell model\n",
    "wt_model = cobra.io.read_sbml_model(\"./model/ios2164_2cell.xml\")\n",
    "trans_model = cobra.io.read_sbml_model(\"./model/ios2164_2cell.xml\")\n",
    "#Estimate inf\n",
    "inf = 1e6\n",
    "\n",
    "\n",
    "#Define linear relationship between PPFD and Cellular maintainance costs\n",
    "#This formula comes from Topfer et al (2020) where she defined NGAM in a linear relationship with incident light\n",
    "\n",
    "\n",
    "def generate_constraint(model,reaction, name, lb, ub):\n",
    "    reaction_fex = model.reactions.get_by_id(name).flux_expression\n",
    "    constraint = model.problem.Constraint(reaction_fex, lb=lb, ub=ub)\n",
    "    constraint.name = name + '_constraint'\n",
    "    model.add_cons_vars\n",
    "\n",
    "def compute_ngam_atp(ppfd):\n",
    "    v_atp = 0.0049*ppfd + 2.7851\n",
    "    return v_atp\n",
    "\n",
    "\n",
    "#This function is used to set the inputs to the model used. \n",
    "def define_model_medium(model, co2, o2, ppfd, \n",
    "                        medium_dir='./misc/photo_medium.csv', no3=inf, h2o=inf, h=inf, \n",
    "                        nh4=inf, pi=inf):\n",
    "    model_photo_media = mm.read_medium_csv(medium_dir, model)\n",
    "    model_photo_media['EX_no3(e)'] = no3\n",
    "    model_photo_media['EX_h2o(e)'] = h2o\n",
    "    model_photo_media['EX_h(e)'] = h\n",
    "    model_photo_media['EX_nh4(e)'] = nh4\n",
    "    model_photo_media['EX_co2(e)'] = co2\n",
    "    model_photo_media['EX_o2(e)'] = o2\n",
    "    model_photo_media['EX_photonVis(e)'] = ppfd\n",
    "    model_photo_media['EX_pi(e)'] = pi\n",
    "    #Set set model medium as model\n",
    "#     print('Added model medium')\n",
    "    return model_photo_media\n",
    "\n",
    "    \n",
    "def turn_off_cofac_cycles(model, inact_dir='./misc/leaf_inactivated.tsv'):\n",
    "    file = csv.reader(open(inact_dir), delimiter='\\t')\n",
    "    leaf_inactive_rxns = list()\n",
    "    for rows in file:\n",
    "        row_m = str()\n",
    "        row_bs = str()\n",
    "        for rxns in rows:\n",
    "            row_m += str(rxns) + \"_M\"\n",
    "            row_bs += str(rxns) + \"_BS\"\n",
    "        leaf_inactive_rxns.append(row_m)\n",
    "        leaf_inactive_rxns.append(row_bs)\n",
    "        \n",
    "    for rxns in model.reactions:\n",
    "        if rxns.id in leaf_inactive_rxns:\n",
    "            rxns.bounds = (0,0)\n",
    "#     print('Successfully turned off cofactor-cycling reactions')\n",
    "\n",
    "    \n",
    "# #Add constraints to model\n",
    "#This code block contains constraints that would simulate the assimilation rates of bs and m cells in a two-cell system (such as those seen near the midvein region of rice leaves)\n",
    "# #BS photon flux must be the same/less than M flux (Adapted from B&B, 2019)\n",
    "# photon_import = model.reactions.get_by_id(\"EX_photonVis(e)\")\n",
    "def add_tissue_constraints(model):\n",
    "    #For input fluxes for light, we will set the flux ratio to 10:1 to reflect the anatomical proportions of our model ()\n",
    "    \n",
    "    BS_photon_import = model.reactions.PRISM_white_LED_BS\n",
    "    M_photon_import = model.reactions.PRISM_white_LED_M\n",
    "\n",
    "    #Set photon flux ratio to 10:1\n",
    "    photon_flux = mm.set_fix_flux_ratio({M_photon_import.id:10, BS_photon_import.id:1},model)\n",
    "    model.add_cons_vars(photon_flux)\n",
    "\n",
    "    \n",
    "    #UPDATE: Change CO2 intake to the M Cell instead rather than set a ratio, which is a better assumption overall. Assume na lang that external gasses are assimilated\n",
    "    #Via the M cell.\n",
    "    #From Morrison et al 2005 -- Lateral diffusion of Gases is unlikely to support photosynthesis due to the\n",
    "    #assimilation of diffused CO2 in tissues prior to BS//\n",
    "    model.reactions.CO2tex_BS.bounds = (0,0)\n",
    "    model.reactions.O2tex_BS.bounds = (0,0)\n",
    "    \n",
    "    #UPDATE: This assumption does not hold considering that recent transcriptomic analysis confirms that \n",
    "    #the bundle sheath is involved in the assimilation of inorganic nutrients, including nitrogen (nitrates/ammonia), and \n",
    "    #Sulfates. In turn, this will be implemented by simply setting the exchanges to the M cell to 0. (Hua et al, 2021)\n",
    "    model.reactions.SO3tex_M.bounds = (0,0)\n",
    "    model.reactions.SO4tex_M.bounds = (0,0)\n",
    "    model.reactions.NH4tex_M.bounds = (0,0)\n",
    "    model.reactions.NO3tex_M.bounds = (0,0)\n",
    "    \n",
    "    #Model will also constraint H2O input to BS cell only as it is also assumed that BS tissue in rice is specialized for H2O transport (Hua et al. 2021)\n",
    "    #There is a demand reaction naman for H2O for the M cell which is not connected to the BS H2Otex\n",
    "    #Restrict H2O transport to be unidirectional from the BS cell\n",
    "    model.reactions.H2Otex_M.bounds = (0, 0)\n",
    "    model.reactions.h2o_pd.bounds = (-inf, 0)\n",
    "    \n",
    "    #need to turn off HCO import as the model incorrectly transfers fixed HCO to the BS cell via the common pool compartment\n",
    "    model.reactions.HCO3tex_M.bounds = (0,0)\n",
    "    model.reactions.HCO3tex_BS.bounds = (0,0)\n",
    "    \n",
    "    #No constraints will be implemented for H+ availability allowing the model to use protons on-demand.\n",
    "    \n",
    "    #Turn off other Demand reactions that may serve as sinks for the model except DM_Phloem_BS (Which represents the output of photoassimilate thru the BS cell\n",
    "    model.reactions.DM_Phloem_M.bounds = (0,0)\n",
    "    model.reactions.Straw_Biomass_M.bounds = (0,0)\n",
    "    model.reactions.Straw_Biomass_BS.bounds = (0,0)\n",
    "    model.reactions.Coleoptile_Biomass_M.bounds = (0,0)\n",
    "    model.reactions.Coleoptile_Biomass_BS.bounds = (0,0)\n",
    "    model.reactions.DM_Phloem_BS.bounds = (0, inf)\n",
    "    \n",
    "\n",
    "def add_enzyme_constraints(model, \n",
    "                           wt_pepc = 0, \n",
    "                           wt_mdh = 11.18, \n",
    "                           wt_nadp_me = 0.14, \n",
    "                           wt_ppdk=0.31,\n",
    "                          wt_CA=7.5):\n",
    "    \n",
    "    \n",
    "    # #This code block contains constraints specific for enzyme rate constraints\n",
    "    #This approach is derived from Bogart & Myers (2016) where they constrained the enzyme rate \n",
    "    #fluxes in each of the 2-cell segments to a specific upper bound while keeping the lower bound\n",
    "    #At 0. For reversible reactions the lower bounds are set to the same value\n",
    "    \n",
    "    \n",
    "    #PEPC constraint (Reaction id: PPCc)\n",
    "    #Need to constrain it to 0 since reaction is only detected in Vascular tissue\n",
    "    pepc_BS = model.reactions.PPCc_BS\n",
    "    pepc_M = model.reactions.PPCc_M\n",
    "    \n",
    "    pepc_BS.bounds = (0,0)\n",
    "    pepc_M.bounds = (0,0)\n",
    "\n",
    "    #PPDK constraints (Reaction id: PPDKs) (note that this is found in the chloroplast?) \n",
    "    #Not detected via immunolocalization but enzyme activity is detected\n",
    "\n",
    "    ppdks_BS = model.reactions.PPDKs_BS\n",
    "    ppdks_M = model.reactions.PPDKs_M\n",
    "    ppdkc_BS = model.reactions.PPDKc_BS\n",
    "    ppdkc_M = model.reactions.PPDKc_M\n",
    "    wt_ppdks_cons = model.problem.Constraint(ppdks_BS.flux_expression \n",
    "                                             + ppdks_M.flux_expression\n",
    "                                             + ppdkc_BS.flux_expression\n",
    "                                             + ppdkc_M.flux_expression, \n",
    "                                             lb = 0, ub = wt_ppdk)\n",
    "    wt_ppdks_cons.name = 'wt_ppdks_cons'\n",
    "    model.add_cons_vars(wt_ppdks_cons)\n",
    "    #Malate Dehydrogenase \n",
    "    #Only mitochondrial in WT Rice M cells\n",
    "    mdhm_M = model.reactions.MDHm_M\n",
    "\n",
    "\n",
    "    wt_mdh_cons = model.problem.Constraint(mdhm_M.flux_expression,\n",
    "                                           lb= 0, ub=wt_mdh)\n",
    "    wt_mdh_cons.name = \"wt_mdh_cons\"\n",
    "    model.add_cons_vars(wt_mdh_cons)\n",
    "\n",
    "    #NADP-ME (Since no signal is detected in WT, no locational constraints are imposed)\n",
    "    #Let's see if I can force it to have a small amount of flux \n",
    "    nadp_me_M = model.reactions.MDHys_M\n",
    "    nadp_me_BS = model.reactions.MDHys_BS\n",
    "\n",
    "    wt_nadpme_cons = model.problem.Constraint(nadp_me_M.flux_expression\n",
    "                                             + nadp_me_BS.flux_expression,\n",
    "                                             lb= 0, ub=wt_nadp_me)\n",
    "    wt_nadpme_cons.name = \"wt_nadpme_cons\"\n",
    "    model.add_cons_vars(wt_nadpme_cons)\n",
    "\n",
    "\n",
    "    #I should add constraints for Carbonic Anhydrase\n",
    "    #I should constrain it to 0.4 ubar, which would constitute ambient CO2 partial pressure\n",
    "    #Flux is reversible so constraints are bi-directional\n",
    "    #This should be revised considering that it allows reversible reactions  and an abnormally high flux thru carbonic anhydrase, which shouldn't be the case\n",
    "\n",
    "    hco3es_m = model.reactions.HCO3Es_M.flux_expression\n",
    "    hco3ec_m = model.reactions.HCO3Ec_M.flux_expression\n",
    "    hco3em_m = model.reactions.HCO3Em_M.flux_expression\n",
    "    hco3es_bs = model.reactions.HCO3Es_BS.flux_expression\n",
    "    hco3ec_bs = model.reactions.HCO3Ec_BS.flux_expression\n",
    "    hco3em_bs = model.reactions.HCO3Em_BS.flux_expression\n",
    "\n",
    "    ca_cons = model.problem.Constraint(hco3es_m + hco3ec_m + hco3em_m \n",
    "                                       + hco3es_bs + hco3ec_bs + hco3em_bs,\n",
    "                                      lb = -wt_CA, ub = wt_CA)\n",
    "    ca_cons.name = 'Carbonic_anhydrase_constraint'\n",
    "    model.add_cons_vars(ca_cons)\n",
    "\n",
    "\n",
    "    #Rbcl constaints\n",
    "    #Retrieve flux expressions oof each RBCl reaction\n",
    "    rbpc_M = model.reactions.RBPCs_M.flux_expression\n",
    "    rbpc_BS = model.reactions.RBPCs_BS.flux_expression\n",
    "    rbpo_M = model.reactions.RBPOs_M.flux_expression\n",
    "    rbpo_BS = model.reactions.RBPOs_BS.flux_expression\n",
    "\n",
    "    #Constraint such that it is limited to 132 umol m-2 s-1\n",
    "    rbcl_vcmax_cons = model.problem.Constraint(rbpc_M + rbpc_BS, lb = 0, ub= 132)\n",
    "    rbcl_vcmax_cons.name='rbcl_vcmax_cons'\n",
    "    model.add_cons_vars(rbcl_vcmax_cons)\n",
    "    #Constraints for rbcl flux such that v_c/v_o = 3 or higher.\n",
    "    rbcl_vcvo = model.problem.Constraint(3*(rbpo_M + rbpo_BS) \n",
    "                                         - 1*(rbpc_M + rbpc_BS),\n",
    "                                         lb=0,ub=1000)\n",
    "    rbcl_vcvo.name = 'rbcl_vc/vo_ratio'\n",
    "    model.add_cons_vars(rbcl_vcvo)\n",
    "\n",
    "    #Turn off the RBPC2s reactions since we already defined the constraints above\n",
    "    model.reactions.RBPC2s_M.bounds = (0,0)\n",
    "    model.reactions.RBPC2s_BS.bounds = (0,0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #What if I simply constrained that of the M cell one to 3:1?\n",
    "    #This constraint is pretty good actually. \n",
    "    #This allows the system to be set at a specific Vc/Vo rate while still allowing local variation \n",
    "    #wherein Rubisco may act in an uncoupled fashion and may have favorable internal vc/vo rates.\n",
    "# #This code block is to set a constraint such that M-to-BS cell NGAM ratio is 10-to-1 \n",
    "# #Similar to what Moreno-Villena et al (2022) had done \n",
    "\n",
    "#This function takes two arguments: the model and the maximal  ppfd input to the system\n",
    "def add_ngam_cons(model, ppfd): \n",
    "    ngam_atp_m = mm.get_rxn(model, 'ngam_atp_c_M')\n",
    "    ngam_atp_bs = mm.get_rxn(model, 'ngam_atp_c_BS')\n",
    "    ngam_atp_m.bounds = (0,inf)\n",
    "    ngam_atp_bs.bounds = (0,inf)\n",
    "    ngam_ratio = mm.set_fix_flux_ratio({ngam_atp_m.id:10, ngam_atp_bs.id:1}, model)\n",
    "    ngam_ratio.name = 'ngam_BS/M_ratio'\n",
    "    model.add_cons_vars(ngam_ratio)\n",
    "\n",
    "    #Retrieve NGAM reactions\n",
    "    ngam_nadphox_c_M = mm.get_rxn(model, 'ngam_nadphox_c_M')\n",
    "    ngam_nadphox_s_M = mm.get_rxn(model, 'ngam_nadphox_s_M')\n",
    "    ngam_nadphox_m_M = mm.get_rxn(model, 'ngam_nadphox_m_M')\n",
    "    ngam_nadphox_c_BS = mm.get_rxn(model, 'ngam_nadphox_c_BS')\n",
    "    ngam_nadphox_s_BS = mm.get_rxn(model, 'ngam_nadphox_s_BS')\n",
    "    ngam_nadphox_m_BS = mm.get_rxn(model, 'ngam_nadphox_m_BS')\n",
    "\n",
    "\n",
    "    #Set Fixed fluxes\n",
    "    nadphox_c_s_M = mm.set_fix_flux_ratio({ngam_nadphox_c_M.id:1, ngam_nadphox_s_M.id:1},model)\n",
    "    nadphox_c_s_M.name = \"nadphox_cs_ratio_M\"\n",
    "    nadphox_s_m_M = mm.set_fix_flux_ratio({ngam_nadphox_s_M.id:1, ngam_nadphox_m_M.id:1}, model)\n",
    "    nadphox_s_m_M.name = \"nadphox_sm_ratio_M\"\n",
    "\n",
    "    nadphox_c_s_BS = mm.set_fix_flux_ratio({ngam_nadphox_c_BS.id:1, ngam_nadphox_s_BS.id:1},model)\n",
    "    nadphox_c_s_BS.name = \"nadphox_cs_ratio_BS\"\n",
    "    nadphox_s_m_BS = mm.set_fix_flux_ratio({ngam_nadphox_s_BS.id:1, ngam_nadphox_m_BS.id:1}, model)\n",
    "    nadphox_s_m_BS.name = \"nadphox_sm_ratio_BS\"\n",
    "\n",
    "    #Add constraints\n",
    "    model.add_cons_vars(nadphox_c_s_M)\n",
    "    model.add_cons_vars(nadphox_s_m_M)\n",
    "    model.add_cons_vars(nadphox_c_s_BS)\n",
    "    model.add_cons_vars(nadphox_s_m_BS)\n",
    "\n",
    "    #Retrieve flux expressionns\n",
    "    fex_nadphox_c_M =  mm.get_flux_exp(model, ngam_nadphox_c_M)\n",
    "    fex_nadphox_s_M = mm.get_flux_exp(model, ngam_nadphox_s_M)\n",
    "    fex_nadphox_m_M = mm.get_flux_exp(model, ngam_nadphox_m_M)\n",
    "\n",
    "    fex_nadphox_c_BS =  mm.get_flux_exp(model, ngam_nadphox_c_BS)\n",
    "    fex_nadphox_s_BS =  mm.get_flux_exp(model, ngam_nadphox_s_BS)\n",
    "    fex_nadphox_m_BS =  mm.get_flux_exp(model, ngam_nadphox_m_BS)\n",
    "\n",
    "    fex_atp_c_M = mm.get_flux_exp(model, ngam_atp_m)\n",
    "    fex_atp_c_BS =  mm.get_flux_exp(model, ngam_atp_bs)\n",
    "\n",
    "    #Set the constraint between ATP:NADPH NGAM to 3:1\n",
    "    nadphox_atpase = model.problem.Constraint(3*(fex_nadphox_c_M + fex_nadphox_s_M + fex_nadphox_m_M\n",
    "                                                       + fex_nadphox_c_BS + fex_nadphox_s_BS + fex_nadphox_m_BS) \n",
    "                                         - 1*(fex_atp_c_M + fex_atp_c_BS),\n",
    "                                         lb=0,ub=0)\n",
    "    nadphox_atpase.name = \"nadphox_atpase_ratio\"\n",
    "    model.add_cons_vars(nadphox_atpase)\n",
    "    #Compute NGAM value and add constraint as a lower bound/upper bound to model\n",
    "    ngam_value = compute_ngam_atp(ppfd)\n",
    "    ngam_cons = model.problem.Constraint(fex_atp_c_M + \n",
    "                                        fex_atp_c_BS, lb=ngam_value, ub=ngam_value)\n",
    "    ngam_cons.name = 'NGAM_ATP_constraint'\n",
    "    model.add_cons_vars(ngam_cons)\n",
    "    \n",
    "#This code  block gives a snapshot of the relevant fluxes on each of the cell types based on the saved sample_fluxes values above\n",
    "\n",
    "def print_summary(model, sample_fluxes_df):\n",
    "    print('rbcl M cell: ', sample_fluxes['RBPCs_M'], 'rbcl BS cell: ',sample_fluxes['RBPCs_BS'])\n",
    "    print('rbcl M cell (photorespiration)', sample_fluxes['RBPOs_M'], 'rbcl BS cell (PR)', sample_fluxes['RBPOs_BS'])\n",
    "    print('vc/vo M:', sample_fluxes['RBPCs_M']/sample_fluxes['RBPOs_M'], 'vc/vo BS:', sample_fluxes['RBPCs_BS']/sample_fluxes['RBPOs_BS'])\n",
    "    print('RBPC2s_M', sample_fluxes['RBPC2s_M'], 'RBPC2s_BS', sample_fluxes['RBPC2s_BS'])\n",
    "    print('PEPC M', sample_fluxes['PPCc_M'], 'PEPC BS', sample_fluxes['PPCc_BS'])\n",
    "    print('Carbonic Anhydrase (Cytosolic) M', sample_fluxes['HCO3Ec_M'], 'Carbonic Anhydrase (Cytosolic) BS', sample_fluxes['HCO3Ec_BS'])\n",
    "    print('NADP-ME M', sample_fluxes['MDHys_M'], 'NADP-ME BS', sample_fluxes['MDHys_BS'])\n",
    "    print('Biomass M: ', sample_fluxes['Straw_Biomass_M'], 'Biomass BS', sample_fluxes['Straw_Biomass_BS'])\n",
    "    print('Phloem M: ', sample_fluxes['DM_Phloem_M'], 'Phloem BS', sample_fluxes['DM_Phloem_BS'])\n",
    "    print('co2 consumption M', sample_fluxes['CO2tex_M'], 'co2 consumption BS', sample_fluxes['CO2tex_BS'])\n",
    "    print('o2 consumption M', sample_fluxes['O2tex_M'], 'o2 consumption BS', sample_fluxes['O2tex_BS'])\n",
    "    print('Photosystem II M', sample_fluxes['PSIINC_M'], 'PSII BS', sample_fluxes['PSIINC_BS'])\n",
    "    print('PSI M', sample_fluxes['PSIMR_M'], 'PSI BS', sample_fluxes['PSIMR_BS'])\n",
    "    print('PPFD M: ', sample_fluxes['PRISM_white_LED_M'], 'PPFD BS: ', sample_fluxes['PRISM_white_LED_BS'])\n",
    "    print('ATP synthesis (stromal) M', sample_fluxes['ATPSs_M'], 'ATP synthase (mit) M', sample_fluxes['ATPSm_M'])\n",
    "    pd_rxn = [x for x in model.reactions if \"pd\" in x.id and \"h2o\" not in x.id]\n",
    "    pd_abs_flux = 0\n",
    "    for pds in pd_rxn:\n",
    "        pd_abs_flux += abs(sample_fluxes[pds.id])\n",
    "    \n",
    "    print('pd_abs_flux: ', pd_abs_flux)\n",
    "    \n",
    "#initialize list of transgenic reactions to add  to model\n",
    "\n",
    "def add_trans_reactions(model):\n",
    "    '''\n",
    "    This function is used to add a number of new tissue-specific reactions that were not present in the\n",
    "    original model to facilitate modelling of the transgenic C4 rice\n",
    "    '''\n",
    "    trans_list = list()\n",
    "    #Transgenic PEPC copy\n",
    "    #PEPC = Chloroplastic in M & V (rxn id: PPCc)\n",
    "    trans_ppcs = Reaction('trans_PPCs_M')\n",
    "    trans_ppcs.name = \"Phosphoenolpyruvate carboxylase, plastidic (Transgenic)\"\n",
    "    \n",
    "    pep_s0 = model.metabolites.pep_s0\n",
    "    hco3_s0 = model.metabolites.hco3_s0\n",
    "    oaa_s0 = model.metabolites.oaa_s0\n",
    "    pi_s0 = model.metabolites.pi_s0\n",
    "\n",
    "\n",
    "    #Add metabolites, bounds, and subsystem\n",
    "    trans_ppcs.add_metabolites({hco3_s0:-1, pep_s0:-1, oaa_s0:1, pi_s0:1})\n",
    "    trans_ppcs.bounds= model.reactions.PPCc_M.bounds\n",
    "    trans_ppcs.subsystem = model.reactions.PPCc_M.subsystem\n",
    "\n",
    "    trans_list.append(trans_ppcs)\n",
    "\n",
    "\n",
    "    #Transgenic PPDK Copy\n",
    "    #Since it already exists I'll just copy and readd it\n",
    "    trans_ppdks_m = Reaction('trans_PPDKs_M')\n",
    "    trans_ppdks_m.add_metabolites(model.reactions.PPDKs_M.metabolites)\n",
    "    trans_ppdks_m.bounds = model.reactions.PPDKs_M.bounds\n",
    "    trans_ppdks_m.name = \"Pyruvate phosphate dikinase, plastidic (Transgenic)\"\n",
    "\n",
    "    trans_ppdks_bs = Reaction('trans_PPDKs_BS')\n",
    "    trans_ppdks_bs.add_metabolites(model.reactions.PPDKs_BS.metabolites)\n",
    "    trans_ppdks_bs.bounds = model.reactions.PPDKs_BS.bounds\n",
    "    trans_ppdks_bs.name = \"Pyruvate phosphate dikinase, plastidic (Transgenic)\"\n",
    "\n",
    "    trans_list.append(trans_ppdks_m)\n",
    "    trans_list.append(trans_ppdks_bs)\n",
    "\n",
    "\n",
    "    #Transgenic NADP-ME\n",
    "    #NADP-ME = Mitochondrial in M\n",
    "    trans_nadp_me = Reaction('trans_MDHym_M')\n",
    "\n",
    "    #retrieve reactants\n",
    "    mal_m0 = model.metabolites.get_by_id('mal-L_m0')\n",
    "    nadp_m0 = model.metabolites.nadp_m0\n",
    "    h_m0 = model.metabolites.h_m0\n",
    "    nadph_m0 = model.metabolites.nadph_m0\n",
    "    oaa_m0 = model.metabolites.oaa_m0\n",
    "\n",
    "    #Add to rxn\n",
    "    trans_nadp_me.add_metabolites({mal_m0:-1, nadp_m0:-1, h_m0:1, nadph_m0:1, oaa_m0:1})\n",
    "    #Add bounds\n",
    "    trans_nadp_me.bounds=(-inf, inf)\n",
    "\n",
    "    trans_list.append(trans_nadp_me)\n",
    "\n",
    "\n",
    "    #Malate Dehydrogenase, mitochondrial (M cell)\n",
    "    trans_MDHm_M = Reaction('trans_MDHm_M')\n",
    "    trans_MDHm_M.name = 'Malate Dehydrogenase, Mitochondrial'\n",
    "    trans_MDHm_M.add_metabolites(model.reactions.MDHm_M.metabolites)\n",
    "    trans_MDHm_M.subsystem = model.reactions.MDHm_M.subsystem\n",
    "\n",
    "    trans_list.append(trans_MDHm_M)\n",
    "\n",
    "    #Malate dehydrogenase, plastidic (M cell)\n",
    "    trans_MDHs_M = Reaction('trans_MDHs_M')\n",
    "    trans_MDHs_M.name = 'Malate Dehydrogenase, Plastidic'\n",
    "    trans_MDHs_M.add_metabolites(model.reactions.MDHs_M.metabolites)\n",
    "    trans_MDHs_M.subsystem = model.reactions.MDHs_M.subsystem\n",
    "\n",
    "    trans_list.append(trans_MDHs_M)\n",
    "\n",
    "    #Malate dehydrogenase, plastidic(BS Cell)\n",
    "    trans_MDHs_BS = Reaction('trans_MDHs_BS')\n",
    "    trans_MDHs_BS.name = 'Malate Dehydrogenase, Plastidic'\n",
    "    trans_MDHs_BS.add_metabolites(model.reactions.MDHs_BS.metabolites)\n",
    "    trans_MDHs_BS.subsystem = model.reactions.MDHs_BS.subsystem\n",
    "\n",
    "    trans_list.append(trans_MDHs_BS)\n",
    "\n",
    "\n",
    "    #Trans CA\n",
    "    #Cytosolic in M\n",
    "    trans_hco3ec_M = Reaction('trans_hco3ec_M')\n",
    "    trans_hco3ec_M.name = 'carbonic anhydrase, cytosolic'\n",
    "    trans_hco3ec_M.add_metabolites(model.reactions.HCO3Ec_M.metabolites)\n",
    "    trans_hco3ec_M.bounds = model.reactions.HCO3Ec_M.bounds\n",
    "\n",
    "    trans_hco3ec_M.subsystem = model.reactions.HCO3Ec_M.subsystem\n",
    "    trans_list.append(trans_hco3ec_M)\n",
    "\n",
    "\n",
    "    #Bulk add to model\n",
    "    model.add_reactions(trans_list)\n",
    "    \n",
    "    model.repair()\n",
    "####ADDING TRANS CONSTRAINTS\n",
    "\n",
    "def add_trans_constraints(model,\n",
    "                         trans_pepc_rates = 7.01,\n",
    "                         trans_ppdks_rates = 3.66,\n",
    "                         trans_mdh_rates = 152.87,\n",
    "                         trans_nadp_me_rates = 0.60,\n",
    "                         trans_CA_rates = 8):\n",
    "    '''\n",
    "    This function is used to add another layer of constraints to parametize model based on the\n",
    "    Enzyme reaction rates assayed from Ermakova et al (2021) where the locations are based on the \n",
    "    each of the transgenic enzyme's tissue-specific localizations. \n",
    "    '''\n",
    "    \n",
    "    #PEPC constraint\n",
    "    wt_PPCc_M = mm.get_rxn(model, 'PPCc_M')\n",
    "    wt_PPCc_BS = mm.get_rxn(model, 'PPCc_BS')\n",
    "    trans_PPCs_M = mm.get_rxn(model, 'trans_PPCs_M')                           \n",
    "    trans_PEPC_cons = model.problem.Constraint(trans_PPCs_M.flux_expression\n",
    "                                            +wt_PPCc_BS.flux_expression \n",
    "                                            + wt_PPCc_M.flux_expression, \n",
    "                                            lb = 0, ub = trans_pepc_rates)\n",
    "\n",
    "    model.add_cons_vars(trans_PEPC_cons)\n",
    "\n",
    "    #PPDK constraint\n",
    "    trans_PPDKs_M  = mm.get_rxn(model, 'trans_PPDKs_M')\n",
    "    trans_PPDKs_BS = mm.get_rxn(model, 'trans_PPDKs_BS')\n",
    "    wt_PPDKs_M = mm.get_rxn(model, 'PPDKs_M')\n",
    "    wt_PPDKs_BS = mm.get_rxn(model, 'PPDKs_BS')\n",
    "    \n",
    "    trans_PPDKs_cons = model.problem.Constraint( \n",
    "        trans_PPDKs_BS.flux_expression + trans_PPDKs_M.flux_expression \n",
    "        +wt_PPDKs_BS.flux_expression + wt_PPDKs_M.flux_expression, \n",
    "                                             lb = 0, ub = trans_ppdks_rates)\n",
    "    trans_PPDKs_cons.name = 'trans_ppdks_cons'\n",
    "    model.add_cons_vars(trans_PPDKs_cons)\n",
    "\n",
    "\n",
    "    #Malate Dehydrogenase Constraints\n",
    "    trans_MDHm_M = mm.get_rxn(model, 'trans_MDHm_M')\n",
    "    trans_MDHs_M = mm.get_rxn(model, 'trans_MDHs_M')\n",
    "    trans_MDHs_BS = mm.get_rxn(model, 'trans_MDHs_BS')\n",
    "    wt_MDHm_M =  mm.get_rxn(model, 'MDHm_M')\n",
    "    wt_MDHs_M = mm.get_rxn(model, 'MDHs_M')\n",
    "    wt_MDHs_BS = mm.get_rxn(model, 'MDHs_BS')\n",
    "    \n",
    "    trans_mdh_cons =  model.problem.Constraint(\n",
    "       trans_MDHm_M.flux_expression + \n",
    "        wt_MDHm_M.flux_expression + \n",
    "        trans_MDHs_M.flux_expression + \n",
    "        trans_MDHs_BS.flux_expression +\n",
    "        wt_MDHs_BS.flux_expression +\n",
    "        wt_MDHs_M.flux_expression, \n",
    "        lb= 0, ub=trans_mdh_rates)\n",
    "\n",
    "    trans_mdh_cons.name = \"trans_mdh_cons\"\n",
    "    model.add_cons_vars(trans_mdh_cons)\n",
    "\n",
    "    #Add NADP-ME constraints\n",
    "    trans_MDHym_M = mm.get_rxn(model, 'trans_MDHym_M')\n",
    "    wt_MDHys_M = mm.get_rxn(model, 'MDHys_M')\n",
    "    wt_MDHys_BS = mm.get_rxn(model, 'MDHys_BS')\n",
    "    \n",
    "    trans_nadpme_cons = model.problem.Constraint(\n",
    "        trans_MDHym_M.flux_expression + \n",
    "        wt_MDHys_M.flux_expression + \n",
    "        wt_MDHys_BS.flux_expression,\n",
    "        lb= 0, ub=trans_nadp_me_rates)\n",
    "    \n",
    "    trans_nadpme_cons.name = \"trans_nadpme\"\n",
    "    model.add_cons_vars(trans_nadpme_cons)\n",
    "\n",
    "    #Add carbonic anhydrase constraints\n",
    "\n",
    "    trans_hco3ec_M = mm.get_rxn(model, 'trans_hco3ec_M')\n",
    "    wt_hco3ec_M = mm.get_rxn(model, 'HCO3Ec_M')\n",
    "    wt_hco3em_M = mm.get_rxn(model, 'HCO3Em_M')\n",
    "    wt_hco3es_M = mm.get_rxn(model, 'HCO3Es_M')\n",
    "    wt_hco3ec_BS = mm.get_rxn(model, 'HCO3Ec_BS')\n",
    "    wt_hco3em_BS = mm.get_rxn(model, 'HCO3Em_BS')\n",
    "    wt_hco3es_BS = mm.get_rxn(model, 'HCO3Es_BS')\n",
    "    \n",
    "    trans_ca_cons = model.problem.Constraint(trans_hco3ec_M.flux_expression + \n",
    "                                             wt_hco3es_M.flux_expression + \n",
    "                                             wt_hco3ec_M.flux_expression + \n",
    "                                             wt_hco3em_M.flux_expression + \n",
    "                                             wt_hco3es_BS.flux_expression + \n",
    "                                             wt_hco3ec_BS.flux_expression + \n",
    "                                             wt_hco3em_BS.flux_expression,\n",
    "                                      lb = -trans_CA_rates, ub = trans_CA_rates)\n",
    "    trans_ca_cons.name = 'Trans_CA_cons'\n",
    "    model.add_cons_vars(trans_ca_cons)\n",
    "    model.repair()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24d08460-95dc-4dea-ae6e-a7c85ca4122e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_flux_samples(model, num_samples, batch_size, output_filename ,thinning,output_dir='./flux_results/flux_sampling/'):\n",
    "    #This function is used to initialize a flux sampler and afterwards generate a csv file containing the sample solutions.\n",
    "    #default batch size is 1000\n",
    "\n",
    "    #Generate sampler\n",
    "    print(\"generating sampler for model\")\n",
    "    sampler = sampling.OptGPSampler(model, processes=7, thinning=thinning)\n",
    "    print(\"done generating OPTGP sampler\")\n",
    "    \n",
    "    \n",
    "    #Define output file\n",
    "    output_dir = str(output_dir)\n",
    "    output_filename = str(output_filename)\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    print('saving output to ', f\"{output_dir}/{output_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(num_samples // batch_size):\n",
    "        print(f\"Generating batch {i+1}/{num_samples//batch_size}\")\n",
    "        samples = sampler.sample(n=batch_size)\n",
    "        df = pd.DataFrame(samples, columns=model.reactions.list_attr(\"id\"))\n",
    "        if i == 0:\n",
    "            df.to_csv(f\"{output_dir}/{output_filename}\", index=False)\n",
    "        else:\n",
    "            df.to_csv(f\"{output_dir}/{output_filename}\", index=False, header=False, mode=\"a\")\n",
    "#             \n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "def parametrize_model(model, ppfd_low, ppfd_high, co2,if_trans, fva_bounds_file=''):\n",
    "    \n",
    "    print('start time for parametrize_model(): ' ,datetime.datetime.now())\n",
    "\n",
    "    #Generates a parametrized model which returns the constrained model as a callable object.\n",
    "    \n",
    "    #Copy model \n",
    "    model_instance = model.copy()\n",
    "                                                                                                                                                                                                                                \n",
    "    model_instance.medium = define_model_medium(model_instance, co2=co2, o2=inf, ppfd=inf, h=inf, nh4=inf, no3=inf)\n",
    "    turn_off_cofac_cycles(model_instance)\n",
    "    add_tissue_constraints(model_instance)\n",
    "    add_enzyme_constraints(model_instance)\n",
    "\n",
    "    #Adds NGAM (Computed as an average between the high and low instead of directly constraining it to the model, w/c makes the problem non-linear)\n",
    "    add_ngam_cons(model_instance, (ppfd_high+ppfd_low)/2)\n",
    "    \n",
    "    #Constrain PPFD range to indicated value\n",
    "    model_instance.reactions.get_by_id('EX_photonVis(e)').bounds = (-1*ppfd_high, -1*ppfd_low)\n",
    "    \n",
    "\n",
    "    #Check if trans then add constraints if true\n",
    "    if if_trans==True:\n",
    "        add_trans_reactions(model_instance)\n",
    "        add_trans_constraints(model_instance)\n",
    "    \n",
    "    \n",
    "    #Readd objective coefficient, maybe it'll work?\n",
    "    model_instance.reactions.get_by_id('DM_Phloem_BS').objective_coefficient = 1\n",
    "    \n",
    "    #Run FVA to preprocess the model to fix reaction reversibilities as well as to ensure that there are no \"extreme\" fluxes in the final sampling\n",
    "    # Perform Flux Variability Analysis (FVA)\n",
    "    #This step constrains the upper and lower bounds to the detected \"Maximal\" and \"minimal\" fluxes given an objective\n",
    "    #The default fraction of optimum will be implemented\n",
    "    #Will implement pFBA factor to constrain the model to 110% of the detected lowest flux \n",
    "\n",
    "    \n",
    "#     # #Let's try adding loopless FBA (june 17, 2023) - Remove if it doesn't wokr\n",
    "#     print('adding loopless to model instance')\n",
    "#     cobra.flux_analysis.add_loopless(model_instance, zero_cutoff=1e-7)\n",
    "#     #Doesn't wotk\n",
    "\n",
    "\n",
    "    #Initialize filter list for removal \n",
    "    filter_list=list()\n",
    "    \n",
    "    #flux_variability_analysis produces a Pandas Dataframe that can be taken apart and applied to the model_instance as direct bounds. \n",
    "    \n",
    "    print('computing Loopless FVA to model')\n",
    "    if fva_bounds_file:\n",
    "        fva_result = pd.read_csv(fva_bounds_file, index_col=0)\n",
    "        fva_result.columns = ['minimum', 'maximum']\n",
    "        \n",
    "        for rxn in model_instance.reactions:\n",
    "            if rxn.id not in fva_result.index:\n",
    "                filter_list.append(rxn.id)\n",
    "\n",
    "            \n",
    "        \n",
    "    else:\n",
    "        fva_result = cobra.flux_analysis.flux_variability_analysis(model_instance, loopless=True, pfba_factor=1.1, processes=7)\n",
    "\n",
    "    \n",
    "    # Set FVA constraints in the model\n",
    "    print('setting FVA constraints to model')\n",
    "    \n",
    "    tol = model_instance.tolerance\n",
    "    \n",
    "    \n",
    "    for reaction_id, bounds in fva_result.iterrows():\n",
    "        reaction = model_instance.reactions.get_by_id(reaction_id)        \n",
    "        # Check if FVA results have NaNs or has 0 bounds. If it does it removes it from the model\n",
    "        if (bounds['minimum']==0 and bounds['maximum']==0) or bounds.isnull().any():\n",
    "            filter_list.append(reaction_id)\n",
    "\n",
    "        \n",
    "        \n",
    "        # Check which is higher or lower to avoid Value errors\n",
    "        lower_bound = float(min(bounds['minimum'], bounds['maximum']))\n",
    "        upper_bound = float(max(bounds['minimum'], bounds['maximum']))\n",
    "        reaction.bounds = (lower_bound, upper_bound)\n",
    "            \n",
    "    \n",
    "\n",
    "        \n",
    "    #    # Identify and prune blocked reactions\n",
    "#     #I don't think this is necessary anymore since I'm filtering the reactions anyway\n",
    "#     blocked_reactions = cobra.flux_analysis.variability.find_blocked_reactions(model_instance, processes=7, zero_cutoff=tol)\n",
    "#     model_instance.remove_reactions(blocked_reactions)\n",
    "    \n",
    "    \n",
    "    #Remove reactions that are not in the filtered list\n",
    "\n",
    "\n",
    "    \n",
    "    print('reactions number (before pruning): ', len(model_instance.reactions))\n",
    "    model_instance.remove_reactions(filter_list)\n",
    "    print('reactions number (after pruning): ', len(model_instance.reactions))\n",
    "    \n",
    "    # Identify unneeded metabolites\n",
    "    unneeded_metabolites = []\n",
    "    for metabolite in model.metabolites:\n",
    "        if metabolite.reactions == []:\n",
    "            unneeded_metabolites.append(metabolite)\n",
    "\n",
    "    # Remove unneeded metabolites from the model\n",
    "    model.remove_metabolites(unneeded_metabolites)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('end time for parametrize_model(): ' ,datetime.datetime.now())\n",
    "\n",
    "    \n",
    "    return model_instance\n",
    "\n",
    "\n",
    "\n",
    "def save_model_bounds(model, filename, directory='./flux_results/flux_sampling/model_bounds/'):\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Get the bounds of each reaction in the model\n",
    "    bounds = []\n",
    "    for reaction in model.reactions:\n",
    "        bounds.append([reaction.id, reaction.bounds[0], reaction.bounds[1]])\n",
    "\n",
    "    # Create a DataFrame with the bounds\n",
    "    bounds_df = pd.DataFrame(bounds, columns=['Reaction', 'Lower Bound', 'Upper Bound'])\n",
    "\n",
    "    # Write the DataFrame to a CSV file\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    bounds_df.to_csv(filepath, index=False)\n",
    "\n",
    "    print(f\"Model bounds saved to: {filepath}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06e29c47-648e-4386-ae33-677c2dc130ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the sampling and the preprocessing step. Sakit sa ulo mag-parametrize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca406088-5276-4af4-b78f-fbb3a3a0432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit\n",
    "\n",
    "\n",
    "# #Parametrize models per type by generating model instance\n",
    "# print('Generating parametrized models for flux sampling')\n",
    "# WT_250 =  parametrize_model(wt_model, 225,275,co2=29, if_trans=False)\n",
    "# WT_750 = parametrize_model(wt_model, 725, 775,co2=29, if_trans=False)\n",
    "# WT_1500 = parametrize_model(wt_model, 1475, 1525,co2=29, if_trans=False)\n",
    "\n",
    "# TR_250 = parametrize_model(wt_model, 225, 275,co2=22.2, if_trans=True)\n",
    "# TR_750 = parametrize_model(wt_model, 725, 775,co2=22.2, if_trans=True)\n",
    "# TR_1500 = parametrize_model(wt_model, 1475, 1525,co2=22.2, if_trans=True)\n",
    "\n",
    "# #Generate list of models for flux sampling\n",
    "# sampling_list = [WT_250, WT_750, WT_1500, TR_250, TR_750, TR_1500]\n",
    "\n",
    "# print('generating flux samples for parametrized models')\n",
    "# for model in sampling_list:\n",
    "#     print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "#     model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "#     name_for_file = str('flux_sample_'+model_name+'_Loopless_FVA_25kT')\n",
    "    \n",
    "#     #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "#     save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "    \n",
    "#     #Parametrize OPTGP sampler\n",
    "#     num_samples =5000\n",
    "#     thinning = 75000\n",
    "    \n",
    "#     print('Starting OPTGP sampler:')\n",
    "#     print('num_samples: ', num_samples)\n",
    "#     print('Thinning coefficient: ', thinning)\n",
    "#     generate_flux_samples(model, num_samples =5000, batch_size=2500, thinning=75000, output_filename=name_for_file)\n",
    "#     del model #Deletes model instance to free up memory \n",
    "#     print('end time: ', datetime.datetime.now())\n",
    "\n",
    "# #This outputs a set of bounds that we can reuse to re-parametrize a model instead of re-running the parametrization script again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3dd4bc9-740b-4566-8ffe-d8c52fb606ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating parametrized models for flux sampling\n",
      "start time for parametrize_model():  2023-06-20 02:22:16.084529\n",
      "Read LP format model from file /tmp/tmpxvbya_hf.lp\n",
      "Reading time = 0.02 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "computing Loopless FVA to model\n",
      "setting FVA constraints to model\n",
      "reactions number (before pruning):  4940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  703\n",
      "end time for parametrize_model():  2023-06-20 02:22:36.871576\n",
      "start time for parametrize_model():  2023-06-20 02:22:36.871750\n",
      "Read LP format model from file /tmp/tmps892tmju.lp\n",
      "Reading time = 0.02 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "computing Loopless FVA to model\n",
      "setting FVA constraints to model\n",
      "reactions number (before pruning):  4940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  846\n",
      "end time for parametrize_model():  2023-06-20 02:22:57.354717\n",
      "start time for parametrize_model():  2023-06-20 02:22:57.354903\n",
      "Read LP format model from file /tmp/tmpr4urvrbl.lp\n",
      "Reading time = 0.01 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "computing Loopless FVA to model\n",
      "setting FVA constraints to model\n",
      "reactions number (before pruning):  4940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  1118\n",
      "end time for parametrize_model():  2023-06-20 02:23:17.312519\n",
      "start time for parametrize_model():  2023-06-20 02:23:17.312691\n",
      "Read LP format model from file /tmp/tmp24zbcttu.lp\n",
      "Reading time = 0.02 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "computing Loopless FVA to model\n",
      "setting FVA constraints to model\n",
      "reactions number (before pruning):  4948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  676\n",
      "end time for parametrize_model():  2023-06-20 02:23:37.833153\n",
      "start time for parametrize_model():  2023-06-20 02:23:37.833327\n",
      "Read LP format model from file /tmp/tmp6gjvpajo.lp\n",
      "Reading time = 0.01 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "computing Loopless FVA to model\n",
      "setting FVA constraints to model\n",
      "reactions number (before pruning):  4948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  878\n",
      "end time for parametrize_model():  2023-06-20 02:23:58.537483\n",
      "start time for parametrize_model():  2023-06-20 02:23:58.537656\n",
      "Read LP format model from file /tmp/tmp705tlcme.lp\n",
      "Reading time = 0.02 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "computing Loopless FVA to model\n",
      "setting FVA constraints to model\n",
      "reactions number (before pruning):  4948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  1132\n",
      "end time for parametrize_model():  2023-06-20 02:24:18.723822\n",
      "generating flux samples for parametrized models\n",
      "start time for sampler generation:  2023-06-20 02:24:18.724118\n",
      "Model bounds saved to: ./flux_results/flux_sampling/model_bounds/flux_sample_WT_250_Loopless_FVA_25kT\n",
      "Starting OPTGP sampler:\n",
      "generating sampler for model\n",
      "Read LP format model from file /tmp/tmp2yyntwas.lp\n",
      "Reading time = 0.00 seconds\n",
      ": 3970 rows, 1412 columns, 5486 nonzeros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4961/2014468437.py:21: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  model_name = str([k for k, v in locals().items() if v == model][0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done generating OPTGP sampler\n",
      "saving output to  ./flux_results/flux_sampling//flux_sample_WT_250_Loopless_FVA_25kT\n",
      "Generating batch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/sampling/optgp.py:127: RuntimeWarning: Mean of empty slice.\n",
      "  (len(self.model.variables),), self.warmup.mean(axis=0)\n",
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "high <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/sampling/optgp.py\", line 226, in _sample_chain\n    pi = np.random.randint(sampler.n_warmup)\n  File \"mtrand.pyx\", line 748, in numpy.random.mtrand.RandomState.randint\n  File \"_bounded_integers.pyx\", line 1247, in numpy.random._bounded_integers._rand_int64\nValueError: high <= 0\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 30\u001b[0m\n\u001b[1;32m     25\u001b[0m save_model_bounds(model, filename\u001b[38;5;241m=\u001b[39mname_for_file)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting OPTGP sampler:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mgenerate_flux_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m75000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname_for_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m model \u001b[38;5;66;03m#Deletes model instance to free up memory \u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend time: \u001b[39m\u001b[38;5;124m'\u001b[39m, datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n",
      "Cell \u001b[0;32mIn[22], line 24\u001b[0m, in \u001b[0;36mgenerate_flux_samples\u001b[0;34m(model, num_samples, batch_size, output_filename, thinning, output_dir)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_samples\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(samples, columns\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mreactions\u001b[38;5;241m.\u001b[39mlist_attr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/sampling/optgp.py:174\u001b[0m, in \u001b[0;36mOptGPSampler.sample\u001b[0;34m(self, n, fluxes)\u001b[0m\n\u001b[1;32m    169\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m([n_process] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocesses, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocesses)))\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPool(\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocesses, initializer\u001b[38;5;241m=\u001b[39mmp_init, initargs\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m,)\n\u001b[1;32m    173\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m--> 174\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_sample_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m chains \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([r[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results])\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(r[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results)\n",
      "File \u001b[0;32m~/anaconda3/envs/RiceMM/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/RiceMM/lib/python3.10/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mValueError\u001b[0m: high <= 0"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "#Include the FVA bounds file\n",
    "\n",
    "#Parametrize models per type by generating model instance\n",
    "print('Generating parametrized models for flux sampling')\n",
    "WT_250 =  parametrize_model(wt_model, 225,275,co2=29, if_trans=False, fva_bounds_file='./flux_results/flux_sampling/model_bounds/flux_sample_WT_250_Loopless_FVA_75kT.csv')\n",
    "WT_750 = parametrize_model(wt_model, 725, 775,co2=29, if_trans=False, fva_bounds_file='./flux_results/flux_sampling/model_bounds/flux_sample_WT_750_Loopless_FVA_75kT.csv')\n",
    "WT_1500 = parametrize_model(wt_model, 1475, 1525,co2=29, if_trans=False, fva_bounds_file='./flux_results/flux_sampling/model_bounds/flux_sample_WT_1500_Loopless_FVA_75kT.csv')\n",
    "\n",
    "\n",
    "TR_250 = parametrize_model(wt_model, 225, 275,co2=22.2, if_trans=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/flux_sample_TR_250_Loopless_FVA_75kT.csv')\n",
    "TR_750 = parametrize_model(wt_model, 725, 775,co2=22.2, if_trans=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/flux_sample_TR_750_Loopless_FVA_75kT.csv')\n",
    "TR_1500 = parametrize_model(wt_model, 1475, 1525,co2=22.2, if_trans=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/flux_sample_TR_1500_Loopless_FVA_75kT.csv')\n",
    "\n",
    "#Generate list of models for flux sampling\n",
    "sampling_list = [WT_250, WT_750, WT_1500, TR_250, TR_750, TR_1500]\n",
    "\n",
    "print('generating flux samples for parametrized models')\n",
    "for model in sampling_list:\n",
    "    print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "    model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "    name_for_file = str('flux_sample_'+model_name+'_Loopless_FVA_25kT')\n",
    "    \n",
    "    #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "    save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Starting OPTGP sampler:')\n",
    "    generate_flux_samples(model, num_samples =5000, batch_size=2500, thinning=75000, output_filename=name_for_file)\n",
    "    del model #Deletes model instance to free up memory \n",
    "    print('end time: ', datetime.datetime.now())\n",
    "\n",
    "#This outputs a set of bounds that we can reuse to re-parametrize a model instead of re-running the parametrization script again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efb83acf-a461-4820-855d-f152d5bdb7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating sampler for model\n",
      "Read LP format model from file /tmp/tmp9bcbf1ye.lp\n",
      "Reading time = 0.00 seconds\n",
      ": 3975 rows, 1767 columns, 7085 nonzeros\n",
      "done generating OPTGP sampler\n",
      "100\n",
      "50\n",
      "2\n",
      "Generating batch 1/2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "high <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/sampling/optgp.py\", line 226, in _sample_chain\n    pi = np.random.randint(sampler.n_warmup)\n  File \"mtrand.pyx\", line 748, in numpy.random.mtrand.RandomState.randint\n  File \"_bounded_integers.pyx\", line 1247, in numpy.random._bounded_integers._rand_int64\nValueError: high <= 0\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(num_samples \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_samples\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(samples, columns\u001b[38;5;241m=\u001b[39mWT_250\u001b[38;5;241m.\u001b[39mreactions\u001b[38;5;241m.\u001b[39mlist_attr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/sampling/optgp.py:174\u001b[0m, in \u001b[0;36mOptGPSampler.sample\u001b[0;34m(self, n, fluxes)\u001b[0m\n\u001b[1;32m    169\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m([n_process] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocesses, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocesses)))\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPool(\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocesses, initializer\u001b[38;5;241m=\u001b[39mmp_init, initargs\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m,)\n\u001b[1;32m    173\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m--> 174\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_sample_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m chains \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([r[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results])\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(r[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results)\n",
      "File \u001b[0;32m~/anaconda3/envs/RiceMM/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/RiceMM/lib/python3.10/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mValueError\u001b[0m: high <= 0"
     ]
    }
   ],
   "source": [
    "\n",
    "#Generate sampler\n",
    "print(\"generating sampler for model\")\n",
    "sampler = sampling.OptGPSampler(TR_750, processes=6, thinning=1)\n",
    "print(\"done generating OPTGP sampler\")\n",
    "\n",
    "\n",
    "num_samples = 100\n",
    "batch_size = 50\n",
    "\n",
    "\n",
    "\n",
    "for i in range(num_samples // batch_size):\n",
    "    print(num_samples)\n",
    "    print(batch_size)\n",
    "    print(num_samples // batch_size)\n",
    "    print(f\"Generating batch {i+1}/{num_samples//batch_size}\")\n",
    "    samples = sampler.sample(n=5000)\n",
    "    df = pd.DataFrame(samples, columns=WT_250.reactions.list_attr(\"id\"))\n",
    "    if i == 0:\n",
    "        df.to_csv(f\"{output_dir}/{output_filename}\", index=False)\n",
    "    else:\n",
    "        df.to_csv(f\"{output_dir}/{output_filename}\", index=False, header=False, mode=\"a\")\n",
    "#             \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc5de19-a7eb-4723-9567-c124b826f9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time for parametrize_model():  2023-06-20 02:30:26.734710\n",
      "Read LP format model from file /tmp/tmpvrb9yibr.lp\n",
      "Reading time = 0.01 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "computing Loopless FVA to model\n",
      "setting FVA constraints to model\n",
      "reactions number (before pruning):  4940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  3736\n",
      "end time for parametrize_model():  2023-06-20 02:30:38.127710\n",
      "generating sampler for model\n",
      "Read LP format model from file /tmp/tmpo_4ir6jh.lp\n",
      "Reading time = 0.01 seconds\n",
      ": 3970 rows, 7478 columns, 31838 nonzeros\n"
     ]
    }
   ],
   "source": [
    "#Parametrization test, old \n",
    "\n",
    "#It appears that adding Loopless overconstrains the model that it prevents the generation of warmup points.\n",
    "wt_250_old_bounds = parametrize_model(wt_model, 725,775,co2=29, if_trans=False, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Old/flux_sample_WT_750.csv')\n",
    "\n",
    "\n",
    "\n",
    "#Generate sampler\n",
    "print(\"generating sampler for model\")\n",
    "sampler = sampling.OptGPSampler(wt_250_old_bounds, processes=6, thinning=1)\n",
    "print(\"done generating OPTGP sampler\")\n",
    "\n",
    "\n",
    "num_samples = 100\n",
    "batch_size = 50\n",
    "\n",
    "\n",
    "\n",
    "for i in range(num_samples // batch_size):\n",
    "    print(num_samples)\n",
    "    print(batch_size)\n",
    "    print(num_samples // batch_size)\n",
    "    print(f\"Generating batch {i+1}/{num_samples//batch_size}\")\n",
    "    samples = sampler.sample(n=5000)\n",
    "    df = pd.DataFrame(samples, columns=WT_250.reactions.list_attr(\"id\"))\n",
    "    if i == 0:\n",
    "        df.to_csv(f\"{output_dir}/{output_filename}\", index=False)\n",
    "    else:\n",
    "        df.to_csv(f\"{output_dir}/{output_filename}\", index=False, header=False, mode=\"a\")\n",
    "#             \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0c6e35e-69b2-4ae8-86c7-efd36099eef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on OptGPSampler in module cobra.sampling.optgp object:\n",
      "\n",
      "class OptGPSampler(cobra.sampling.hr_sampler.HRSampler)\n",
      " |  OptGPSampler(model: 'Model', thinning: int = 100, processes: Optional[int] = None, nproj: Optional[int] = None, seed: Optional[int] = None, **kwargs) -> None\n",
      " |  \n",
      " |  Improved Artificial Centering Hit-and-Run sampler.\n",
      " |  \n",
      " |  A parallel sampler with fast convergence and parallel execution.\n",
      " |  See [1]_ for details.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  model : cobra.Model\n",
      " |      The cobra model from which to generate samples.\n",
      " |  processes: int, optional\n",
      " |      The number of processes used during sampling\n",
      " |      (default cobra.Configuration.processes).\n",
      " |  thinning : int, optional\n",
      " |      The thinning factor of the generated sampling chain. A thinning of\n",
      " |      10 means samples are returned every 10 steps (default 100).\n",
      " |  nproj : int > 0, optional\n",
      " |      How often to reproject the sampling point into the feasibility\n",
      " |      space. Avoids numerical issues at the cost of lower sampling. If\n",
      " |      you observe many equality constraint violations with\n",
      " |      `sampler.validate` you should lower this number (default None).\n",
      " |  seed : int > 0, optional\n",
      " |      Sets the random number seed. Initialized to the current time stamp\n",
      " |      if None (default None).\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  n_samples : int\n",
      " |      The total number of samples that have been generated by this\n",
      " |      sampler instance.\n",
      " |  problem : typing.NamedTuple\n",
      " |      A NamedTuple whose attributes define the entire sampling problem in\n",
      " |      matrix form.\n",
      " |  warmup : numpy.matrix\n",
      " |      A numpy matrix with as many columns as reactions in the model and\n",
      " |      more than 3 rows containing a warmup sample in each row. None if no\n",
      " |      warmup points have been generated yet.\n",
      " |  retries : int\n",
      " |      The overall of sampling retries the sampler has observed. Larger\n",
      " |      values indicate numerical instabilities.\n",
      " |  fwd_idx : numpy.array\n",
      " |      A numpy array having one entry for each reaction in the model,\n",
      " |      containing the index of the respective forward variable.\n",
      " |  rev_idx : numpy.array\n",
      " |      A numpy array having one entry for each reaction in the model,\n",
      " |      containing the index of the respective reverse variable.\n",
      " |  prev : numpy.array\n",
      " |      The current/last flux sample generated.\n",
      " |  center : numpy.array\n",
      " |      The center of the sampling space as estimated by the mean of all\n",
      " |      previously generated samples.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The sampler is very similar to artificial centering where each process\n",
      " |  samples its own chain. Initial points are chosen randomly from the\n",
      " |  warmup points followed by a linear transformation that pulls the points\n",
      " |  a little bit towards the center of the sampling space.\n",
      " |  \n",
      " |  If the number of processes used is larger than the one requested,\n",
      " |  number of samples is adjusted to the smallest multiple of the number of\n",
      " |  processes larger than the requested sample number. For instance, if you\n",
      " |  have 3 processes and request 8 samples, you will receive 9.\n",
      " |  \n",
      " |  Memory usage is roughly in the order of (2 * number of reactions)^2\n",
      " |  due to the required nullspace matrices and warmup points. So, large\n",
      " |  models easily take up a few GBs of RAM. However, most of the large\n",
      " |  matrices are kept in shared memory. So the RAM usage is independent of\n",
      " |  the number of processes.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] Megchelenbrink W, Huynen M, Marchiori E (2014)\n",
      " |     optGpSampler: An Improved Tool for Uniformly Sampling the Solution-Space\n",
      " |     of Genome-Scale Metabolic Networks.\n",
      " |     PLoS ONE 9(2): e86587.\n",
      " |     https://doi.org/10.1371/journal.pone.0086587\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      OptGPSampler\n",
      " |      cobra.sampling.hr_sampler.HRSampler\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getstate__(self) -> Dict\n",
      " |      Return the object for serialization.\n",
      " |  \n",
      " |  __init__(self, model: 'Model', thinning: int = 100, processes: Optional[int] = None, nproj: Optional[int] = None, seed: Optional[int] = None, **kwargs) -> None\n",
      " |      Initialize a new OptGPSampler.\n",
      " |  \n",
      " |  sample(self, n: int, fluxes: bool = True) -> pandas.core.frame.DataFrame\n",
      " |      Generate a set of samples.\n",
      " |      \n",
      " |      This is the basic sampling function for all hit-and-run samplers.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          The minimum number of samples that are generated at once.\n",
      " |      fluxes : bool, optional\n",
      " |          Whether to return fluxes or the internal solver variables. If\n",
      " |          set to False, will return a variable for each forward and\n",
      " |          backward flux as well as all additional variables you might\n",
      " |          have defined in the model (default True).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.DataFrame\n",
      " |          Returns a pandas DataFrame with `n` rows, each containing a\n",
      " |          flux sample.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Performance of this function linearly depends on the number\n",
      " |      of reactions in your model and the thinning factor.\n",
      " |      \n",
      " |      If the number of processes is larger than one, computation is split\n",
      " |      across the CPU cores of your machine. This may shorten computation\n",
      " |      time. However, there is also overhead in setting up parallel\n",
      " |      computation primitives so, we recommend to calculate large numbers\n",
      " |      of samples at once (`n` > 1000).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from cobra.sampling.hr_sampler.HRSampler:\n",
      " |  \n",
      " |  batch(self, batch_size: int, batch_num: int, fluxes: bool = True) -> pandas.core.frame.DataFrame\n",
      " |      Create a batch generator.\n",
      " |      \n",
      " |      This is useful to generate `batch_num` batches of `batch_size`\n",
      " |      samples each.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      batch_size : int\n",
      " |          The number of samples contained in each batch.\n",
      " |      batch_num : int\n",
      " |          The number of batches in the generator.\n",
      " |      fluxes : bool, optional\n",
      " |          Whether to return fluxes or the internal solver variables. If\n",
      " |          set to False, will return a variable for each forward and\n",
      " |          backward flux as well as all additional variables you might\n",
      " |          have defined in the model (default True).\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      pandas.DataFrame\n",
      " |          A DataFrame with dimensions (batch_size x n_r) containing\n",
      " |          a valid flux sample for a total of n_r reactions (or variables\n",
      " |          if fluxes=False) in each row.\n",
      " |  \n",
      " |  generate_fva_warmup(self) -> None\n",
      " |      Generate the warmup points for the sampler.\n",
      " |      \n",
      " |      Generates warmup points by setting each flux as the sole objective\n",
      " |      and minimizing/maximizing it. Also caches the projection of the\n",
      " |      warmup points into the nullspace for non-homogeneous problems (only\n",
      " |      if necessary).\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If flux cone contains a single point or the problem is\n",
      " |          inhomogeneous.\n",
      " |  \n",
      " |  validate(self, samples: numpy.matrix) -> numpy.ndarray\n",
      " |      Validate a set of samples for equality and inequality feasibility.\n",
      " |      \n",
      " |      Can be used to check whether the generated samples and warmup points\n",
      " |      are feasible.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      samples : numpy.matrix\n",
      " |          Must be of dimension (samples x n_reactions). Contains the\n",
      " |          samples to be validated. Samples must be from fluxes.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.array\n",
      " |          A one-dimensional numpy array containing\n",
      " |          a code of 1 to 3 letters denoting the validation result:\n",
      " |          - 'v' means feasible in bounds and equality constraints\n",
      " |          - 'l' means a lower bound violation\n",
      " |          - 'u' means a lower bound validation\n",
      " |          - 'e' means and equality constraint violation\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If wrong number of columns.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from cobra.sampling.hr_sampler.HRSampler:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampler.validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2dc480-3a7d-4422-b65f-226de5898637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Generate list of models for flux sampling\n",
    "# sampling_list = [WT_250, WT_750, WT_1500, TR_250, TR_750, TR_1500]\n",
    "\n",
    "# print('generating flux samples for parametrized models')\n",
    "# for model in sampling_list:\n",
    "#     print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "#     model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "#     name_for_file = str('flux_sample_'+model_name+'_Loopless_FVA_25kT')\n",
    "    \n",
    "#     #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "#     save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "    \n",
    "#     #Parametrize OPTGP sampler\n",
    "#     num_samples =5000\n",
    "#     thinning = 75000\n",
    "    \n",
    "#     print('Starting OPTGP sampler:')\n",
    "#     print('num_samples: ', num_samples)\n",
    "#     print('Thinning coefficient: ', thinning)\n",
    "#     generate_flux_samples(model, num_samples =5000, batch_size=2500, thinning=25000, output_filename=name_for_file)\n",
    "#     del model #Deletes model instance to free up memory \n",
    "#     print('end time: ', datetime.datetime.now())\n",
    "\n",
    "# #This outputs a set of bounds that we can reuse to re-parametrize a model instead of re-running the parametrization script again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427eeda4-9339-42e4-b50f-eaf511ab957b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %timeit\n",
    "\n",
    "# #Let's try adding Loopless FVA to the mix. For some reason the solutions are highly inflated which indicates some cycling happening\n",
    "# #I added the loopless FVA to the parametrize_model() function (which I forgot to add, tanga tanga ko putangina)\n",
    "# #Parametrize models per type by generating model instance\n",
    "# print('Generating parametrized models for flux sampling')\n",
    "# WT_1500 = parametrize_model(wt_model, 1475, 1525,co2=29, if_trans=False)\n",
    "\n",
    "# #Add Loopless constraints to parametrized model (Just a test\n",
    "\n",
    "\n",
    "# #Generate list of models for flux sampling\n",
    "# sampling_list = [WT_1500]\n",
    "\n",
    "# print('generating flux samples for parametrized models')\n",
    "# for model in sampling_list:\n",
    "#     print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "#     model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "#     name_for_file = str('flux_sample_'+model_name+'_Loopless_FVA_100T')\n",
    "    \n",
    "#     #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "#     save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "    \n",
    "#     #Parametrize OPTGP sampler\n",
    "#     num_samples =5000\n",
    "#     thinning = 20000\n",
    "    \n",
    "#     print('Starting OPTGP sampler:')\n",
    "#     print('num_samples: ', num_samples)\n",
    "#     print('Thinning coefficient: ', thinning)\n",
    "#     generate_flux_samples(model, num_samples =num_samples, batch_size=2500, thinning=thinning, output_filename=name_for_file)\n",
    "#     del model #Deletes model instance to free up memory \n",
    "#     print('end time: ', datetime.datetime.now())\n",
    "\n",
    "    \n",
    "    \n",
    "# #Notes: June 17\n",
    "# #Adding the \"Loopless FVA\" parameter to the pre-processing step does not work and generates an infeasible solution. It causes the solver to become stuck.\n",
    "\n",
    "# #Note: it takes 30 minutes to implement Loopless FVA to the model. Upon checking yung mga flux bounds it reduces the max and min values to something closer to their pFBA counterparts. \n",
    "# #I'll try to rerun my pipeline to accomodate that.\n",
    "# #Note: Loopless FVA produces NaNs in the flux bounds of some reactions. Need to remove that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff71c37-82b1-4a85-ba4e-e0770c320b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Generate list of models for flux sampling\n",
    "# sampling_list = [WT_1500]\n",
    "\n",
    "# print('generating flux samples for parametrized models')\n",
    "# for model in sampling_list:\n",
    "#     print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "#     model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "#     name_for_file = str('flux_sample_'+model_name+'_Loopless_FVA_100T')\n",
    "    \n",
    "#     #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "#     save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "    \n",
    "#     #Parametrize OPTGP sampler\n",
    "#     num_samples =1000\n",
    "#     thinning = 100\n",
    "    \n",
    "#     print('Starting OPTGP sampler:')\n",
    "#     print('num_samples: ', num_samples)\n",
    "#     print('Thinning coefficient: ', thinning)\n",
    "#     generate_flux_samples(model, num_samples =num_samples, batch_size=1000, thinning=thinning, output_filename=name_for_file)\n",
    "#     del model #Deletes model instance to free up memory \n",
    "#     print('end time: ', datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121358d0-c57f-4971-ab9d-5453a86b9f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit\n",
    "# #Run another set of samples to ensure convergence rate\n",
    "\n",
    "# #Parametrize models per type by generating model instance\n",
    "# print('Generating parametrized models for flux sampling')\n",
    "# WT_250 =  parametrize_model(wt_model, 225,275,co2=29, if_trans=False)\n",
    "# WT_750 = parametrize_model(wt_model, 725, 775,co2=29, if_trans=False)\n",
    "# WT_1500 = parametrize_model(wt_model, 1475, 1525,co2=29, if_trans=False)\n",
    "\n",
    "# TR_250 = parametrize_model(wt_model, 225, 275,co2=22.2, if_trans=True)\n",
    "# TR_750 = parametrize_model(wt_model, 725, 775,co2=22.2, if_trans=True)\n",
    "# TR_1500 = parametrize_model(wt_model, 1475, 1525,co2=22.2, if_trans=True)\n",
    "\n",
    "# #Generate list of models for flux sampling\n",
    "# sampling_list = [WT_250, WT_750, WT_1500, TR_250, TR_750, TR_1500]\n",
    "\n",
    "# print('generating flux samples for parametrized models')\n",
    "# for model in sampling_list:\n",
    "#     print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "#     model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "#     name_for_file = str('flux_sample_'+model_name+'2ndRun')\n",
    "    \n",
    "#     #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "#     save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "#     generate_flux_samples(model, num_samples =5000, batch_size=2500, thinning=35000, output_filename=name_for_file)\n",
    "#     del model #Deletes model instance to free up memory \n",
    "#     print('end time: ', datetime.datetime.now())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b10e5-c885-4c13-81c9-911f892789cc",
   "metadata": {},
   "source": [
    "Notes: needed to repeat sampling due to the following:\n",
    "- sampling matrices are too large to load, compensate with the use of thinning instead. Use specifications from Hermann et al (2020) which uses instead a thinning coefficient of 10000 instead of keeping all samples. My original parameters were n = 50000, batch size = 2000 and thinning = 500. \n",
    "- Maybe I should use a thinning coefficient of 100000 instead? Since my model has a number of dimensions one exponent higher than the previously benchmarked Arnold Model\n",
    "    - I've decided to run my model with a thinning coefficient of 25000. Hopefully autocorrelation and convergence wouldn't be much of an issue. Total samples would be equal in turn to 1.25e8 individual sampling points. \n",
    "\n",
    "- I needed to reparametrize samples considering that the objective function doesn't apply in flux sampling. INstead of adding an objective coefficient all demand reactions that output biomass are turned off except for \"DM_Phloem_BS\". What I need to do instead is re-parametrize it to allow photoassimilates to exit at that reaction rather than to others.\n",
    "- I'll save the format to \".npz\" instead of \"csv\" since I'm running out of memory whenever I'm loading it out of this script. I think the output of the model is sparse enough that I can instead use this format instead.\n",
    "    - Actually I can save my csv to a normal csv once since I can just adjust the thinning number instead of keeping all samples.\n",
    "\n",
    "- It is still a question whether my samples are uncorrelated or not. I will run the diagnostic tests after I finish running the rest of the scripts.\n",
    "\n",
    "\n",
    "\n",
    "Note: May 17 2023\n",
    "Flux sampling script was interrupted @ TR750 and was rerun at that point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae799577-6b2a-444f-9f90-aa72715e0ec2",
   "metadata": {},
   "source": [
    "Notes: \n",
    "OPTGP Is shown to be faster than ACHR and also converges faster\n",
    "\n",
    "Let's try with a 10 samples first with 10 batches\n",
    "\n",
    "I think the model is too large to be loaded into the flux sampler. \n",
    "\n",
    "It initialized after 30 minutes, let's try sampling na. \n",
    "\n",
    "It takes 1-2 hours at most to generate 2000 samples with a thinning coefficient of 10000. Extrapolating from that, we need probably 4-6 hours to generate 5000 samples with a TC of 20000. To keep things tractable I'll keep the thinning coefficient at 10000. I can just add more samples if needed.\n",
    "\n",
    "\n",
    "Things to add to the paper:\n",
    "\n",
    "\n",
    "Flux sampling is another constraints-based technique used for characterizing the null space of a given stoichiometric model, providing us insights on the flux distributions of a given metabolic model without the explicit definition of a given cellular objective. Not only does this technique offer advantages over conventional FBA and FVA where it allows researchers to determine the feasibility of solutions within a given defined range, as well as the distribution of these fluxes provided the model constaints.. The latter, in turn, allows statistical analysis to determine whether any given fluxes exist within a single probability distribution or not. This, in turn, allows a more direct comparison of fluxes and to adequately sample a solution space provided the constraints implemented in the model.\n",
    "\n",
    "The same constraints have been implemented as with the previous set-ups but with a modification with regards to how the objective functions are concerned. Unlike in pFBA where we can set a particular reaction as an objective, no such setting exists for flux sampling. Thus, this setup is in turn reliant on explicitly defined constraints that would define the n reaction-dimensional solution space. To parametrize this, we have turned off all biomass-related demands such as Coleoptile Biomass, Straw_Biomass and the \"DM_Phloem_M\" reaction to force the model to output flux to the \"DM_Phloem_BS\" reaction. Additionally, the model is constrained in a similar manner as with the previous pFBA setups that we had done to benchmark and assess our model's performance.\n",
    "\n",
    "THe benefits of using Flux Sampling compared to other methods such as FVA in characterizing a solution space is that:\n",
    "a. We may establish confidence intervals with the use of statistical tests to fully characterize a given solution space and whether\n",
    "b. Rather than simply generating representative fluxes showing the maximum and minimum amount of possible flux towards a particular reaction, flux sampling allows summary statistics to be generated, including the probability distribution of each particular reaction. \n",
    "c. Lastly, flux sampling allows a detailed comparison of the interdependence of each particular reaction, showing which reactions are coupled to each other in a positive and negative fashion. This is done\n",
    "\n",
    "Three setups per parametrized model were initialized, each with a representative light treatment of 250, 750 and 1500 PPFD with a defined range of +-25, respectively. The NGAM reactions were instead set at a static value at each representative light point detailed above. A total of 6 treatments were initialized to represent both the WT and Trans models at the selected light points. \n",
    "\n",
    "The sampling algorithm used was the OPTGP (optimized general parallel) sampler from the Cobrapy.sampling package. The sampler was parametrized to generate 5000 samples with a thinning coefficient of 25000, representing 1.25x10^8 sampling points, and was multithreaded into 7 processes each. Run times varied from between 3-6 hours per model parametrized, which was expected based on the number of reactions in the parametrized model.\n",
    "\n",
    "\n",
    "After the generation of individual sampling points, convergence statistics were done to assess the level of autocorrelation as well as to assess whether the samplers have sufficiently converged to a singular value. The former is done with the use of the \"acf\" function to assess the level of autocorrelation on each given column, while the latter is assessed with the use of two specific methods -- the Gelman-Rubin and the Geweke statistics. These are two methods that we will use to assess whether the number of sampling points is sufficient to ensure adequate convergence of each reaction in the model. Reactions that have not converged sufficiently will be indicated.\n",
    "\n",
    "After the assessment of autocorrelation and convergence, each of the pairs between light treatments (225-725, 725-1475, 225-1475) and between models (WT and Trans) are subjected to pairwise Kruskal-Wallis tests to assess which reaction pairs are derived from the same distribution. It is a non-parametric rank-based test test suitable for comparing outputs where there are no assumed distributions behind a population, and has been used in a similar fashion in previous flux sampling setups that involve Plant Metabolism  (Herrmann et al., 2019).  \n",
    "\n",
    "This procedure, in turn, allows us to deduce in finer detail which reactions in particular are positively correlated with CO2 flux into the BS cell's Rubisco reaction. In the previous pFBA experiment we were able to demonstrate a similar approach to this by performing a sensitivity analysis on Glycine Decarboxylase, and had demonstrated the negative relationship between M cell GLYDHD and BS Cell GLYDHD.\n",
    "\n",
    "Lastly, we can afterwards assess which fluxes are coupled by iterating over the list of fluxes in a single flux sample matrix and computing the spearman correlations between the pairwise comparisons. From here we can assess which particular reactions are positively or negatively correlated or not. A particular focus will then be held. Further Downstream analysis includes determination of reactions that are positively or negatively coupled with each other and corroborating this fact on whether the reaction is disrupted in the \"Trans\" parametrized model.  \n",
    "\n",
    "\n",
    "\n",
    "May 19, 2023\n",
    "Some observations on the fluxes obtained from initial flux sampling runs:\n",
    "- It seems it doesn't maximize CO2 assimilation as with pFBA. \n",
    "- It features some reactions with infeasibly large fluxes, particularly those expected to have flux cycling.\n",
    "\n",
    "I asked the Gitter group on what are their thoughts on how to approach this.\n",
    "\n",
    "One solution I think is this:\n",
    "- Reparametrize a model first and generate FVA solutions to \"pre-process\" the model, and in turn add directionality and bound constraints to the model to reduce its solution space further.\n",
    "- Try readding the objective function for photoassimilate generation as well as the pfba objective, as well as add the \"cyclefreeflux\" function by Desouki et al (2015).\n",
    "\n",
    "\n",
    "\n",
    "I am currently testing the Latter.\n",
    "\n",
    "May 20, 2023\n",
    "\n",
    "The latter does not work since it applies MILP, I think. It returns the following error:\n",
    "    \n",
    "    TypeError: Sampling does not work with integer problems.\n",
    "\n",
    "I will instead to the former instead. I've also implemented pruning to remove any unused reactions and metabolites based on the find_blocked_reactions() function of FVA. This will further constrain the model to sort of \"Contextualise\" it. \n",
    "\n",
    "\n",
    "May 20, 2023\n",
    "\n",
    "Based on the Geweke Statistic, and with a z-score of 1.96 (indicating 0.95 confidence  interval) most of the samples have converged on a single statistic. Based on the Gelman Rubin statistic however all of the reactions have not converged to a singular solution. Why?\n",
    "\n",
    "I've rerun the diagnostic scripts in R using Coda and have produced a more reliable measure of convergence and autocorrelation. In both cases only \n",
    "\n",
    "I'll test 5000x25000 samples with the reduced and pFVA-constrained models. I think sampling will be faster considering that I've pruned the samples as well as reduced the solution space by a lot. \n",
    "\n",
    "\n",
    "Flux sampling convergence statistics are based on the methods highlighted by Hermmann et al (2019) and by Fallahi et al (2020). It says that we shouldn't use the normal Gelman-Rubin statistic and instead use the Brooks-Gelman formulation instead.\n",
    "\n",
    "However, for both cases I've instead used the Raftery-Lewis statistic and \n",
    "the Geweke Diagnostic to assess convergences for all parameters. I decided to re-run instead the two last samples considering that they both have significant amounts of reactions that haven't converged based on the RL statistic and the GW statistic.\n",
    "\n",
    "For the RL statistic both 250 and 750 parametrized samplers have converged, although the Geweke diagnostic only reports a convergence rate of around 70 percent. In 1500 the convergence rate falls to 40 percent only which necessitates the re-run scenario. AFterwards I can simply re-run the scripts and re-assess my results. In the meantime however I can analyze both 250 and 750 scenarios as well the highb light scenarios particularly those with significantly varying distributions\n",
    "\n",
    "\n",
    "June 13, 2023\n",
    "\n",
    "I have rerun both WT andTR 1500 to validate if both have converged. If it hasn't I'll report the results as-is and include it in the discussion.\n",
    "\n",
    "June 15, 2023\n",
    "\n",
    "I have an idea in order to ensure convergence as well as to reduce runtimes.\n",
    "My idea is to remove all reactions that are not foundd in the model to 0 in order to reduce the nullspace of the model. This will be based on the initial runs for the flux sampling runs. \n",
    "\n",
    "Afterwards I need to compare their distributions based dun sa mga previous runs to determine if pareho yung distribution. If it is the same or virtually the samme I will use it because I can ensure that it has a higher convergence rate than the one with lower samples.\n",
    "\n",
    "If in case this works then it should return the same distribution and my samples would've converged faster. Furthermore there isn't need to go for breadth considering that my parametrizations are already fixed. Hopefully it can converge faster but since I've changed the thinning constant to 100k it may change the distribution.\n",
    "\n",
    "June 15 2023\n",
    "\n",
    "    Filtering and Increasing the thinning doesn't work apparently. It reduced the convergence rate of my reactions by almost 20 percent -- very alarming. What I should do instead is to increase the thinning coefficient to something more ok (around 35000) while still being relatively fast enough.\n",
    "\n",
    "    However I'll be re-running my sampling attempt in order to fix some errors with H2O cycling. (Change H2O flux to be unidirectional towards M cell to reflect transpiration mechanism. Before what happened was that )\n",
    "\n",
    "    Furthermore I fixed the flux bounds for Photon flux. Apparently I had a typo dun sa upper bounds nung TR_1500 which caused it to have 25 lesser flux than normal.\n",
    "\n",
    "    Hopefully at the end of this ok na siya. Wala na kong problem after nito -- analysis na lang.\n",
    "\n",
    "\n",
    "June 17, 2023\n",
    "\n",
    "I just discovered how inflated the flux values are for high light conditions, which indicate that there is significant looping in some of my solutions, which I need to reassess considering how central they are to my model, particularly yung reactions involving Malate.\n",
    "\n",
    "I can try to add Loopless FVA then compare the results with the normal runs. Kahit paspasan lang.\n",
    "\n",
    "\n",
    "June 19, 2023:\n",
    "\n",
    "I think I've finally optimized my Sampling runs. I just need to rerun my scripts kahit 25000 thinning lang since increasing it didn't really affect yung convergence rates.\n",
    "\n",
    "\n",
    "Things I have tested (So far)\n",
    "- Filtering out reactions -- Convergence rates lower almost 20 percent accorss the board.\n",
    "- 10000 Thinning\n",
    "- 25000 Thinning\n",
    "- 35000 Thinning -- little improvement in convergence rates, in fact it lessened percent converged \n",
    "- Using add_loopless() function -- doesn't work, turns the model to an MILP problem which breaks Sampling\n",
    "- Loopless FVA to define reaction bounds == works so far\n",
    "\n",
    "June 20, 2023\n",
    "- I have problems regarding sampling right now. Sigh. I don't even know the issue behind it rn it just breaks\n",
    "\n",
    "\n",
    "\n",
    "Pipeline breakdown:\n",
    "\n",
    "Load CSVs to a memory saving format first\n",
    "\n",
    "1.\n",
    "Run convergence statistics on each and generate plots to assess total convergence stats for each CSV. These will include tests such as the \n",
    "Raftery-Lewis statistic and the Geweke statistics to assess both autocorrelation as well as assess convergence.\n",
    "\n",
    "Afterwards get only the flux names of those reactions that have converged\n",
    "Run pairwise Kruskal-wallis tests per CSV using the above list of converged reactions\n",
    "Identify each reaction with significant and non-significant distributions each\n",
    "\n",
    "Generate histograms/probability densities for relevant reactions with significantly different distributions with WT and Trans models.\n",
    "2. Flux coupling analysis\n",
    "Check which fluxes are coupled with each otehr and identify which fluxes are then related to each other, particularly Carbon Fixation reactions in the BS cell such as Rubisco and the DM_Phloem reactions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
