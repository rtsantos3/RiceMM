{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03a656bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T11:08:41.205406Z",
     "start_time": "2023-03-23T11:08:39.074105Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "import cobra\n",
    "import libsbml\n",
    "import pandas as pd\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import memote\n",
    "import csv\n",
    "import pytest\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xlsxwriter\n",
    "import path \n",
    "import datetime\n",
    "import scipy.sparse as sp\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "\n",
    "from cobra import sampling\n",
    "from cobra import Reaction\n",
    "\n",
    "#Change working dir first, ty ChatGPT, much loves\n",
    "cwd = os.getcwd()\n",
    "# Split the path into a list of directories\n",
    "directories = cwd.split(os.sep)\n",
    "# Remove the last two directories from the list\n",
    "directories = directories[:-2]\n",
    "# Join the directories back into a path\n",
    "new_cwd = os.sep.join(directories)\n",
    "# Change the current working directory to the new path\n",
    "os.chdir(new_cwd)\n",
    "\n",
    "sys.path.append(\"./src\")\n",
    "\n",
    "import model_manipulation  as mm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19cbcb9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T11:14:41.725034Z",
     "start_time": "2023-03-23T11:11:53.801Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This codeblock is to define some of the functions used for modelling\n",
    "\n",
    "\n",
    "#Set solver to gurobi\n",
    "config = cobra.Configuration()\n",
    "config.solver = 'gurobi'\n",
    "\n",
    "#Read 2-cell model\n",
    "wt_model = cobra.io.read_sbml_model(\"./model/ios2164_2cell.xml\")\n",
    "trans_model = cobra.io.read_sbml_model(\"./model/ios2164_2cell.xml\")\n",
    "#Estimate inf\n",
    "inf = 1e6\n",
    "\n",
    "\n",
    "#Define linear relationship between PPFD and Cellular maintainance costs\n",
    "#This formula comes from Topfer et al (2020) where she defined NGAM in a linear relationship with incident light\n",
    "\n",
    "\n",
    "def generate_constraint(model,reaction, name, lb, ub):\n",
    "    reaction_fex = model.reactions.get_by_id(name).flux_expression\n",
    "    constraint = model.problem.Constraint(reaction_fex, lb=lb, ub=ub)\n",
    "    constraint.name = name + '_constraint'\n",
    "    model.add_cons_vars\n",
    "\n",
    "def compute_ngam_atp(ppfd):\n",
    "    v_atp = 0.0049*ppfd + 2.7851\n",
    "    return v_atp\n",
    "\n",
    "\n",
    "#This function is used to set the inputs to the model used. \n",
    "def define_model_medium(model, co2, o2, ppfd, \n",
    "                        medium_dir='./misc/photo_medium.csv', no3=inf, h2o=inf, h=inf, \n",
    "                        nh4=inf, pi=inf):\n",
    "    model_photo_media = mm.read_medium_csv(medium_dir, model)\n",
    "    model_photo_media['EX_no3(e)'] = no3\n",
    "    model_photo_media['EX_h2o(e)'] = h2o\n",
    "    model_photo_media['EX_h(e)'] = h\n",
    "    model_photo_media['EX_nh4(e)'] = nh4\n",
    "    model_photo_media['EX_co2(e)'] = co2\n",
    "    model_photo_media['EX_o2(e)'] = o2\n",
    "    model_photo_media['EX_photonVis(e)'] = ppfd\n",
    "    model_photo_media['EX_pi(e)'] = pi\n",
    "    #Set set model medium as model\n",
    "#     print('Added model medium')\n",
    "    return model_photo_media\n",
    "\n",
    "    \n",
    "def turn_off_cofac_cycles(model, inact_dir='./misc/leaf_inactivated.tsv'):\n",
    "    file = csv.reader(open(inact_dir), delimiter='\\t')\n",
    "    leaf_inactive_rxns = list()\n",
    "    for rows in file:\n",
    "        row_m = str()\n",
    "        row_bs = str()\n",
    "        for rxns in rows:\n",
    "            row_m += str(rxns) + \"_M\"\n",
    "            row_bs += str(rxns) + \"_BS\"\n",
    "        leaf_inactive_rxns.append(row_m)\n",
    "        leaf_inactive_rxns.append(row_bs)\n",
    "        \n",
    "    for rxns in model.reactions:\n",
    "        if rxns.id in leaf_inactive_rxns:\n",
    "            rxns.bounds = (0,0)\n",
    "#     print('Successfully turned off cofactor-cycling reactions')\n",
    "\n",
    "    \n",
    "# #Add constraints to model\n",
    "#This code block contains constraints that would simulate the assimilation rates of bs and m cells in a two-cell system (such as those seen near the midvein region of rice leaves)\n",
    "# #BS photon flux must be the same/less than M flux (Adapted from B&B, 2019)\n",
    "# photon_import = model.reactions.get_by_id(\"EX_photonVis(e)\")\n",
    "def add_tissue_constraints(model):\n",
    "    #For input fluxes for light, we will set the flux ratio to 10:1 to reflect the anatomical proportions of our model ()\n",
    "    \n",
    "    BS_photon_import = model.reactions.PRISM_white_LED_BS\n",
    "    M_photon_import = model.reactions.PRISM_white_LED_M\n",
    "\n",
    "    #Set photon flux ratio to 10:1\n",
    "    photon_flux = mm.set_fix_flux_ratio({M_photon_import.id:10, BS_photon_import.id:1},model)\n",
    "    model.add_cons_vars(photon_flux)\n",
    "\n",
    "    \n",
    "    #UPDATE: Change CO2 intake to the M Cell instead rather than set a ratio, which is a better assumption overall. Assume na lang that external gasses are assimilated\n",
    "    #Via the M cell.\n",
    "    #From Morrison et al 2005 -- Lateral diffusion of Gases is unlikely to support photosynthesis due to the\n",
    "    #assimilation of diffused CO2 in tissues prior to BS//\n",
    "    model.reactions.CO2tex_BS.bounds = (0,0)\n",
    "    model.reactions.O2tex_BS.bounds = (0,0)\n",
    "    \n",
    "    #UPDATE: This assumption does not hold considering that recent transcriptomic analysis confirms that \n",
    "    #the bundle sheath is involved in the assimilation of inorganic nutrients, including nitrogen (nitrates/ammonia), and \n",
    "    #Sulfates. In turn, this will be implemented by simply setting the exchanges to the M cell to 0. (Hua et al, 2021)\n",
    "    model.reactions.SO3tex_M.bounds = (0,0)\n",
    "    model.reactions.SO4tex_M.bounds = (0,0)\n",
    "    model.reactions.NH4tex_M.bounds = (0,0)\n",
    "    model.reactions.NO3tex_M.bounds = (0,0)\n",
    "    \n",
    "    #Model will also constraint H2O input to BS cell only as it is also assumed that BS tissue in rice is specialized for H2O transport (Hua et al. 2021)\n",
    "    #There is a demand reaction naman for H2O for the M cell which is not connected to the BS H2Otex\n",
    "    #Restrict H2O transport to be unidirectional from the BS cell\n",
    "    model.reactions.H2Otex_M.bounds = (0, 0)\n",
    "    model.reactions.h2o_pd.bounds = (-inf, 0)\n",
    "    \n",
    "    #need to turn off HCO import as the model incorrectly transfers fixed HCO to the BS cell via the common pool compartment\n",
    "    model.reactions.HCO3tex_M.bounds = (0,0)\n",
    "    model.reactions.HCO3tex_BS.bounds = (0,0)\n",
    "    \n",
    "    #No constraints will be implemented for H+ availability allowing the model to use protons on-demand.\n",
    "    \n",
    "    #Turn off other Demand reactions that may serve as sinks for the model except DM_Phloem_BS (Which represents the output of photoassimilate thru the BS cell\n",
    "    model.reactions.DM_Phloem_M.bounds = (0,0)\n",
    "    model.reactions.Straw_Biomass_M.bounds = (0,0)\n",
    "    model.reactions.Straw_Biomass_BS.bounds = (0,0)\n",
    "    model.reactions.Coleoptile_Biomass_M.bounds = (0,0)\n",
    "    model.reactions.Coleoptile_Biomass_BS.bounds = (0,0)\n",
    "    model.reactions.DM_Phloem_BS.bounds = (0, inf)\n",
    "    \n",
    "\n",
    "def add_enzyme_constraints(model, \n",
    "                           wt_pepc = 0, \n",
    "                           wt_mdh = 11.18, \n",
    "                           wt_nadp_me = 0.14, \n",
    "                           wt_ppdk=0.31,\n",
    "                          wt_CA=7.5):\n",
    "    \n",
    "    \n",
    "    # #This code block contains constraints specific for enzyme rate constraints\n",
    "    #This approach is derived from Bogart & Myers (2016) where they constrained the enzyme rate \n",
    "    #fluxes in each of the 2-cell segments to a specific upper bound while keeping the lower bound\n",
    "    #At 0. For reversible reactions the lower bounds are set to the same value\n",
    "    \n",
    "    \n",
    "    #PEPC constraint (Reaction id: PPCc)\n",
    "    #Need to constrain it to 0 since reaction is only detected in Vascular tissue\n",
    "    pepc_BS = model.reactions.PPCc_BS\n",
    "    pepc_M = model.reactions.PPCc_M\n",
    "    \n",
    "    pepc_BS.bounds = (0,0)\n",
    "    pepc_M.bounds = (0,0)\n",
    "\n",
    "    #PPDK constraints (Reaction id: PPDKs) (note that this is found in the chloroplast?) \n",
    "    #Not detected via immunolocalization but enzyme activity is detected\n",
    "\n",
    "    ppdks_BS = model.reactions.PPDKs_BS\n",
    "    ppdks_M = model.reactions.PPDKs_M\n",
    "    ppdkc_BS = model.reactions.PPDKc_BS\n",
    "    ppdkc_M = model.reactions.PPDKc_M\n",
    "    wt_ppdks_cons = model.problem.Constraint(ppdks_BS.flux_expression \n",
    "                                             + ppdks_M.flux_expression\n",
    "                                             + ppdkc_BS.flux_expression\n",
    "                                             + ppdkc_M.flux_expression, \n",
    "                                             lb = 0, ub = wt_ppdk)\n",
    "    wt_ppdks_cons.name = 'wt_ppdks_cons'\n",
    "    model.add_cons_vars(wt_ppdks_cons)\n",
    "    #Malate Dehydrogenase \n",
    "    #Only mitochondrial in WT Rice M cells\n",
    "    mdhm_M = model.reactions.MDHm_M\n",
    "\n",
    "\n",
    "    wt_mdh_cons = model.problem.Constraint(mdhm_M.flux_expression,\n",
    "                                           lb= 0, ub=wt_mdh)\n",
    "    wt_mdh_cons.name = \"wt_mdh_cons\"\n",
    "    model.add_cons_vars(wt_mdh_cons)\n",
    "\n",
    "    #NADP-ME (Since no signal is detected in WT, no locational constraints are imposed)\n",
    "    #Let's see if I can force it to have a small amount of flux \n",
    "    nadp_me_M = model.reactions.MDHys_M\n",
    "    nadp_me_BS = model.reactions.MDHys_BS\n",
    "\n",
    "    wt_nadpme_cons = model.problem.Constraint(nadp_me_M.flux_expression\n",
    "                                             + nadp_me_BS.flux_expression,\n",
    "                                             lb= 0, ub=wt_nadp_me)\n",
    "    wt_nadpme_cons.name = \"wt_nadpme_cons\"\n",
    "    model.add_cons_vars(wt_nadpme_cons)\n",
    "\n",
    "\n",
    "    #I should add constraints for Carbonic Anhydrase\n",
    "    #I should constrain it to 0.4 ubar, which would constitute ambient CO2 partial pressure\n",
    "    #Flux is reversible so constraints are bi-directional\n",
    "    #This should be revised considering that it allows reversible reactions  and an abnormally high flux thru carbonic anhydrase, which shouldn't be the case\n",
    "\n",
    "    hco3es_m = model.reactions.HCO3Es_M.flux_expression\n",
    "    hco3ec_m = model.reactions.HCO3Ec_M.flux_expression\n",
    "    hco3em_m = model.reactions.HCO3Em_M.flux_expression\n",
    "    hco3es_bs = model.reactions.HCO3Es_BS.flux_expression\n",
    "    hco3ec_bs = model.reactions.HCO3Ec_BS.flux_expression\n",
    "    hco3em_bs = model.reactions.HCO3Em_BS.flux_expression\n",
    "\n",
    "    ca_cons = model.problem.Constraint(hco3es_m + hco3ec_m + hco3em_m \n",
    "                                       + hco3es_bs + hco3ec_bs + hco3em_bs,\n",
    "                                      lb = -wt_CA, ub = wt_CA)\n",
    "    ca_cons.name = 'Carbonic_anhydrase_constraint'\n",
    "    model.add_cons_vars(ca_cons)\n",
    "\n",
    "\n",
    "    #Rbcl constaints\n",
    "    #Retrieve flux expressions oof each RBCl reaction\n",
    "    rbpc_M = model.reactions.RBPCs_M.flux_expression\n",
    "    rbpc_BS = model.reactions.RBPCs_BS.flux_expression\n",
    "    rbpo_M = model.reactions.RBPOs_M.flux_expression\n",
    "    rbpo_BS = model.reactions.RBPOs_BS.flux_expression\n",
    "\n",
    "    #Constraint such that it is limited to 132 umol m-2 s-1\n",
    "    rbcl_vcmax_cons = model.problem.Constraint(rbpc_M + rbpc_BS, lb = 0, ub= 132)\n",
    "    rbcl_vcmax_cons.name='rbcl_vcmax_cons'\n",
    "    model.add_cons_vars(rbcl_vcmax_cons)\n",
    "    #Constraints for rbcl flux such that v_c/v_o = 3 or higher.\n",
    "    rbcl_vcvo = model.problem.Constraint(3*(rbpo_M + rbpo_BS) \n",
    "                                         - 1*(rbpc_M + rbpc_BS),\n",
    "                                         lb=0,ub=1000)\n",
    "    rbcl_vcvo.name = 'rbcl_vc/vo_ratio'\n",
    "    model.add_cons_vars(rbcl_vcvo)\n",
    "\n",
    "    #Turn off the RBPC2s reactions since we already defined the constraints above\n",
    "    model.reactions.RBPC2s_M.bounds = (0,0)\n",
    "    model.reactions.RBPC2s_BS.bounds = (0,0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #What if I simply constrained that of the M cell one to 3:1?\n",
    "    #This constraint is pretty good actually. \n",
    "    #This allows the system to be set at a specific Vc/Vo rate while still allowing local variation \n",
    "    #wherein Rubisco may act in an uncoupled fashion and may have favorable internal vc/vo rates.\n",
    "# #This code block is to set a constraint such that M-to-BS cell NGAM ratio is 10-to-1 \n",
    "# #Similar to what Moreno-Villena et al (2022) had done \n",
    "\n",
    "#This function takes two arguments: the model and the maximal  ppfd input to the system\n",
    "def add_ngam_cons(model, ppfd): \n",
    "    ngam_atp_m = mm.get_rxn(model, 'ngam_atp_c_M')\n",
    "    ngam_atp_bs = mm.get_rxn(model, 'ngam_atp_c_BS')\n",
    "    ngam_atp_m.bounds = (0,inf)\n",
    "    ngam_atp_bs.bounds = (0,inf)\n",
    "    ngam_ratio = mm.set_fix_flux_ratio({ngam_atp_m.id:10, ngam_atp_bs.id:1}, model)\n",
    "    ngam_ratio.name = 'ngam_BS/M_ratio'\n",
    "    model.add_cons_vars(ngam_ratio)\n",
    "\n",
    "    #Retrieve NGAM reactions\n",
    "    ngam_nadphox_c_M = mm.get_rxn(model, 'ngam_nadphox_c_M')\n",
    "    ngam_nadphox_s_M = mm.get_rxn(model, 'ngam_nadphox_s_M')\n",
    "    ngam_nadphox_m_M = mm.get_rxn(model, 'ngam_nadphox_m_M')\n",
    "    ngam_nadphox_c_BS = mm.get_rxn(model, 'ngam_nadphox_c_BS')\n",
    "    ngam_nadphox_s_BS = mm.get_rxn(model, 'ngam_nadphox_s_BS')\n",
    "    ngam_nadphox_m_BS = mm.get_rxn(model, 'ngam_nadphox_m_BS')\n",
    "\n",
    "\n",
    "    #Set Fixed fluxes\n",
    "    nadphox_c_s_M = mm.set_fix_flux_ratio({ngam_nadphox_c_M.id:1, ngam_nadphox_s_M.id:1},model)\n",
    "    nadphox_c_s_M.name = \"nadphox_cs_ratio_M\"\n",
    "    nadphox_s_m_M = mm.set_fix_flux_ratio({ngam_nadphox_s_M.id:1, ngam_nadphox_m_M.id:1}, model)\n",
    "    nadphox_s_m_M.name = \"nadphox_sm_ratio_M\"\n",
    "\n",
    "    nadphox_c_s_BS = mm.set_fix_flux_ratio({ngam_nadphox_c_BS.id:1, ngam_nadphox_s_BS.id:1},model)\n",
    "    nadphox_c_s_BS.name = \"nadphox_cs_ratio_BS\"\n",
    "    nadphox_s_m_BS = mm.set_fix_flux_ratio({ngam_nadphox_s_BS.id:1, ngam_nadphox_m_BS.id:1}, model)\n",
    "    nadphox_s_m_BS.name = \"nadphox_sm_ratio_BS\"\n",
    "\n",
    "    #Add constraints\n",
    "    model.add_cons_vars(nadphox_c_s_M)\n",
    "    model.add_cons_vars(nadphox_s_m_M)\n",
    "    model.add_cons_vars(nadphox_c_s_BS)\n",
    "    model.add_cons_vars(nadphox_s_m_BS)\n",
    "\n",
    "    #Retrieve flux expressionns\n",
    "    fex_nadphox_c_M =  mm.get_flux_exp(model, ngam_nadphox_c_M)\n",
    "    fex_nadphox_s_M = mm.get_flux_exp(model, ngam_nadphox_s_M)\n",
    "    fex_nadphox_m_M = mm.get_flux_exp(model, ngam_nadphox_m_M)\n",
    "\n",
    "    fex_nadphox_c_BS =  mm.get_flux_exp(model, ngam_nadphox_c_BS)\n",
    "    fex_nadphox_s_BS =  mm.get_flux_exp(model, ngam_nadphox_s_BS)\n",
    "    fex_nadphox_m_BS =  mm.get_flux_exp(model, ngam_nadphox_m_BS)\n",
    "\n",
    "    fex_atp_c_M = mm.get_flux_exp(model, ngam_atp_m)\n",
    "    fex_atp_c_BS =  mm.get_flux_exp(model, ngam_atp_bs)\n",
    "\n",
    "    #Set the constraint between ATP:NADPH NGAM to 3:1\n",
    "    nadphox_atpase = model.problem.Constraint(3*(fex_nadphox_c_M + fex_nadphox_s_M + fex_nadphox_m_M\n",
    "                                                       + fex_nadphox_c_BS + fex_nadphox_s_BS + fex_nadphox_m_BS) \n",
    "                                         - 1*(fex_atp_c_M + fex_atp_c_BS),\n",
    "                                         lb=0,ub=0)\n",
    "    nadphox_atpase.name = \"nadphox_atpase_ratio\"\n",
    "    model.add_cons_vars(nadphox_atpase)\n",
    "    #Compute NGAM value and add constraint as a lower bound/upper bound to model\n",
    "    ngam_value = compute_ngam_atp(ppfd)\n",
    "    ngam_cons = model.problem.Constraint(fex_atp_c_M + \n",
    "                                        fex_atp_c_BS, lb=ngam_value, ub=ngam_value)\n",
    "    ngam_cons.name = 'NGAM_ATP_constraint'\n",
    "    model.add_cons_vars(ngam_cons)\n",
    "    \n",
    "#This code  block gives a snapshot of the relevant fluxes on each of the cell types based on the saved sample_fluxes values above\n",
    "\n",
    "def print_summary(model, sample_fluxes_df):\n",
    "    print('rbcl M cell: ', sample_fluxes['RBPCs_M'], 'rbcl BS cell: ',sample_fluxes['RBPCs_BS'])\n",
    "    print('rbcl M cell (photorespiration)', sample_fluxes['RBPOs_M'], 'rbcl BS cell (PR)', sample_fluxes['RBPOs_BS'])\n",
    "    print('vc/vo M:', sample_fluxes['RBPCs_M']/sample_fluxes['RBPOs_M'], 'vc/vo BS:', sample_fluxes['RBPCs_BS']/sample_fluxes['RBPOs_BS'])\n",
    "    print('RBPC2s_M', sample_fluxes['RBPC2s_M'], 'RBPC2s_BS', sample_fluxes['RBPC2s_BS'])\n",
    "    print('PEPC M', sample_fluxes['PPCc_M'], 'PEPC BS', sample_fluxes['PPCc_BS'])\n",
    "    print('Carbonic Anhydrase (Cytosolic) M', sample_fluxes['HCO3Ec_M'], 'Carbonic Anhydrase (Cytosolic) BS', sample_fluxes['HCO3Ec_BS'])\n",
    "    print('NADP-ME M', sample_fluxes['MDHys_M'], 'NADP-ME BS', sample_fluxes['MDHys_BS'])\n",
    "    print('Biomass M: ', sample_fluxes['Straw_Biomass_M'], 'Biomass BS', sample_fluxes['Straw_Biomass_BS'])\n",
    "    print('Phloem M: ', sample_fluxes['DM_Phloem_M'], 'Phloem BS', sample_fluxes['DM_Phloem_BS'])\n",
    "    print('co2 consumption M', sample_fluxes['CO2tex_M'], 'co2 consumption BS', sample_fluxes['CO2tex_BS'])\n",
    "    print('o2 consumption M', sample_fluxes['O2tex_M'], 'o2 consumption BS', sample_fluxes['O2tex_BS'])\n",
    "    print('Photosystem II M', sample_fluxes['PSIINC_M'], 'PSII BS', sample_fluxes['PSIINC_BS'])\n",
    "    print('PSI M', sample_fluxes['PSIMR_M'], 'PSI BS', sample_fluxes['PSIMR_BS'])\n",
    "    print('PPFD M: ', sample_fluxes['PRISM_white_LED_M'], 'PPFD BS: ', sample_fluxes['PRISM_white_LED_BS'])\n",
    "    print('ATP synthesis (stromal) M', sample_fluxes['ATPSs_M'], 'ATP synthase (mit) M', sample_fluxes['ATPSm_M'])\n",
    "    pd_rxn = [x for x in model.reactions if \"pd\" in x.id and \"h2o\" not in x.id]\n",
    "    pd_abs_flux = 0\n",
    "    for pds in pd_rxn:\n",
    "        pd_abs_flux += abs(sample_fluxes[pds.id])\n",
    "    \n",
    "    print('pd_abs_flux: ', pd_abs_flux)\n",
    "    \n",
    "#initialize list of transgenic reactions to add  to model\n",
    "\n",
    "def add_trans_reactions(model):\n",
    "    '''\n",
    "    This function is used to add a number of new tissue-specific reactions that were not present in the\n",
    "    original model to facilitate modelling of the transgenic C4 rice\n",
    "    '''\n",
    "    trans_list = list()\n",
    "    #Transgenic PEPC copy\n",
    "    #PEPC = Chloroplastic in M & V (rxn id: PPCc)\n",
    "    trans_ppcs = Reaction('trans_PPCs_M')\n",
    "    trans_ppcs.name = \"Phosphoenolpyruvate carboxylase, plastidic (Transgenic)\"\n",
    "    \n",
    "    pep_s0 = model.metabolites.pep_s0\n",
    "    hco3_s0 = model.metabolites.hco3_s0\n",
    "    oaa_s0 = model.metabolites.oaa_s0\n",
    "    pi_s0 = model.metabolites.pi_s0\n",
    "\n",
    "\n",
    "    #Add metabolites, bounds, and subsystem\n",
    "    trans_ppcs.add_metabolites({hco3_s0:-1, pep_s0:-1, oaa_s0:1, pi_s0:1})\n",
    "    trans_ppcs.bounds= model.reactions.PPCc_M.bounds\n",
    "    trans_ppcs.subsystem = model.reactions.PPCc_M.subsystem\n",
    "\n",
    "    trans_list.append(trans_ppcs)\n",
    "\n",
    "\n",
    "    #Transgenic PPDK Copy\n",
    "    #Since it already exists I'll just copy and readd it\n",
    "    trans_ppdks_m = Reaction('trans_PPDKs_M')\n",
    "    trans_ppdks_m.add_metabolites(model.reactions.PPDKs_M.metabolites)\n",
    "    trans_ppdks_m.bounds = model.reactions.PPDKs_M.bounds\n",
    "    trans_ppdks_m.name = \"Pyruvate phosphate dikinase, plastidic (Transgenic)\"\n",
    "\n",
    "    trans_ppdks_bs = Reaction('trans_PPDKs_BS')\n",
    "    trans_ppdks_bs.add_metabolites(model.reactions.PPDKs_BS.metabolites)\n",
    "    trans_ppdks_bs.bounds = model.reactions.PPDKs_BS.bounds\n",
    "    trans_ppdks_bs.name = \"Pyruvate phosphate dikinase, plastidic (Transgenic)\"\n",
    "\n",
    "    trans_list.append(trans_ppdks_m)\n",
    "    trans_list.append(trans_ppdks_bs)\n",
    "\n",
    "\n",
    "    #Transgenic NADP-ME\n",
    "    #NADP-ME = Mitochondrial in M\n",
    "    trans_nadp_me = Reaction('trans_MDHym_M')\n",
    "\n",
    "    #retrieve reactants\n",
    "    mal_m0 = model.metabolites.get_by_id('mal-L_m0')\n",
    "    nadp_m0 = model.metabolites.nadp_m0\n",
    "    h_m0 = model.metabolites.h_m0\n",
    "    nadph_m0 = model.metabolites.nadph_m0\n",
    "    oaa_m0 = model.metabolites.oaa_m0\n",
    "\n",
    "    #Add to rxn\n",
    "    trans_nadp_me.add_metabolites({mal_m0:-1, nadp_m0:-1, h_m0:1, nadph_m0:1, oaa_m0:1})\n",
    "    #Add bounds\n",
    "    trans_nadp_me.bounds=(-inf, inf)\n",
    "\n",
    "    trans_list.append(trans_nadp_me)\n",
    "\n",
    "\n",
    "    #Malate Dehydrogenase, mitochondrial (M cell)\n",
    "    trans_MDHm_M = Reaction('trans_MDHm_M')\n",
    "    trans_MDHm_M.name = 'Malate Dehydrogenase, Mitochondrial'\n",
    "    trans_MDHm_M.add_metabolites(model.reactions.MDHm_M.metabolites)\n",
    "    trans_MDHm_M.subsystem = model.reactions.MDHm_M.subsystem\n",
    "\n",
    "    trans_list.append(trans_MDHm_M)\n",
    "\n",
    "    #Malate dehydrogenase, plastidic (M cell)\n",
    "    trans_MDHs_M = Reaction('trans_MDHs_M')\n",
    "    trans_MDHs_M.name = 'Malate Dehydrogenase, Plastidic'\n",
    "    trans_MDHs_M.add_metabolites(model.reactions.MDHs_M.metabolites)\n",
    "    trans_MDHs_M.subsystem = model.reactions.MDHs_M.subsystem\n",
    "\n",
    "    trans_list.append(trans_MDHs_M)\n",
    "\n",
    "    #Malate dehydrogenase, plastidic(BS Cell)\n",
    "    trans_MDHs_BS = Reaction('trans_MDHs_BS')\n",
    "    trans_MDHs_BS.name = 'Malate Dehydrogenase, Plastidic'\n",
    "    trans_MDHs_BS.add_metabolites(model.reactions.MDHs_BS.metabolites)\n",
    "    trans_MDHs_BS.subsystem = model.reactions.MDHs_BS.subsystem\n",
    "\n",
    "    trans_list.append(trans_MDHs_BS)\n",
    "\n",
    "\n",
    "    #Trans CA\n",
    "    #Cytosolic in M\n",
    "    trans_hco3ec_M = Reaction('trans_hco3ec_M')\n",
    "    trans_hco3ec_M.name = 'carbonic anhydrase, cytosolic'\n",
    "    trans_hco3ec_M.add_metabolites(model.reactions.HCO3Ec_M.metabolites)\n",
    "    trans_hco3ec_M.bounds = model.reactions.HCO3Ec_M.bounds\n",
    "\n",
    "    trans_hco3ec_M.subsystem = model.reactions.HCO3Ec_M.subsystem\n",
    "    trans_list.append(trans_hco3ec_M)\n",
    "\n",
    "\n",
    "    #Bulk add to model\n",
    "    model.add_reactions(trans_list)\n",
    "    \n",
    "    model.repair()\n",
    "####ADDING TRANS CONSTRAINTS\n",
    "\n",
    "def add_trans_constraints(model,\n",
    "                         trans_pepc_rates = 7.01,\n",
    "                         trans_ppdks_rates = 3.66,\n",
    "                         trans_mdh_rates = 152.87,\n",
    "                         trans_nadp_me_rates = 0.60,\n",
    "                         trans_CA_rates = 8):\n",
    "    '''\n",
    "    This function is used to add another layer of constraints to parametize model based on the\n",
    "    Enzyme reaction rates assayed from Ermakova et al (2021) where the locations are based on the \n",
    "    each of the transgenic enzyme's tissue-specific localizations. \n",
    "    '''\n",
    "    \n",
    "    #PEPC constraint\n",
    "    wt_PPCc_M = mm.get_rxn(model, 'PPCc_M')\n",
    "    wt_PPCc_BS = mm.get_rxn(model, 'PPCc_BS')\n",
    "    trans_PPCs_M = mm.get_rxn(model, 'trans_PPCs_M')                           \n",
    "    trans_PEPC_cons = model.problem.Constraint(trans_PPCs_M.flux_expression\n",
    "                                            +wt_PPCc_BS.flux_expression \n",
    "                                            + wt_PPCc_M.flux_expression, \n",
    "                                            lb = 0, ub = trans_pepc_rates)\n",
    "\n",
    "    model.add_cons_vars(trans_PEPC_cons)\n",
    "\n",
    "    #PPDK constraint\n",
    "    trans_PPDKs_M  = mm.get_rxn(model, 'trans_PPDKs_M')\n",
    "    trans_PPDKs_BS = mm.get_rxn(model, 'trans_PPDKs_BS')\n",
    "    wt_PPDKs_M = mm.get_rxn(model, 'PPDKs_M')\n",
    "    wt_PPDKs_BS = mm.get_rxn(model, 'PPDKs_BS')\n",
    "    \n",
    "    trans_PPDKs_cons = model.problem.Constraint( \n",
    "        trans_PPDKs_BS.flux_expression + trans_PPDKs_M.flux_expression \n",
    "        +wt_PPDKs_BS.flux_expression + wt_PPDKs_M.flux_expression, \n",
    "                                             lb = 0, ub = trans_ppdks_rates)\n",
    "    trans_PPDKs_cons.name = 'trans_ppdks_cons'\n",
    "    model.add_cons_vars(trans_PPDKs_cons)\n",
    "\n",
    "\n",
    "    #Malate Dehydrogenase Constraints\n",
    "    trans_MDHm_M = mm.get_rxn(model, 'trans_MDHm_M')\n",
    "    trans_MDHs_M = mm.get_rxn(model, 'trans_MDHs_M')\n",
    "    trans_MDHs_BS = mm.get_rxn(model, 'trans_MDHs_BS')\n",
    "    wt_MDHm_M =  mm.get_rxn(model, 'MDHm_M')\n",
    "    wt_MDHs_M = mm.get_rxn(model, 'MDHs_M')\n",
    "    wt_MDHs_BS = mm.get_rxn(model, 'MDHs_BS')\n",
    "    \n",
    "    trans_mdh_cons =  model.problem.Constraint(\n",
    "       trans_MDHm_M.flux_expression + \n",
    "        wt_MDHm_M.flux_expression + \n",
    "        trans_MDHs_M.flux_expression + \n",
    "        trans_MDHs_BS.flux_expression +\n",
    "        wt_MDHs_BS.flux_expression +\n",
    "        wt_MDHs_M.flux_expression, \n",
    "        lb= 0, ub=trans_mdh_rates)\n",
    "\n",
    "    trans_mdh_cons.name = \"trans_mdh_cons\"\n",
    "    model.add_cons_vars(trans_mdh_cons)\n",
    "\n",
    "    #Add NADP-ME constraints\n",
    "    trans_MDHym_M = mm.get_rxn(model, 'trans_MDHym_M')\n",
    "    wt_MDHys_M = mm.get_rxn(model, 'MDHys_M')\n",
    "    wt_MDHys_BS = mm.get_rxn(model, 'MDHys_BS')\n",
    "    \n",
    "    trans_nadpme_cons = model.problem.Constraint(\n",
    "        trans_MDHym_M.flux_expression + \n",
    "        wt_MDHys_M.flux_expression + \n",
    "        wt_MDHys_BS.flux_expression,\n",
    "        lb= 0, ub=trans_nadp_me_rates)\n",
    "    \n",
    "    trans_nadpme_cons.name = \"trans_nadpme\"\n",
    "    model.add_cons_vars(trans_nadpme_cons)\n",
    "\n",
    "    #Add carbonic anhydrase constraints\n",
    "\n",
    "    trans_hco3ec_M = mm.get_rxn(model, 'trans_hco3ec_M')\n",
    "    wt_hco3ec_M = mm.get_rxn(model, 'HCO3Ec_M')\n",
    "    wt_hco3em_M = mm.get_rxn(model, 'HCO3Em_M')\n",
    "    wt_hco3es_M = mm.get_rxn(model, 'HCO3Es_M')\n",
    "    wt_hco3ec_BS = mm.get_rxn(model, 'HCO3Ec_BS')\n",
    "    wt_hco3em_BS = mm.get_rxn(model, 'HCO3Em_BS')\n",
    "    wt_hco3es_BS = mm.get_rxn(model, 'HCO3Es_BS')\n",
    "    \n",
    "    trans_ca_cons = model.problem.Constraint(trans_hco3ec_M.flux_expression + \n",
    "                                             wt_hco3es_M.flux_expression + \n",
    "                                             wt_hco3ec_M.flux_expression + \n",
    "                                             wt_hco3em_M.flux_expression + \n",
    "                                             wt_hco3es_BS.flux_expression + \n",
    "                                             wt_hco3ec_BS.flux_expression + \n",
    "                                             wt_hco3em_BS.flux_expression,\n",
    "                                      lb = -trans_CA_rates, ub = trans_CA_rates)\n",
    "    trans_ca_cons.name = 'Trans_CA_cons'\n",
    "    model.add_cons_vars(trans_ca_cons)\n",
    "    model.repair()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24d08460-95dc-4dea-ae6e-a7c85ca4122e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_flux_samples(model, num_samples, batch_size, output_filename ,thinning,output_dir='./flux_results/flux_sampling/'):\n",
    "    #This function is used to initialize a flux sampler and afterwards generate a csv file containing the sample solutions.\n",
    "    #default batch size is 1000\n",
    "\n",
    "    #Generate sampler\n",
    "    print(\"generating sampler for model\")\n",
    "    sampler = sampling.OptGPSampler(model, processes=7, thinning=thinning)\n",
    "    \n",
    "    \n",
    "    #Define output file\n",
    "    output_dir = str(output_dir)\n",
    "    output_filename = str(output_filename)\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    print('saving output to ', f\"{output_dir}/{output_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(num_samples // batch_size):\n",
    "        print(f\"Generating batch {i+1}/{num_samples//batch_size}\")\n",
    "        samples = sampler.sample(n=batch_size)\n",
    "        df = pd.DataFrame(samples, columns=model.reactions.list_attr(\"id\"))\n",
    "        if i == 0:\n",
    "            df.to_csv(f\"{output_dir}/{output_filename}\", index=False)\n",
    "        else:\n",
    "            df.to_csv(f\"{output_dir}/{output_filename}\", index=False, header=False, mode=\"a\")\n",
    "#             \n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "def parametrize_model(model, ppfd_low, ppfd_high, co2,if_trans, filter_list=list()):\n",
    "    \n",
    "    print('start time for parametrize_model(): ' ,datetime.datetime.now())\n",
    "\n",
    "    #Generates a parametrized model which returns the parametrized model as a callable object.\n",
    "    \n",
    "    #Copy model \n",
    "    model_instance = model.copy()\n",
    "                                                                                                                                                                                                                                \n",
    "    model_instance.medium = define_model_medium(model_instance, co2=co2, o2=inf, ppfd=inf, h=inf, nh4=inf, no3=inf)\n",
    "    turn_off_cofac_cycles(model_instance)\n",
    "    add_tissue_constraints(model_instance)\n",
    "    add_enzyme_constraints(model_instance)\n",
    "\n",
    "    #Adds NGAM (Computed as an average between the high and low instead of directly constraining it to the model, w/c makes the problem non-linear)\n",
    "    add_ngam_cons(model_instance, (ppfd_high+ppfd_low)/2)\n",
    "\n",
    "    #Constrain PPFD range to indicated value\n",
    "    model_instance.reactions.get_by_id('EX_photonVis(e)').bounds = (-1*ppfd_high, -1*ppfd_low)\n",
    "    \n",
    "\n",
    "    #Check if trans then add constraints if true\n",
    "    if if_trans==True:\n",
    "        add_trans_reactions(model_instance)\n",
    "        add_trans_constraints(model_instance)\n",
    "    \n",
    "    \n",
    "    #Readd objective coefficient, maybe it'll work?\n",
    "    model_instance.reactions.get_by_id('DM_Phloem_BS').objective_coefficient = 1\n",
    "    \n",
    "    #Run FVA to preprocess the model to fix reaction reversibilities as well as to ensure that there are no \"extreme\" fluxes in the final sampling\n",
    "    # Perform Flux Variability Analysis (FVA)\n",
    "    #This step constrains the upper and lower bounds to the detected \"Maximal\" and \"minimal\" fluxes given an objective\n",
    "    #The default fraction of optimum will be implemented\n",
    "    #Will implement pFBA factor to constrain the model to 110% of the detected lowest flux \n",
    "    \n",
    "    #flux_variability_analysis produces a Pandas Dataframe that can be taken apart and applied to the model_instance as direct bounds. \n",
    "    fva_result = cobra.flux_analysis.flux_variability_analysis(model_instance, pfba_factor=1.1, processes=7)\n",
    "\n",
    "    # Set FVA constraints in the model\n",
    "    for reaction_id, bounds in fva_result.iterrows():\n",
    "        reaction = model_instance.reactions.get_by_id(reaction_id)\n",
    "        # Add tolerance to handle numerical precision issues\n",
    "        tol = model_instance.tolerance\n",
    "        reaction.bounds = (bounds['minimum'] - tol, bounds['maximum'] + tol)\n",
    "        #No issues so far with adding a tolerance value)\n",
    "        \n",
    "    #    # Identify and prune blocked reactions\n",
    "    #I don't think this is necessary anymore since I'm filtering the reactions anyway\n",
    "    blocked_reactions = cobra.flux_analysis.variability.find_blocked_reactions(model_instance, processes=7, zero_cutoff=tol)\n",
    "    model_instance.remove_reactions(blocked_reactions)\n",
    "    \n",
    "    \n",
    "    #Remove reactions that are not in the filtered list\n",
    "\n",
    "    print(len(model_instance.reactions))\n",
    "    \n",
    "    if len(filter_list) > 0:\n",
    "        filt_rxns = list()\n",
    "        for rxns in model_instance.reactions:\n",
    "            if rxns.id not in filter_list:\n",
    "                filt_rxns.append(rxns.id)\n",
    "\n",
    "        model_instance.remove_reactions(filt_rxns)\n",
    "    \n",
    "    print(len(model_instance.reactions))\n",
    "    \n",
    "    # Identify unneeded metabolites\n",
    "    unneeded_metabolites = []\n",
    "    for metabolite in model.metabolites:\n",
    "        if metabolite.reactions == []:\n",
    "            unneeded_metabolites.append(metabolite)\n",
    "\n",
    "    # Remove unneeded metabolites from the model\n",
    "    model.remove_metabolites(unneeded_metabolites)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('end time for parametrize_model(): ' ,datetime.datetime.now())\n",
    "\n",
    "    \n",
    "    return model_instance\n",
    "\n",
    "\n",
    "\n",
    "def save_model_bounds(model, filename, directory='./flux_results/flux_sampling/model_bounds/'):\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Get the bounds of each reaction in the model\n",
    "    bounds = []\n",
    "    for reaction in model.reactions:\n",
    "        bounds.append([reaction.id, reaction.bounds[0], reaction.bounds[1]])\n",
    "\n",
    "    # Create a DataFrame with the bounds\n",
    "    bounds_df = pd.DataFrame(bounds, columns=['Reaction', 'Lower Bound', 'Upper Bound'])\n",
    "\n",
    "    # Write the DataFrame to a CSV file\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    bounds_df.to_csv(filepath, index=False)\n",
    "\n",
    "    print(f\"Model bounds saved to: {filepath}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca406088-5276-4af4-b78f-fbb3a3a0432c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating parametrized models for flux sampling\n",
      "start time for parametrize_model():  2023-06-15 20:28:44.509744\n",
      "Read LP format model from file /tmp/tmpmk7lok_l.lp\n",
      "Reading time = 0.02 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'numeric'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n",
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3786\n",
      "3786\n",
      "end time for parametrize_model():  2023-06-15 20:30:18.812996\n",
      "start time for parametrize_model():  2023-06-15 20:30:18.813263\n",
      "Read LP format model from file /tmp/tmpkrymbyv7.lp\n",
      "Reading time = 0.02 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'numeric'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n",
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3760\n",
      "3760\n",
      "end time for parametrize_model():  2023-06-15 20:31:57.088576\n",
      "start time for parametrize_model():  2023-06-15 20:31:57.089130\n",
      "Read LP format model from file /tmp/tmprg3yzt5_.lp\n",
      "Reading time = 0.02 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3898\n",
      "3898\n",
      "end time for parametrize_model():  2023-06-15 20:33:41.323145\n",
      "start time for parametrize_model():  2023-06-15 20:33:41.323429\n",
      "Read LP format model from file /tmp/tmpjjmabmdd.lp\n",
      "Reading time = 0.02 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'numeric'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n",
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3754\n",
      "3754\n",
      "end time for parametrize_model():  2023-06-15 20:35:21.463132\n",
      "start time for parametrize_model():  2023-06-15 20:35:21.463448\n",
      "Read LP format model from file /tmp/tmpfonw6x2h.lp\n",
      "Reading time = 0.02 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3770\n",
      "3770\n",
      "end time for parametrize_model():  2023-06-15 20:36:59.025677\n",
      "start time for parametrize_model():  2023-06-15 20:36:59.025954\n",
      "Read LP format model from file /tmp/tmpbpgocqow.lp\n",
      "Reading time = 0.02 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3890\n",
      "3890\n",
      "end time for parametrize_model():  2023-06-15 20:38:53.445091\n",
      "generating flux samples for parametrized models\n",
      "start time for sampler generation:  2023-06-15 20:38:53.445599\n",
      "Model bounds saved to: ./flux_results/flux_sampling/model_bounds/flux_sample_WT_250\n",
      "generating sampler for model\n",
      "Read LP format model from file /tmp/tmpqzsc3dub.lp\n",
      "Reading time = 0.01 seconds\n",
      ": 3970 rows, 7578 columns, 32242 nonzeros\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "\n",
    "\n",
    "#Parametrize models per type by generating model instance\n",
    "print('Generating parametrized models for flux sampling')\n",
    "WT_250 =  parametrize_model(wt_model, 225,275,co2=29, if_trans=False)\n",
    "WT_750 = parametrize_model(wt_model, 725, 775,co2=29, if_trans=False)\n",
    "WT_1500 = parametrize_model(wt_model, 1475, 1525,co2=29, if_trans=False)\n",
    "\n",
    "TR_250 = parametrize_model(wt_model, 225, 275,co2=22.2, if_trans=True)\n",
    "TR_750 = parametrize_model(wt_model, 725, 775,co2=22.2, if_trans=True)\n",
    "TR_1500 = parametrize_model(wt_model, 1475, 1525,co2=22.2, if_trans=True)\n",
    "\n",
    "#Generate list of models for flux sampling\n",
    "sampling_list = [WT_250, WT_750, WT_1500, TR_250, TR_750, TR_1500]\n",
    "\n",
    "print('generating flux samples for parametrized models')\n",
    "for model in sampling_list:\n",
    "    print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "    model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "    name_for_file = str('flux_sample_'+model_name)\n",
    "    \n",
    "    #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "    save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "    generate_flux_samples(model, num_samples =5000, batch_size=2500, thinning=35000, output_filename=name_for_file)\n",
    "    del model #Deletes model instance to free up memory \n",
    "    print('end time: ', datetime.datetime.now())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f32aa0e-9d20-4534-86a2-c936ee48ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "#This code block is for a version of the above but it filters the model first then afterwards resamples the model\n",
    "\n",
    "#Load filter list \n",
    "filter_list = []\n",
    "\n",
    "def run_sampler_script1():\n",
    "    # Load the CSV file and store its contents into the 2-dimensional list\n",
    "    with open('./misc/filtered_reactions_from_sampling.csv', 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            filter_list.append(row)\n",
    "\n",
    "\n",
    "    #Parametrize models per type by generating model instance\n",
    "    print('Generating parametrized models for flux sampling')\n",
    "    WT_250 =  parametrize_model(wt_model, 225,275,co2=29, filter_list=filter_list[0],if_trans=False)\n",
    "    WT_750 = parametrize_model(wt_model, 725, 775,co2=29, filter_list=filter_list[1],if_trans=False)\n",
    "    WT_1500 = parametrize_model(wt_model, 1475, 1525,co2=29, filter_list=filter_list[2], if_trans=False)\n",
    "\n",
    "    TR_250 = parametrize_model(wt_model, 225, 275,co2=22.2, filter_list=filter_list[3],if_trans=True)\n",
    "    TR_750 = parametrize_model(wt_model, 725, 775,co2=22.2, filter_list=filter_list[4],if_trans=True)\n",
    "    TR_1500 = parametrize_model(wt_model, 1475, 1525,co2=22.2, filter_list=filter_list[5],if_trans=True)\n",
    "\n",
    "    #Generate list of models for flux sampling\n",
    "    sampling_list = [WT_250, WT_750, WT_1500, TR_250, TR_750, TR_1500]\n",
    "    \n",
    "    \n",
    "    #Generate sampler and start the OPTGP sampler\n",
    "    print('generating flux samples for parametrized models')\n",
    "    for model in sampling_list:\n",
    "        print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "        model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "        name_for_file = str('flux_sample_'+model_name+'filtered_75000T')\n",
    "\n",
    "        #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "        save_model_bounds(model, filename=name_for_file)\n",
    "\n",
    "        generate_flux_samples(model, num_samples =5000, batch_size=5000, thinning=100000, output_filename=name_for_file)\n",
    "        del model #Deletes model instance to free up memory \n",
    "        print('end time: ', datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a773b485-14e6-4140-b15a-ffc36235f6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating parametrized models for flux sampling\n",
      "start time for parametrize_model():  2023-06-15 08:40:06.705128\n",
      "Read LP format model from file /tmp/tmpgp_x9qyq.lp\n",
      "Reading time = 0.02 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n"
     ]
    }
   ],
   "source": [
    "run_sampler_script1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b10e5-c885-4c13-81c9-911f892789cc",
   "metadata": {},
   "source": [
    "Notes: needed to repeat sampling due to the following:\n",
    "- sampling matrices are too large to load, compensate with the use of thinning instead. Use specifications from Hermann et al (2020) which uses instead a thinning coefficient of 10000 instead of keeping all samples. My original parameters were n = 50000, batch size = 2000 and thinning = 500. \n",
    "- Maybe I should use a thinning coefficient of 100000 instead? Since my model has a number of dimensions one exponent higher than the previously benchmarked Arnold Model\n",
    "    - I've decided to run my model with a thinning coefficient of 25000. Hopefully autocorrelation and convergence wouldn't be much of an issue. Total samples would be equal in turn to 1.25e8 individual sampling points. \n",
    "\n",
    "- I needed to reparametrize samples considering that the objective function doesn't apply in flux sampling. INstead of adding an objective coefficient all demand reactions that output biomass are turned off except for \"DM_Phloem_BS\". What I need to do instead is re-parametrize it to allow photoassimilates to exit at that reaction rather than to others.\n",
    "- I'll save the format to \".npz\" instead of \"csv\" since I'm running out of memory whenever I'm loading it out of this script. I think the output of the model is sparse enough that I can instead use this format instead.\n",
    "    - Actually I can save my csv to a normal csv once since I can just adjust the thinning number instead of keeping all samples.\n",
    "\n",
    "- It is still a question whether my samples are uncorrelated or not. I will run the diagnostic tests after I finish running the rest of the scripts.\n",
    "\n",
    "\n",
    "\n",
    "Note: May 17 2023\n",
    "Flux sampling script was interrupted @ TR750 and was rerun at that point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae799577-6b2a-444f-9f90-aa72715e0ec2",
   "metadata": {},
   "source": [
    "Notes: \n",
    "OPTGP Is shown to be faster than ACHR and also converges faster\n",
    "\n",
    "Let's try with a 10 samples first with 10 batches\n",
    "\n",
    "I think the model is too large to be loaded into the flux sampler. \n",
    "\n",
    "It initialized after 30 minutes, let's try sampling na. \n",
    "\n",
    "It takes 1-2 hours at most to generate 2000 samples with a thinning coefficient of 10000. Extrapolating from that, we need probably 4-6 hours to generate 5000 samples with a TC of 20000. To keep things tractable I'll keep the thinning coefficient at 10000. I can just add more samples if needed.\n",
    "\n",
    "\n",
    "Things to add to the paper:\n",
    "\n",
    "\n",
    "Flux sampling is another constraints-based technique used for characterizing the null space of a given stoichiometric model, providing us insights on the flux distributions of a given metabolic model without the explicit definition of a given cellular objective. Not only does this technique offer advantages over conventional FBA and FVA where it allows researchers to determine the feasibility of solutions within a given defined range, as well as the distribution of these fluxes provided the model constaints.. The latter, in turn, allows statistical analysis to determine whether any given fluxes exist within a single probability distribution or not. This, in turn, allows a more direct comparison of fluxes and to adequately sample a solution space provided the constraints implemented in the model.\n",
    "\n",
    "The same constraints have been implemented as with the previous set-ups but with a modification with regards to how the objective functions are concerned. Unlike in pFBA where we can set a particular reaction as an objective, no such setting exists for flux sampling. Thus, this setup is in turn reliant on explicitly defined constraints that would define the n reaction-dimensional solution space. To parametrize this, we have turned off all biomass-related demands such as Coleoptile Biomass, Straw_Biomass and the \"DM_Phloem_M\" reaction to force the model to output flux to the \"DM_Phloem_BS\" reaction. Additionally, the model is constrained in a similar manner as with the previous pFBA setups that we had done to benchmark and assess our model's performance.\n",
    "\n",
    "THe benefits of using Flux Sampling compared to other methods such as FVA in characterizing a solution space is that:\n",
    "a. We may establish confidence intervals with the use of statistical tests to fully characterize a given solution space and whether\n",
    "b. Rather than simply generating representative fluxes showing the maximum and minimum amount of possible flux towards a particular reaction, flux sampling allows summary statistics to be generated, including the probability distribution of each particular reaction. \n",
    "c. Lastly, flux sampling allows a detailed comparison of the interdependence of each particular reaction, showing which reactions are coupled to each other in a positive and negative fashion. This is done\n",
    "\n",
    "Three setups per parametrized model were initialized, each with a representative light treatment of 250, 750 and 1500 PPFD with a defined range of +-25, respectively. The NGAM reactions were instead set at a static value at each representative light point detailed above. A total of 6 treatments were initialized to represent both the WT and Trans models at the selected light points. \n",
    "\n",
    "The sampling algorithm used was the OPTGP (optimized general parallel) sampler from the Cobrapy.sampling package. The sampler was parametrized to generate 5000 samples with a thinning coefficient of 25000, representing 1.25x10^8 sampling points, and was multithreaded into 7 processes each. Run times varied from between 3-6 hours per model parametrized, which was expected based on the number of reactions in the parametrized model.\n",
    "\n",
    "\n",
    "After the generation of individual sampling points, convergence statistics were done to assess the level of autocorrelation as well as to assess whether the samplers have sufficiently converged to a singular value. The former is done with the use of the \"acf\" function to assess the level of autocorrelation on each given column, while the latter is assessed with the use of two specific methods -- the Gelman-Rubin and the Geweke statistics. These are two methods that we will use to assess whether the number of sampling points is sufficient to ensure adequate convergence of each reaction in the model. Reactions that have not converged sufficiently will be indicated.\n",
    "\n",
    "After the assessment of autocorrelation and convergence, each of the pairs between light treatments (225-725, 725-1475, 225-1475) and between models (WT and Trans) are subjected to pairwise Kruskal-Wallis tests to assess which reaction pairs are derived from the same distribution. It is a non-parametric rank-based test test suitable for comparing outputs where there are no assumed distributions behind a population, and has been used in a similar fashion in previous flux sampling setups that involve Plant Metabolism  (Herrmann et al., 2019).  \n",
    "\n",
    "This procedure, in turn, allows us to deduce in finer detail which reactions in particular are positively correlated with CO2 flux into the BS cell's Rubisco reaction. In the previous pFBA experiment we were able to demonstrate a similar approach to this by performing a sensitivity analysis on Glycine Decarboxylase, and had demonstrated the negative relationship between M cell GLYDHD and BS Cell GLYDHD.\n",
    "\n",
    "Lastly, we can afterwards assess which fluxes are coupled by iterating over the list of fluxes in a single flux sample matrix and computing the spearman correlations between the pairwise comparisons. From here we can assess which particular reactions are positively or negatively correlated or not. A particular focus will then be held. Further Downstream analysis includes determination of reactions that are positively or negatively coupled with each other and corroborating this fact on whether the reaction is disrupted in the \"Trans\" parametrized model.  \n",
    "\n",
    "\n",
    "\n",
    "May 19, 2023\n",
    "Some observations on the fluxes obtained from initial flux sampling runs:\n",
    "- It seems it doesn't maximize CO2 assimilation as with pFBA. \n",
    "- It features some reactions with infeasibly large fluxes, particularly those expected to have flux cycling.\n",
    "\n",
    "I asked the Gitter group on what are their thoughts on how to approach this.\n",
    "\n",
    "One solution I think is this:\n",
    "- Reparametrize a model first and generate FVA solutions to \"pre-process\" the model, and in turn add directionality and bound constraints to the model to reduce its solution space further.\n",
    "- Try readding the objective function for photoassimilate generation as well as the pfba objective, as well as add the \"cyclefreeflux\" function by Desouki et al (2015).\n",
    "\n",
    "\n",
    "\n",
    "I am currently testing the Latter.\n",
    "\n",
    "May 20, 2023\n",
    "\n",
    "The latter does not work since it applies MILP, I think. It returns the following error:\n",
    "    \n",
    "    TypeError: Sampling does not work with integer problems.\n",
    "\n",
    "I will instead to the former instead. I've also implemented pruning to remove any unused reactions and metabolites based on the find_blocked_reactions() function of FVA. This will further constrain the model to sort of \"Contextualise\" it. \n",
    "\n",
    "\n",
    "May 20, 2023\n",
    "\n",
    "Based on the Geweke Statistic, and with a z-score of 1.96 (indicating 0.95 confidence  interval) most of the samples have converged on a single statistic. Based on the Gelman Rubin statistic however all of the reactions have not converged to a singular solution. Why?\n",
    "\n",
    "I've rerun the diagnostic scripts in R using Coda and have produced a more reliable measure of convergence and autocorrelation. In both cases only \n",
    "\n",
    "I'll test 5000x25000 samples with the reduced and pFVA-constrained models. I think sampling will be faster considering that I've pruned the samples as well as reduced the solution space by a lot. \n",
    "\n",
    "\n",
    "Flux sampling convergence statistics are based on the methods highlighted by Hermmann et al (2019) and by Fallahi et al (2020). It says that we shouldn't use the normal Gelman-Rubin statistic and instead use the Brooks-Gelman formulation instead.\n",
    "\n",
    "However, for both cases I've instead used the Raftery-Lewis statistic and \n",
    "the Geweke Diagnostic to assess convergences for all parameters. I decided to re-run instead the two last samples considering that they both have significant amounts of reactions that haven't converged based on the RL statistic and the GW statistic.\n",
    "\n",
    "For the RL statistic both 250 and 750 parametrized samplers have converged, although the Geweke diagnostic only reports a convergence rate of around 70 percent. In 1500 the convergence rate falls to 40 percent only which necessitates the re-run scenario. AFterwards I can simply re-run the scripts and re-assess my results. In the meantime however I can analyze both 250 and 750 scenarios as well the highb light scenarios particularly those with significantly varying distributions\n",
    "\n",
    "\n",
    "June 13, 2023\n",
    "\n",
    "I have rerun both WT andTR 1500 to validate if both have converged. If it hasn't I'll report the results as-is and include it in the discussion.\n",
    "\n",
    "June 15, 2023\n",
    "\n",
    "I have an idea in order to ensure convergence as well as to reduce runtimes.\n",
    "My idea is to remove all reactions that are not foundd in the model to 0 in order to reduce the nullspace of the model. This will be based on the initial runs for the flux sampling runs. \n",
    "\n",
    "Afterwards I need to compare their distributions based dun sa mga previous runs to determine if pareho yung distribution. If it is the same or virtually the samme I will use it because I can ensure that it has a higher convergence rate than the one with lower samples.\n",
    "\n",
    "If in case this works then it should return the same distribution and my samples would've converged faster. Furthermore there isn't need to go for breadth considering that my parametrizations are already fixed. Hopefully it can converge faster but since I've changed the thinning constant to 100k it may change the distribution.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Pipeline breakdown:\n",
    "\n",
    "Load CSVs to a memory saving format first\n",
    "\n",
    "1.\n",
    "Run convergence statistics on each and generate plots to assess total convergence stats for each CSV. These will include tests such as the \n",
    "Raftery-Lewis statistic and the Geweke statistics to assess both autocorrelation as well as assess convergence.\n",
    "\n",
    "Afterwards get only the flux names of those reactions that have converged\n",
    "Run pairwise Kruskal-wallis tests per CSV using the above list of converged reactions\n",
    "Identify each reaction with significant and non-significant distributions each\n",
    "\n",
    "Generate histograms/probability densities for relevant reactions with significantly different distributions with WT and Trans models.\n",
    "2. Flux coupling analysis\n",
    "Check which fluxes are coupled with each otehr and identify which fluxes are then related to each other, particularly Carbon Fixation reactions in the BS cell such as Rubisco and the DM_Phloem reactions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
