{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a656bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T11:08:41.205406Z",
     "start_time": "2023-03-23T11:08:39.074105Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "import cobra\n",
    "import libsbml\n",
    "import pandas as pd\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import memote\n",
    "import csv\n",
    "import pytest\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xlsxwriter\n",
    "import path \n",
    "import datetime\n",
    "import scipy.sparse as sp\n",
    "import warnings\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from functools import partial  \n",
    "from parallelbar import progress_map\n",
    "\n",
    "\n",
    "from cobra import sampling\n",
    "from cobra import Reaction\n",
    "\n",
    "#Change working dir first, ty ChatGPT, much loves\n",
    "cwd = os.getcwd()\n",
    "# Split the path into a list of directories\n",
    "directories = cwd.split(os.sep)\n",
    "# Remove the last two directories from the list\n",
    "directories = directories[:-2]\n",
    "# Join the directories back into a path\n",
    "new_cwd = os.sep.join(directories)\n",
    "# Change the current working directory to the new path\n",
    "os.chdir(new_cwd)\n",
    "\n",
    "sys.path.append(\"./src\")\n",
    "\n",
    "import model_manipulation  as mm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19cbcb9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T11:14:41.725034Z",
     "start_time": "2023-03-23T11:11:53.801Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This codeblock is to define some of the functions used for modelling\n",
    "\n",
    "##UPDATED JULY 28 2023\n",
    "\n",
    "##NOTES:\n",
    "##Fixed wrong encoding of reactions for Malate dehydrogenase as well as NADP ME.\n",
    "\n",
    "\n",
    "\n",
    "#Define linear relationship between PPFD and Cellular maintainance costs\n",
    "#This formula comes from Topfer et al (2020) where she defined NGAM in a linear relationship with incident light\n",
    "inf=1e6\n",
    "\n",
    "def generate_constraint(model,reaction, name, lb, ub):\n",
    "    reaction_fex = model.reactions.get_by_id(name).flux_expression\n",
    "    constraint = model.problem.Constraint(reaction_fex, lb=lb, ub=ub)\n",
    "    constraint.name = name + '_constraint'\n",
    "    model.add_cons_vars\n",
    "\n",
    "def compute_ngam_atp(ppfd):\n",
    "    v_atp = 0.0049*ppfd + 2.7851\n",
    "    return v_atp\n",
    "\n",
    "\n",
    "#This function is used to set the inputs to the model used. \n",
    "def define_model_medium(model, co2, o2, ppfd, \n",
    "                        medium_dir='./misc/photo_medium.csv', no3=inf, h2o=inf, h=inf, \n",
    "                        nh4=inf, pi=inf):\n",
    "    model_photo_media = mm.read_medium_csv(medium_dir, model)\n",
    "    model_photo_media['EX_no3(e)'] = no3\n",
    "    model_photo_media['EX_h2o(e)'] = h2o\n",
    "    model_photo_media['EX_h(e)'] = h\n",
    "    model_photo_media['EX_nh4(e)'] = nh4\n",
    "    model_photo_media['EX_co2(e)'] = co2\n",
    "    model_photo_media['EX_o2(e)'] = o2\n",
    "    model_photo_media['EX_photonVis(e)'] = ppfd\n",
    "    model_photo_media['EX_pi(e)'] = pi\n",
    "    #Set set model medium as model\n",
    "#     print('Added model medium')\n",
    "    return model_photo_media\n",
    "\n",
    "    \n",
    "def turn_off_cofac_cycles(model, inact_dir='./misc/leaf_inactivated.tsv'):\n",
    "    file = csv.reader(open(inact_dir), delimiter='\\t')\n",
    "    leaf_inactive_rxns = list()\n",
    "    for rows in file:\n",
    "        row_m = str()\n",
    "        row_bs = str()\n",
    "        for rxns in rows:\n",
    "            row_m += str(rxns) + \"_M\"\n",
    "            row_bs += str(rxns) + \"_BS\"\n",
    "        leaf_inactive_rxns.append(row_m)\n",
    "        leaf_inactive_rxns.append(row_bs)\n",
    "        \n",
    "    for rxns in model.reactions:\n",
    "        if rxns.id in leaf_inactive_rxns:\n",
    "            rxns.bounds = (0,0)\n",
    "#     print('Successfully turned off cofactor-cycling reactions')\n",
    "\n",
    "    \n",
    "# #Add constraints to model\n",
    "#This code block contains constraints that would simulate the assimilation rates of bs and m cells in a two-cell system (such as those seen near the midvein region of rice leaves)\n",
    "# #BS photon flux must be the same/less than M flux (Adapted from B&B, 2019)\n",
    "# photon_import = model.reactions.get_by_id(\"EX_photonVis(e)\")\n",
    "def add_tissue_constraints(model):\n",
    "    #For input fluxes for light, we will set the flux ratio to 10:1 to reflect the anatomical proportions of our model ()\n",
    "    \n",
    "    BS_photon_import = model.reactions.PRISM_white_LED_BS\n",
    "    M_photon_import = model.reactions.PRISM_white_LED_M\n",
    "\n",
    "    #Set photon flux ratio to 10:1\n",
    "    photon_flux = mm.set_fix_flux_ratio({M_photon_import.id:10, BS_photon_import.id:1},model)\n",
    "    model.add_cons_vars(photon_flux)\n",
    "\n",
    "    \n",
    "    #UPDATE: Change CO2 intake to the M Cell instead rather than set a ratio, which is a better assumption overall. Assume na lang that external gasses are assimilated\n",
    "    #Via the M cell.\n",
    "    #From Morrison et al 2005 -- Lateral diffusion of Gases is unlikely to support photosynthesis due to the\n",
    "    #assimilation of diffused CO2 in tissues prior to BS//\n",
    "    model.reactions.CO2tex_BS.bounds = (0,0)\n",
    "    model.reactions.O2tex_BS.bounds = (0,0)\n",
    "    \n",
    "    #UPDATE: This assumption does not hold considering that recent transcriptomic analysis confirms that \n",
    "    #the bundle sheath is involved in the assimilation of inorganic nutrients, including nitrogen (nitrates/ammonia), and \n",
    "    #Sulfates. In turn, this will be implemented by simply setting the exchanges to the M cell to 0. (Hua et al, 2021)\n",
    "    model.reactions.SO3tex_M.bounds = (0,0)\n",
    "    model.reactions.SO4tex_M.bounds = (0,0)\n",
    "    model.reactions.NH4tex_M.bounds = (0,0)\n",
    "    model.reactions.NO3tex_M.bounds = (0,0)\n",
    "    \n",
    "    #Model will also constraint H2O input to BS cell only as it is also assumed that BS tissue in rice is specialized for H2O transport (Hua et al. 2021)\n",
    "    #There is a demand reaction naman for H2O for the M cell which is not connected to the BS H2Otex\n",
    "    #Restrict H2O transport to be unidirectional from the BS cell\n",
    "    model.reactions.H2Otex_M.bounds = (0, 0)\n",
    "    model.reactions.h2o_pd.bounds = (-inf, 0)\n",
    "    \n",
    "    #need to turn off HCO import as the model incorrectly transfers fixed HCO to the BS cell via the common pool compartment\n",
    "    model.reactions.HCO3tex_M.bounds = (0,0)\n",
    "    model.reactions.HCO3tex_BS.bounds = (0,0)\n",
    "    \n",
    "    #Turn off extracellular Glycine transport \n",
    "    model.reactions.GLYtex_M.bounds = (0,0)\n",
    "    model.reactions.GLYtex_BS.bounds = (0,0)\n",
    "    \n",
    "    #Turn off other Demand reactions that may serve as sinks for the model except DM_Phloem_BS (Which represents the output of photoassimilate thru the BS cell\n",
    "    model.reactions.DM_Phloem_M.bounds = (0,0)\n",
    "    model.reactions.Straw_Biomass_M.bounds = (0,0)\n",
    "    model.reactions.Straw_Biomass_BS.bounds = (0,0)\n",
    "    model.reactions.Coleoptile_Biomass_M.bounds = (0,0)\n",
    "    model.reactions.Coleoptile_Biomass_BS.bounds = (0,0)\n",
    "    model.reactions.DM_Phloem_BS.bounds = (0, inf)\n",
    "    \n",
    "\n",
    "def add_enzyme_constraints(model, \n",
    "                           wt_pepc = 0, \n",
    "                           wt_mdh = 11.18, \n",
    "                           wt_nadp_me = 0.14, \n",
    "                           wt_ppdk=0.31,\n",
    "                          wt_CA=7.5):\n",
    "    \n",
    "    \n",
    "    # #This code block contains constraints specific for enzyme rate constraints\n",
    "    #This approach is derived from Bogart & Myers (2016) where they constrained the enzyme rate \n",
    "    #fluxes in each of the 2-cell segments to a specific upper bound while keeping the lower bound\n",
    "    #At 0. For reversible reactions the lower bounds are set to the same value\n",
    "    \n",
    "    \n",
    "    #PEPC constraint (Reaction id: PPCc)\n",
    "    #Need to constrain it to 0 since reaction is only detected in Vascular tissue\n",
    "    pepc_BS = model.reactions.PPCc_BS\n",
    "    pepc_M = model.reactions.PPCc_M\n",
    "    \n",
    "    pepc_BS.bounds = (0,0)\n",
    "    pepc_M.bounds = (0,0)\n",
    "\n",
    "    #PPDK constraints (Reaction id: PPDKs) (note that this is found in the chloroplast?) \n",
    "    #Not detected via immunolocalization but enzyme activity is detected\n",
    "\n",
    "    ppdks_BS = model.reactions.PPDKs_BS\n",
    "    ppdks_M = model.reactions.PPDKs_M\n",
    "    ppdkc_BS = model.reactions.PPDKc_BS\n",
    "    ppdkc_M = model.reactions.PPDKc_M\n",
    "    wt_ppdks_cons = model.problem.Constraint(ppdks_BS.flux_expression \n",
    "                                             + ppdks_M.flux_expression\n",
    "                                             + ppdkc_BS.flux_expression\n",
    "                                             + ppdkc_M.flux_expression, \n",
    "                                             lb = 0, ub = wt_ppdk)\n",
    "    wt_ppdks_cons.name = 'wt_ppdks_cons'\n",
    "    model.add_cons_vars(wt_ppdks_cons)\n",
    "    \n",
    "    \n",
    "    #Malate Dehydrogenase \n",
    "    #Only mitochondrial in WT Rice M cells\n",
    "    #Reactions encoded in the model include MDHs, MDHc, MDHx.\n",
    "    model.reactions.MDHs_M.bounds = (0,0)\n",
    "    model.reactions.MDHc_M.bounds = (0,0)\n",
    "    model.reactions.MDHx_M.bounds = (0,0)\n",
    "    model.reactions.MDHs_BS.bounds = (0,0)\n",
    "    model.reactions.MDHc_BS.bounds = (0,0)\n",
    "    model.reactions.MDHx_BS.bounds = (0,0)\n",
    "    model.reactions.MDHm_BS.bounds = (0,0)\n",
    "    #Add constraints to MDHm\n",
    "    mdhm_M = model.reactions.MDHm_M\n",
    "    \n",
    "    wt_mdh_cons = model.problem.Constraint(mdhm_M.flux_expression,\n",
    "                                           lb= -wt_mdh, ub=wt_mdh)\n",
    "    wt_mdh_cons.name = \"wt_mdh_cons\"\n",
    "    model.add_cons_vars(wt_mdh_cons)\n",
    "\n",
    "    \n",
    "    \n",
    "    #NADP-ME (Since no signal is detected in WT, no locational constraints are imposed)\n",
    "    #Let's see if I can force it to have a small amount of flux \n",
    "    mdh2s_M = model.reactions.MDH2s_M\n",
    "    mdh2s_BS = model.reactions.MDH2s_BS\n",
    "    mdh2c_M = model.reactions.MDH2s_M\n",
    "    mdh2c_BS = model.reactions.MDH2s_BS\n",
    "\n",
    "\n",
    "    wt_nadpme_cons = model.problem.Constraint(mdh2s_M.flux_expression\n",
    "                                             + mdh2s_BS.flux_expression\n",
    "                                              + mdh2c_M.flux_expression\n",
    "                                              + mdh2c_BS.flux_expression,\n",
    "                                             lb= 0, ub=wt_nadp_me)\n",
    "    wt_nadpme_cons.name = \"wt_nadpme_cons\"\n",
    "    model.add_cons_vars(wt_nadpme_cons)\n",
    "\n",
    "\n",
    "    #I should add constraints for Carbonic Anhydrase\n",
    "    #I should constrain it to 0.4 ubar, which would constitute ambient CO2 partial pressure\n",
    "    #Flux is reversible so constraints are bi-directional\n",
    "    #This should be revised considering that it allows reversible reactions  and an abnormally high flux thru carbonic anhydrase, which shouldn't be the case\n",
    "\n",
    "    hco3es_m = model.reactions.HCO3Es_M.flux_expression\n",
    "    hco3ec_m = model.reactions.HCO3Ec_M.flux_expression\n",
    "    hco3em_m = model.reactions.HCO3Em_M.flux_expression\n",
    "    hco3es_bs = model.reactions.HCO3Es_BS.flux_expression\n",
    "    hco3ec_bs = model.reactions.HCO3Ec_BS.flux_expression\n",
    "    hco3em_bs = model.reactions.HCO3Em_BS.flux_expression\n",
    "\n",
    "    ca_cons = model.problem.Constraint(hco3es_m + hco3ec_m + hco3em_m \n",
    "                                       + hco3es_bs + hco3ec_bs + hco3em_bs,\n",
    "                                      lb = -wt_CA, ub = wt_CA)\n",
    "    ca_cons.name = 'Carbonic_anhydrase_constraint'\n",
    "    model.add_cons_vars(ca_cons)\n",
    "\n",
    "\n",
    "    #Rbcl constaints\n",
    "    #Retrieve flux expressions oof each RBCl reaction\n",
    "    rbpc_M = model.reactions.RBPCs_M.flux_expression\n",
    "    rbpc_BS = model.reactions.RBPCs_BS.flux_expression\n",
    "    rbpo_M = model.reactions.RBPOs_M.flux_expression\n",
    "    rbpo_BS = model.reactions.RBPOs_BS.flux_expression\n",
    "\n",
    "    #Constraint such that it is limited to 132 umol m-2 s-1\n",
    "    rbcl_vcmax_cons = model.problem.Constraint(rbpc_M + rbpc_BS, lb = 0, ub= 132)\n",
    "    rbcl_vcmax_cons.name='rbcl_vcmax_cons'\n",
    "    model.add_cons_vars(rbcl_vcmax_cons)\n",
    "    #Constraints for rbcl flux such that v_c/v_o = 3 or higher.\n",
    "    rbcl_vcvo = model.problem.Constraint(3*(rbpo_M + rbpo_BS) \n",
    "                                         - 1*(rbpc_M + rbpc_BS),\n",
    "                                         lb=0,ub=1000)\n",
    "    rbcl_vcvo.name = 'rbcl_vc/vo_ratio'\n",
    "    model.add_cons_vars(rbcl_vcvo)\n",
    "\n",
    "    #Turn off the RBPC2s reactions since we already defined the constraints above\n",
    "    model.reactions.RBPC2s_M.bounds = (0,0)\n",
    "    model.reactions.RBPC2s_BS.bounds = (0,0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #What if I simply constrained that of the M cell one to 3:1?\n",
    "    #This constraint is pretty good actually. \n",
    "    #This allows the system to be set at a specific Vc/Vo rate while still allowing local variation \n",
    "    #wherein Rubisco may act in an uncoupled fashion and may have favorable internal vc/vo rates.\n",
    "# #This code block is to set a constraint such that M-to-BS cell NGAM ratio is 10-to-1 \n",
    "# #Similar to what Moreno-Villena et al (2022) had done \n",
    "\n",
    "#This function takes two arguments: the model and the maximal  ppfd input to the system\n",
    "def add_ngam_cons(model, ppfd): \n",
    "    ngam_atp_m = mm.get_rxn(model, 'ngam_atp_c_M')\n",
    "    ngam_atp_bs = mm.get_rxn(model, 'ngam_atp_c_BS')\n",
    "    ngam_atp_m.bounds = (0,inf)\n",
    "    ngam_atp_bs.bounds = (0,inf)\n",
    "    ngam_ratio = mm.set_fix_flux_ratio({ngam_atp_m.id:10, ngam_atp_bs.id:1}, model)\n",
    "    ngam_ratio.name = 'ngam_BS/M_ratio'\n",
    "    model.add_cons_vars(ngam_ratio)\n",
    "\n",
    "    #Retrieve NGAM reactions\n",
    "    ngam_nadphox_c_M = mm.get_rxn(model, 'ngam_nadphox_c_M')\n",
    "    ngam_nadphox_s_M = mm.get_rxn(model, 'ngam_nadphox_s_M')\n",
    "    ngam_nadphox_m_M = mm.get_rxn(model, 'ngam_nadphox_m_M')\n",
    "    ngam_nadphox_c_BS = mm.get_rxn(model, 'ngam_nadphox_c_BS')\n",
    "    ngam_nadphox_s_BS = mm.get_rxn(model, 'ngam_nadphox_s_BS')\n",
    "    ngam_nadphox_m_BS = mm.get_rxn(model, 'ngam_nadphox_m_BS')\n",
    "\n",
    "\n",
    "    #Set Fixed fluxes\n",
    "    nadphox_c_s_M = mm.set_fix_flux_ratio({ngam_nadphox_c_M.id:1, ngam_nadphox_s_M.id:1},model)\n",
    "    nadphox_c_s_M.name = \"nadphox_cs_ratio_M\"\n",
    "    nadphox_s_m_M = mm.set_fix_flux_ratio({ngam_nadphox_s_M.id:1, ngam_nadphox_m_M.id:1}, model)\n",
    "    nadphox_s_m_M.name = \"nadphox_sm_ratio_M\"\n",
    "\n",
    "    nadphox_c_s_BS = mm.set_fix_flux_ratio({ngam_nadphox_c_BS.id:1, ngam_nadphox_s_BS.id:1},model)\n",
    "    nadphox_c_s_BS.name = \"nadphox_cs_ratio_BS\"\n",
    "    nadphox_s_m_BS = mm.set_fix_flux_ratio({ngam_nadphox_s_BS.id:1, ngam_nadphox_m_BS.id:1}, model)\n",
    "    nadphox_s_m_BS.name = \"nadphox_sm_ratio_BS\"\n",
    "\n",
    "    #Add constraints\n",
    "    model.add_cons_vars(nadphox_c_s_M)\n",
    "    model.add_cons_vars(nadphox_s_m_M)\n",
    "    model.add_cons_vars(nadphox_c_s_BS)\n",
    "    model.add_cons_vars(nadphox_s_m_BS)\n",
    "\n",
    "    #Retrieve flux expressionns\n",
    "    fex_nadphox_c_M =  mm.get_flux_exp(model, ngam_nadphox_c_M)\n",
    "    fex_nadphox_s_M = mm.get_flux_exp(model, ngam_nadphox_s_M)\n",
    "    fex_nadphox_m_M = mm.get_flux_exp(model, ngam_nadphox_m_M)\n",
    "\n",
    "    fex_nadphox_c_BS =  mm.get_flux_exp(model, ngam_nadphox_c_BS)\n",
    "    fex_nadphox_s_BS =  mm.get_flux_exp(model, ngam_nadphox_s_BS)\n",
    "    fex_nadphox_m_BS =  mm.get_flux_exp(model, ngam_nadphox_m_BS)\n",
    "\n",
    "    fex_atp_c_M = mm.get_flux_exp(model, ngam_atp_m)\n",
    "    fex_atp_c_BS =  mm.get_flux_exp(model, ngam_atp_bs)\n",
    "\n",
    "    #Set the constraint between ATP:NADPH NGAM to 3:1\n",
    "    nadphox_atpase = model.problem.Constraint(3*(fex_nadphox_c_M + fex_nadphox_s_M + fex_nadphox_m_M\n",
    "                                                       + fex_nadphox_c_BS + fex_nadphox_s_BS + fex_nadphox_m_BS) \n",
    "                                         - 1*(fex_atp_c_M + fex_atp_c_BS),\n",
    "                                         lb=0,ub=0)\n",
    "    nadphox_atpase.name = \"nadphox_atpase_ratio\"\n",
    "    model.add_cons_vars(nadphox_atpase)\n",
    "    #Compute NGAM value and add constraint as a lower bound/upper bound to model\n",
    "    ngam_value = compute_ngam_atp(ppfd)\n",
    "    ngam_cons = model.problem.Constraint(fex_atp_c_M + \n",
    "                                        fex_atp_c_BS, lb=ngam_value, ub=ngam_value)\n",
    "    ngam_cons.name = 'NGAM_ATP_constraint'\n",
    "    model.add_cons_vars(ngam_cons)\n",
    "    \n",
    "#This code  block gives a snapshot of the relevant fluxes on each of the cell types based on the saved sample_fluxes values above\n",
    "\n",
    "def print_summary(model, sample_fluxes_df):\n",
    "    print('rbcl M cell: ', sample_fluxes['RBPCs_M'], 'rbcl BS cell: ',sample_fluxes['RBPCs_BS'])\n",
    "    print('rbcl M cell (photorespiration)', sample_fluxes['RBPOs_M'], 'rbcl BS cell (PR)', sample_fluxes['RBPOs_BS'])\n",
    "    print('vc/vo M:', sample_fluxes['RBPCs_M']/sample_fluxes['RBPOs_M'], 'vc/vo BS:', sample_fluxes['RBPCs_BS']/sample_fluxes['RBPOs_BS'])\n",
    "    print('RBPC2s_M', sample_fluxes['RBPC2s_M'], 'RBPC2s_BS', sample_fluxes['RBPC2s_BS'])\n",
    "    print('PEPC M', sample_fluxes['PPCc_M'], 'PEPC BS', sample_fluxes['PPCc_BS'])\n",
    "    print('Carbonic Anhydrase (Cytosolic) M', sample_fluxes['HCO3Ec_M'], 'Carbonic Anhydrase (Cytosolic) BS', sample_fluxes['HCO3Ec_BS'])\n",
    "    print('NADP-ME M', sample_fluxes['MDHys_M'], 'NADP-ME BS', sample_fluxes['MDHys_BS'])\n",
    "    print('Biomass M: ', sample_fluxes['Straw_Biomass_M'], 'Biomass BS', sample_fluxes['Straw_Biomass_BS'])\n",
    "    print('Phloem M: ', sample_fluxes['DM_Phloem_M'], 'Phloem BS', sample_fluxes['DM_Phloem_BS'])\n",
    "    print('co2 consumption M', sample_fluxes['CO2tex_M'], 'co2 consumption BS', sample_fluxes['CO2tex_BS'])\n",
    "    print('o2 consumption M', sample_fluxes['O2tex_M'], 'o2 consumption BS', sample_fluxes['O2tex_BS'])\n",
    "    print('Photosystem II M', sample_fluxes['PSIINC_M'], 'PSII BS', sample_fluxes['PSIINC_BS'])\n",
    "    print('PSI M', sample_fluxes['PSIMR_M'], 'PSI BS', sample_fluxes['PSIMR_BS'])\n",
    "    print('PPFD M: ', sample_fluxes['PRISM_white_LED_M'], 'PPFD BS: ', sample_fluxes['PRISM_white_LED_BS'])\n",
    "    print('ATP synthesis (stromal) M', sample_fluxes['ATPSs_M'], 'ATP synthase (mit) M', sample_fluxes['ATPSm_M'])\n",
    "    pd_rxn = [x for x in model.reactions if \"pd\" in x.id and \"h2o\" not in x.id]\n",
    "    pd_abs_flux = 0\n",
    "    for pds in pd_rxn:\n",
    "        pd_abs_flux += abs(sample_fluxes[pds.id])\n",
    "    \n",
    "    print('pd_abs_flux: ', pd_abs_flux)\n",
    "    \n",
    "#initialize list of transgenic reactions to add  to model\n",
    "\n",
    "def add_trans_reactions(model):\n",
    "    '''\n",
    "    This function is used to add a number of new tissue-specific reactions that were not present in the\n",
    "    original model to facilitate modelling of the transgenic C4 rice\n",
    "    '''\n",
    "    trans_list = list()\n",
    "    #Transgenic PEPC copy\n",
    "    #PEPC = Chloroplastic in M & V (rxn id: PPCc)\n",
    "    trans_ppcs = Reaction('trans_PPCs_M')\n",
    "    trans_ppcs.name = \"Phosphoenolpyruvate carboxylase, plastidic (Transgenic)\"\n",
    "    \n",
    "    pep_s0 = model.metabolites.pep_s0\n",
    "    hco3_s0 = model.metabolites.hco3_s0\n",
    "    oaa_s0 = model.metabolites.oaa_s0\n",
    "    pi_s0 = model.metabolites.pi_s0\n",
    "\n",
    "\n",
    "    #Add metabolites, bounds, and subsystem\n",
    "    trans_ppcs.add_metabolites({hco3_s0:-1, pep_s0:-1, oaa_s0:1, pi_s0:1})\n",
    "    trans_ppcs.bounds= model.reactions.PPCc_M.bounds\n",
    "    trans_ppcs.subsystem = model.reactions.PPCc_M.subsystem\n",
    "\n",
    "    trans_list.append(trans_ppcs)\n",
    "\n",
    "\n",
    "    #Transgenic PPDK Copy\n",
    "    trans_ppdks_m = Reaction('trans_PPDKs_M')\n",
    "    trans_ppdks_m.add_metabolites(model.reactions.PPDKs_M.metabolites)\n",
    "    trans_ppdks_m.bounds = model.reactions.PPDKs_M.bounds\n",
    "    trans_ppdks_m.name = \"Pyruvate phosphate dikinase, plastidic (Transgenic)\"\n",
    "\n",
    "    trans_ppdks_bs = Reaction('trans_PPDKs_BS')\n",
    "    trans_ppdks_bs.add_metabolites(model.reactions.PPDKs_BS.metabolites)\n",
    "    trans_ppdks_bs.bounds = model.reactions.PPDKs_BS.bounds\n",
    "    trans_ppdks_bs.name = \"Pyruvate phosphate dikinase, plastidic (Transgenic)\"\n",
    "\n",
    "    trans_list.append(trans_ppdks_m)\n",
    "    trans_list.append(trans_ppdks_bs)\n",
    "\n",
    "    #Transgenic NADP-ME\n",
    "    #NADP-ME = Mitochondrial in M\n",
    "    trans_nadp_me = Reaction('trans_MDH2m_M')\n",
    "\n",
    "    #retrieve reactants\n",
    "    mal_m0 = model.metabolites.get_by_id('mal-L_m0')\n",
    "    nadp_m0 = model.metabolites.nadp_m0\n",
    "    co2_m0 = model.metabolites.co2_m0\n",
    "    nadph_m0 = model.metabolites.nadph_m0\n",
    "    pyr_m0 = model.metabolites.pyr_m0\n",
    "\n",
    "    #Add to rxn\n",
    "    trans_nadp_me.add_metabolites({mal_m0:-1, nadp_m0:-1, co2_m0:1, nadph_m0:1, pyr_m0:1})\n",
    "    #Add bounds\n",
    "    trans_nadp_me.bounds=(-inf, inf)\n",
    "\n",
    "    trans_list.append(trans_nadp_me)\n",
    "\n",
    "\n",
    "    \n",
    "    #Not needed anymore aas I've instead rebased the constraint to use the original reactions instead.\n",
    "#     #Malate Dehydrogenase, mitochondrial (M cell)\n",
    "#     trans_MDHm_M = Reaction('trans_MDHm_M')\n",
    "#     trans_MDHm_M.name = 'Malate Dehydrogenase, Mitochondrial'\n",
    "#     trans_MDHm_M.add_metabolites(model.reactions.MDHm_M.metabolites)\n",
    "#     trans_MDHm_M.subsystem = model.reactions.MDHm_M.subsystem\n",
    "#     trans_MDHm_M.notes['SUBSYSTEM'] = trans_MDHm_M.subsystem\n",
    "\n",
    "#     trans_list.append(trans_MDHm_M)\n",
    "\n",
    "#     #Malate dehydrogenase, plastidic (M cell)\n",
    "#     trans_MDHs_M = Reaction('trans_MDHs_M')\n",
    "#     trans_MDHs_M.name = 'Malate Dehydrogenase, Plastidic'\n",
    "#     trans_MDHs_M.add_metabolites(model.reactions.MDHs_M.metabolites)\n",
    "#     trans_MDHs_M.subsystem = model.reactions.MDHs_M.subsystem\n",
    "#     trans_MDHs_M.notes['SUBSYSTEM'] = trans_MDHs_M.subsystem\n",
    "#     trans_list.append(trans_MDHs_M)\n",
    "\n",
    "#     #Malate dehydrogenase, plastidic(BS Cell)\n",
    "#     trans_MDHs_BS = Reaction('trans_MDHs_BS')\n",
    "#     trans_MDHs_BS.name = 'Malate Dehydrogenase, Plastidic'\n",
    "#     trans_MDHs_BS.add_metabolites(model.reactions.MDHs_BS.metabolites)\n",
    "#     trans_MDHs_BS.subsystem = model.reactions.MDHs_BS.subsystem\n",
    "#     trans_MDHs_BS.notes['SUBSYSTEM'] = trans_MDHs_BS.subsystem\n",
    "\n",
    "#     trans_list.append(trans_MDHs_BS)\n",
    "\n",
    "\n",
    "    #Trans CA\n",
    "    #Cytosolic in M\n",
    "    trans_hco3ec_M = Reaction('trans_hco3ec_M')\n",
    "    trans_hco3ec_M.name = 'carbonic anhydrase, cytosolic'\n",
    "    trans_hco3ec_M.add_metabolites(model.reactions.HCO3Ec_M.metabolites)\n",
    "    trans_hco3ec_M.bounds = model.reactions.HCO3Ec_M.bounds\n",
    "\n",
    "    trans_hco3ec_M.subsystem = model.reactions.HCO3Ec_M.subsystem\n",
    "    trans_list.append(trans_hco3ec_M)\n",
    "\n",
    "\n",
    "    #Bulk add to model\n",
    "    model.add_reactions(trans_list)\n",
    "    \n",
    "    model.repair()\n",
    "####ADDING TRANS CONSTRAINTS\n",
    "\n",
    "def add_trans_constraints(model,\n",
    "                         trans_pepc_rates = 7.01,\n",
    "                         trans_ppdks_rates = 3.66,\n",
    "                         trans_mdh_rates = 152.87,\n",
    "                         trans_nadp_me_rates = 0.60,\n",
    "                         trans_CA_rates = 8):\n",
    "    '''\n",
    "    This function is used to add another layer of constraints to parametize model based on the\n",
    "    Enzyme reaction rates assayed from Ermakova et al (2021) where the locations are based on the \n",
    "    each of the transgenic enzyme's tissue-specific localizations. \n",
    "    '''\n",
    "    \n",
    "    #PEPC constraint\n",
    "    wt_PPCc_M = mm.get_rxn(model, 'PPCc_M')\n",
    "    wt_PPCc_BS = mm.get_rxn(model, 'PPCc_BS')\n",
    "    trans_PPCs_M = mm.get_rxn(model, 'trans_PPCs_M')                           \n",
    "    trans_PEPC_cons = model.problem.Constraint(trans_PPCs_M.flux_expression\n",
    "                                            +wt_PPCc_BS.flux_expression \n",
    "                                            + wt_PPCc_M.flux_expression, \n",
    "                                            lb = 0, ub = trans_pepc_rates)\n",
    "\n",
    "    model.add_cons_vars(trans_PEPC_cons)\n",
    "\n",
    "    #PPDK constraint\n",
    "    trans_PPDKs_M  = mm.get_rxn(model, 'trans_PPDKs_M')\n",
    "    trans_PPDKs_BS = mm.get_rxn(model, 'trans_PPDKs_BS')\n",
    "    wt_PPDKs_M = mm.get_rxn(model, 'PPDKs_M')\n",
    "    wt_PPDKs_BS = mm.get_rxn(model, 'PPDKs_BS')\n",
    "    \n",
    "    trans_PPDKs_cons = model.problem.Constraint( \n",
    "        trans_PPDKs_BS.flux_expression + trans_PPDKs_M.flux_expression \n",
    "        +wt_PPDKs_BS.flux_expression + wt_PPDKs_M.flux_expression, \n",
    "                                             lb = 0, ub = trans_ppdks_rates)\n",
    "    trans_PPDKs_cons.name = 'trans_ppdks_cons'\n",
    "    model.add_cons_vars(trans_PPDKs_cons)\n",
    "    \n",
    "\n",
    "\n",
    "    #Malate Dehydrogenase Constraints\n",
    "    trans_MDHm_M = mm.get_rxn(model, 'MDHm_M')\n",
    "    trans_MDHs_M = mm.get_rxn(model, 'MDHs_M')\n",
    "    trans_MDHs_BS = mm.get_rxn(model, 'MDHs_BS')\n",
    "    \n",
    "    #Change bounds to reflect the Trans state (Based on Immunoblotting)\n",
    "    trans_MDHm_M.bounds = (-inf, inf)\n",
    "    trans_MDHs_M.bounds = (-inf, inf)\n",
    "    trans_MDHs_BS.bounds = (-inf, inf)\n",
    "    \n",
    "    trans_mdh_cons =  model.problem.Constraint(\n",
    "       trans_MDHm_M.flux_expression + \n",
    "        trans_MDHs_M.flux_expression + \n",
    "        trans_MDHs_BS.flux_expression, \n",
    "        lb= -trans_mdh_rates, ub=trans_mdh_rates)\n",
    "\n",
    "    trans_mdh_cons.name = \"trans_mdh_cons\"\n",
    "    model.add_cons_vars(trans_mdh_cons)\n",
    "\n",
    "    \n",
    "    \n",
    "    #Add NADP-ME constraints\n",
    "    trans_MDH2m_M = mm.get_rxn(model, 'trans_MDH2m_M')\n",
    "    wt_MDH2s_M = mm.get_rxn(model, 'MDH2s_M')\n",
    "    wt_MDH2s_BS = mm.get_rxn(model, 'MDH2s_BS')\n",
    "    \n",
    "    \n",
    "    \n",
    "    trans_nadpme_cons = model.problem.Constraint(\n",
    "        trans_MDH2m_M.flux_expression + \n",
    "        wt_MDH2s_M.flux_expression + \n",
    "        wt_MDH2s_BS.flux_expression,\n",
    "        lb= 0, ub=trans_nadp_me_rates)\n",
    "    \n",
    "    trans_nadpme_cons.name = \"trans_nadpme\"\n",
    "    model.add_cons_vars(trans_nadpme_cons)\n",
    "\n",
    "    #Add carbonic anhydrase constraints\n",
    "\n",
    "    trans_hco3ec_M = mm.get_rxn(model, 'trans_hco3ec_M')\n",
    "    wt_hco3ec_M = mm.get_rxn(model, 'HCO3Ec_M')\n",
    "    wt_hco3em_M = mm.get_rxn(model, 'HCO3Em_M')\n",
    "    wt_hco3es_M = mm.get_rxn(model, 'HCO3Es_M')\n",
    "    wt_hco3ec_BS = mm.get_rxn(model, 'HCO3Ec_BS')\n",
    "    wt_hco3em_BS = mm.get_rxn(model, 'HCO3Em_BS')\n",
    "    wt_hco3es_BS = mm.get_rxn(model, 'HCO3Es_BS')\n",
    "    \n",
    "    trans_ca_cons = model.problem.Constraint(trans_hco3ec_M.flux_expression + \n",
    "                                             wt_hco3es_M.flux_expression + \n",
    "                                             wt_hco3ec_M.flux_expression + \n",
    "                                             wt_hco3em_M.flux_expression + \n",
    "                                             wt_hco3es_BS.flux_expression + \n",
    "                                             wt_hco3ec_BS.flux_expression + \n",
    "                                             wt_hco3em_BS.flux_expression,\n",
    "                                      lb = -trans_CA_rates, ub = trans_CA_rates)\n",
    "    trans_ca_cons.name = 'Trans_CA_cons'\n",
    "    model.add_cons_vars(trans_ca_cons)\n",
    "    model.repair()\n",
    "    \n",
    "\n",
    "\n",
    "#Read 2-cell model\n",
    "wt_model = cobra.io.read_sbml_model(\"./model/ios2164_2cell.xml\")\n",
    "trans_model = cobra.io.read_sbml_model(\"./model/ios2164_2cell.xml\")\n",
    "\n",
    "wt_model.solver = 'gurobi'\n",
    "trans_model.solver = 'gurobi'\n",
    "\n",
    "\n",
    "trans_model\n",
    "add_trans_reactions(trans_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24d08460-95dc-4dea-ae6e-a7c85ca4122e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_flux_samples(model, num_samples, batch_size, output_filename,thinning,processes=7, nproj=0,output_dir='./flux_results/flux_sampling/'):\n",
    "    #This function is used to initialize a flux sampler and afterwards generate a csv file containing the sample solutions.\n",
    "    #default batch size is 1000\n",
    "\n",
    "    #Generate sampler\n",
    "    print(\"generating sampler for model\")\n",
    "    sampler = sampling.OptGPSampler(model, processes=processes, thinning=thinning, nproj=nproj)\n",
    "    print(\"done generating OPTGP sampler\")\n",
    "    \n",
    "    \n",
    "    #Define output file\n",
    "    output_dir = str(output_dir)\n",
    "    output_filename = str(output_filename)\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    print('saving output to ', f\"{output_dir}/{output_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(num_samples // batch_size):\n",
    "        print(f\"Generating batch {i+1}/{num_samples//batch_size}\")\n",
    "        samples = sampler.sample(n=batch_size)\n",
    "        df = pd.DataFrame(samples, columns=model.reactions.list_attr(\"id\"))\n",
    "        if i == 0:\n",
    "            df.to_csv(f\"{output_dir}/{output_filename}\", index=False)\n",
    "        else:\n",
    "            df.to_csv(f\"{output_dir}/{output_filename}\", index=False, header=False, mode=\"a\")\n",
    "        \n",
    "    \n",
    "\n",
    "def parametrize_model(model, ppfd_low, ppfd_high, co2,if_trans, loopless=False, frac_optimum=1, pruning=False, fva_bounds_file='', intermediate_fva_results=''):\n",
    "    \n",
    "    print('start time for parametrize_model(): ' ,datetime.datetime.now())\n",
    "\n",
    "    #Generates a parametrized model which returns the constrained model as a callable object.\n",
    "    \n",
    "    #Copy model \n",
    "    model_instance = model.copy()\n",
    "                                                                                                                                                                                                                                \n",
    "    model_instance.medium = define_model_medium(model_instance, co2=co2, o2=inf, ppfd=inf, h=inf, nh4=inf, no3=inf)\n",
    "    turn_off_cofac_cycles(model_instance)\n",
    "    add_tissue_constraints(model_instance)\n",
    "    add_enzyme_constraints(model_instance)\n",
    "\n",
    "    #Adds NGAM (Computed as an average between the high and low instead of directly constraining it to the model, w/c makes the problem non-linear)\n",
    "    add_ngam_cons(model_instance, (ppfd_high+ppfd_low)/2)\n",
    "    \n",
    "    #Constrain PPFD range to indicated value\n",
    "    model_instance.reactions.get_by_id('EX_photonVis(e)').bounds = (-1*ppfd_high, -1*ppfd_low)\n",
    "    \n",
    "\n",
    "    #Check if trans then add constraints if true\n",
    "    if if_trans==True:\n",
    "        add_trans_reactions(model_instance)\n",
    "        add_trans_constraints(model_instance)\n",
    "    \n",
    "    \n",
    "    #Readd objective coefficient, maybe it'll work?\n",
    "    model_instance.reactions.get_by_id('DM_Phloem_BS').objective_coefficient = 1\n",
    "    \n",
    "    '''Run FVA to preprocess the model to fix reaction reversibilities as well as to ensure that there are no \"extreme\" fluxes in the final sampling\n",
    "     Perform Flux Variability Analysis (FVA)\n",
    "        This step constrains the upper and lower bounds to the detected \"Maximal\" and \"minimal\" fluxes given an objective\n",
    "        The default fraction of optimum will be implemented\n",
    "    Will implement pFBA factor to constrain the model to 110% of the detected lowest flux '''\n",
    "\n",
    "\n",
    "    list_infeasibles = list()\n",
    "    \n",
    "    #flux_variability_analysis produces a Pandas Dataframe that can be taken apart and applied to the model_instance as direct bounds. \n",
    "    \n",
    "    if fva_bounds_file:\n",
    "        print('reading previous FVA bounds')\n",
    "        fva_result = pd.read_csv(fva_bounds_file, index_col=0)\n",
    "        fva_result.columns = ['minimum', 'maximum']\n",
    "        \n",
    "        \n",
    "        #Add also reactions that are not in the FVA_bounds_file to the rerunning FVA\n",
    "        for rxn in model_instance.reactions:\n",
    "            if rxn.id not in fva_result.index:\n",
    "                list_infeasibles.append(rxn.id)\n",
    "\n",
    "            \n",
    "    else:\n",
    "        print('computing Loopless FVA to model')\n",
    "        fva_result = cobra.flux_analysis.flux_variability_analysis(model_instance, loopless=loopless, fraction_of_optimum=frac_optimum, pfba_factor=1.1, processes=7)\n",
    "\n",
    "    \n",
    "    # Set FVA constraints in the model\n",
    "    print('setting FVA constraints to model and checking for feasibility')\n",
    "    \n",
    "    \n",
    "    for reaction_id, bounds in fva_result.iterrows():\n",
    "        reaction = model_instance.reactions.get_by_id(reaction_id)        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #This method instead double checks the model per flux range and checks if it returns an infeasible solution/0 objective. \n",
    "        #First save old bounds \n",
    "        old_bounds = reaction.bounds\n",
    "        \n",
    "        # Check which is higher or lower to avoid Value errors\n",
    "        lower_bound = float(min(bounds['minimum'], bounds['maximum']))\n",
    "        upper_bound = float(max(bounds['minimum'], bounds['maximum']))\n",
    "        \n",
    "        #Check reaction if it is unbounded then append to list_infeasibles for rerunning\n",
    "        if lower_bound==-1e6 or upper_bound==1e6:\n",
    "            print(f'reaction {reaction_id} is unbounded. Adding to rerun list')\n",
    "            list_infeasibles.append(reaction)\n",
    "        \n",
    "        #Fix the upper and lower bounds\n",
    "        reaction.bounds = (lower_bound, upper_bound)\n",
    "        \n",
    "        #Generate solution and status for checking if reaction is \n",
    "        solution = model_instance.slim_optimize()\n",
    "        status= model_instance.optimize().status\n",
    "        \n",
    "        #Revert model to previous flux bounds in case it causes feasibility issues\n",
    "        if status=='infeasible' or solution==0: #If it causes a 0 obj. function then it's considered broke\n",
    "            print(f'{reaction_id} causes infeasible status/0 objective!')\n",
    "            reaction.bounds=old_bounds\n",
    "            list_infeasibles.append(reaction)\n",
    "            continue\n",
    "            \n",
    "        \n",
    "    \n",
    "    print('Checking done. Length of reactions that cause infeasibility issues/unbounded: ', len(list_infeasibles))\n",
    "            \n",
    "     \n",
    "    #Save intermediate FVA results (For debugging)\n",
    "    if intermediate_fva_results != '':\n",
    "        save_model_bounds(model_instance, f'{intermediate_fva_results}.csv', directory='./flux_results/flux_sampling/model_bounds/for_debugging')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    #Checks if there are any infeasible solutions in the model then reruns the non-loopless version on the NaNs list. This in turn reruns the model to use the non-loopless version of the algorithm instead. It would at least relax the bounds set by the loopless option\n",
    "    #To bounds that are still feasible but still constrained somewhat (rather than setting it to a large value). The rationale behind this is that the first LL-FVA iteration already constrains the model to remove most loops while this iteration would ensure that the model returns a feasible solution\n",
    "    \n",
    "        #Rerun FVA\n",
    "    if len(list_infeasibles) != 0:\n",
    "        print('recomputing list_infeasibles')\n",
    "        fva_non_loopless =  cobra.flux_analysis.flux_variability_analysis(model_instance, reaction_list=list_infeasibles, loopless=True ,fraction_of_optimum=frac_optimum-0.05, pfba_factor=1.1, processes=7)\n",
    "\n",
    "        for reaction_id, bounds in fva_non_loopless.iterrows():\n",
    "            reaction = model_instance.reactions.get_by_id(reaction_id)        \n",
    "            # Check which is higher or lower to avoid Value errors\n",
    "            lower_bound = float(min(bounds['minimum'], bounds['maximum']))\n",
    "            upper_bound = float(max(bounds['minimum'], bounds['maximum']))\n",
    "            print(f'setting bounds for rerun reaction {reaction_id}. Bounds: {lower_bound} | {upper_bound}')\n",
    "            reaction.bounds = (lower_bound, upper_bound)\n",
    "\n",
    "\n",
    "    print('printing model objective:')\n",
    "    print(model_instance.optimize())\n",
    "\n",
    "\n",
    "    if pruning==True:\n",
    "            blocked_reactions = cobra.flux_analysis.find_blocked_reactions(model_instance)\n",
    "            print('reactions number (before pruning): ', len(model_instance.reactions))\n",
    "            # model_instance.remove_reactions(filter_list)\n",
    "            model_instance.remove_reactions(blocked_reactions)\n",
    "            print('reactions number (after pruning): ', len(model_instance.reactions))\n",
    "\n",
    "    # Identify unneeded metabolites\n",
    "    unneeded_metabolites = []\n",
    "    for metabolite in model.metabolites:\n",
    "        if metabolite.reactions == []:\n",
    "            unneeded_metabolites.append(metabolite)\n",
    "\n",
    "    # Remove unneeded metabolites from the model\n",
    "    model.remove_metabolites(unneeded_metabolites)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #This ensures the model is feasible before passing to the solver (Infeasible models cannot generate any solutions)\n",
    "    print('final model objective (Final feasibility check):')\n",
    "    print(model_instance.optimize())\n",
    "    \n",
    "    print('end time for parametrize_model(): ' ,datetime.datetime.now())\n",
    "\n",
    "    \n",
    "    return model_instance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_model_bounds(model, filename, directory='./flux_results/flux_sampling/model_bounds/'):\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Get the bounds of each reaction in the model\n",
    "    bounds = []\n",
    "    for reaction in model.reactions:\n",
    "        bounds.append([reaction.id, reaction.bounds[0], reaction.bounds[1]])\n",
    "\n",
    "    # Create a DataFrame with the bounds\n",
    "    bounds_df = pd.DataFrame(bounds, columns=['Reaction', 'Lower Bound', 'Upper Bound'])\n",
    "\n",
    "    # Write the DataFrame to a CSV file\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    bounds_df.to_csv(filepath, index=False)\n",
    "\n",
    "    print(f\"Model bounds saved to: {filepath}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf1896b-310d-4003-83a7-ef7d537fe7d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# '''June 22, 2023\n",
    "# Let's try running this script with the following parameters in mind. Hopefully it doesn't result with infeasibility issues anymore.\n",
    "\n",
    "# '''\n",
    "\n",
    "# #Let's try running this script with the following parameters in mind. Hopwefully this doesn't result with infeasibility issues anymore\n",
    "# #I suspect that the model is overconstrained due to the frac_optimum \n",
    "# WT_250_test =  parametrize_model(wt_model, 225,275,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True)\n",
    "\n",
    "# #Generate list of models for flux sampling\n",
    "# sampling_list = [WT_250_test]\n",
    "\n",
    "# print('generating flux samples for parametrized models')\n",
    "# for model in sampling_list:\n",
    "#     print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "#     model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "#     name_for_file = str('flux_sample_'+model_name+'_relaxed_Loopless_FVA.csv')\n",
    "    \n",
    "#     #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "#     save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print('Starting OPTGP sampler:')\n",
    "#     generate_flux_samples(model, num_samples =500, batch_size=500, thinning=1, output_filename=name_for_file)\n",
    "#     del model #Deletes model instance to free up memory \n",
    "#     print('end time: ', datetime.datetime.now())\n",
    "    \n",
    "    \n",
    "# '''June 23, 2023\n",
    "# The modifications I've done works marvelously. It even fixes yung consumption ng inorganic nutrients, which was unobservable in the prior attempts. However run times are fairly large so I need to account for that.\n",
    "# Some of my modifications include the following:\n",
    "# setting the fraction optimum to 90% of optimum increasing the solution space for the inputs and outputs\n",
    "# Setting the initial run as loopless then taking into account the reactions with infeasible solutions, and afterwards setting it to non-loopless\n",
    "\n",
    "# Pruning the reaction set to account only for reactions with non-zero flux bounds\n",
    "\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca406088-5276-4af4-b78f-fbb3a3a0432c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating parametrized models for flux sampling\n",
      "start time for parametrize_model():  2023-06-24 03:41:29.772944\n",
      "Read LP format model from file /tmp/tmp7xnx17r8.lp\n",
      "Reading time = 0.01 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "reading previous FVA bounds\n",
      "setting FVA constraints to model and checking for feasibility\n",
      "Checking done. Length of reactions that cause infeasibility issues:  0\n",
      "printing model objective:\n",
      "<Solution 0.332 at 0x7f39dedf33d0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n",
      "Could not get flux for reaction FACOAL160c_M, setting it to NaN. This is usually due to numerical instability.\n",
      "Could not get flux for reaction FACOAL140x_M, setting it to NaN. This is usually due to numerical instability.\n",
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n",
      "Could not get flux for reaction FACOAL140x_BS, setting it to NaN. This is usually due to numerical instability.\n",
      "Could not get flux for reaction FAOS182x_BS, setting it to NaN. This is usually due to numerical instability.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (before pruning):  4940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  2774\n",
      "final model objective (Final feasibility check):\n",
      "<Solution 0.332 at 0x7f39e09ac910>\n",
      "end time for parametrize_model():  2023-06-24 03:42:55.881300\n",
      "start time for parametrize_model():  2023-06-24 03:42:55.881417\n",
      "Read LP format model from file /tmp/tmp_qcfu4w_.lp\n",
      "Reading time = 0.01 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "reading previous FVA bounds\n",
      "setting FVA constraints to model and checking for feasibility\n",
      "Checking done. Length of reactions that cause infeasibility issues:  0\n",
      "printing model objective:\n",
      "<Solution 0.465 at 0x7f39db945000>\n",
      "reactions number (before pruning):  4940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  2779\n",
      "final model objective (Final feasibility check):\n",
      "<Solution 0.465 at 0x7f39de1bce80>\n",
      "end time for parametrize_model():  2023-06-24 03:44:20.725465\n",
      "start time for parametrize_model():  2023-06-24 03:44:20.725579\n",
      "Read LP format model from file /tmp/tmpx5qit634.lp\n",
      "Reading time = 0.02 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "reading previous FVA bounds\n",
      "setting FVA constraints to model and checking for feasibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPSII_430(u)_BS causes infeasible status!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPSII_550(u)_BS causes infeasible status!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPSII_690(u)_BS causes infeasible status!\n",
      "Checking done. Length of reactions that cause infeasibility issues:  3\n",
      "recomputing list_infeasibles\n",
      "printing model objective:\n",
      "<Solution 0.115 at 0x7f39e7222f50>\n",
      "reactions number (before pruning):  4948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  1239\n",
      "final model objective (Final feasibility check):\n",
      "<Solution 0.115 at 0x7f39ea8febf0>\n",
      "end time for parametrize_model():  2023-06-24 03:47:22.529830\n",
      "start time for parametrize_model():  2023-06-24 03:47:22.530255\n",
      "Read LP format model from file /tmp/tmpjkkti4fm.lp\n",
      "Reading time = 0.01 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "reading previous FVA bounds\n",
      "setting FVA constraints to model and checking for feasibility\n",
      "ATGDs_BS causes infeasible status!\n",
      "Checking done. Length of reactions that cause infeasibility issues:  1\n",
      "recomputing list_infeasibles\n",
      "printing model objective:\n",
      "<Solution 0.317 at 0x7f39d831b310>\n",
      "reactions number (before pruning):  4948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  1182\n",
      "final model objective (Final feasibility check):\n",
      "<Solution 0.317 at 0x7f39d568dc90>\n",
      "end time for parametrize_model():  2023-06-24 03:50:07.970224\n",
      "start time for parametrize_model():  2023-06-24 03:50:07.970420\n",
      "Read LP format model from file /tmp/tmpfswppkz8.lp\n",
      "Reading time = 0.01 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "reading previous FVA bounds\n",
      "setting FVA constraints to model and checking for feasibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPSII_690(u)_M causes infeasible status!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPSII_570(u)_BS causes infeasible status!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPSII_630(u)_BS causes infeasible status!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPSII_690(u)_BS causes infeasible status!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADK1s_BS causes infeasible status!\n",
      "ATGDs_BS causes infeasible status!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASNNc_BS causes infeasible status!\n",
      "RPDPKs_BS causes infeasible status!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DVCHLOR430s_BS causes infeasible status!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DM_Phloem_BS causes infeasible status!\n",
      "Checking done. Length of reactions that cause infeasibility issues:  10\n",
      "recomputing list_infeasibles\n",
      "printing model objective:\n",
      "<Solution 0.320 at 0x7f39d4da2c80>\n",
      "reactions number (before pruning):  4948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  1306\n",
      "final model objective (Final feasibility check):\n",
      "<Solution 0.320 at 0x7f39d4403c70>\n",
      "end time for parametrize_model():  2023-06-24 03:53:08.091836\n",
      "generating flux samples for parametrized models\n",
      "start time for sampler generation:  2023-06-24 03:53:08.135543\n",
      "Model bounds saved to: ./flux_results/flux_sampling/model_bounds/flux_sample_WT_750_Relaxed_loopless_FVA_100kT.csv\n",
      "Starting OPTGP sampler:\n",
      "num_samples:  10000\n",
      "Thinning coefficient:  100000\n",
      "generating sampler for model\n",
      "Read LP format model from file /tmp/tmpb3a1rep1.lp\n",
      "Reading time = 0.01 seconds\n",
      ": 3970 rows, 5554 columns, 23854 nonzeros\n",
      "done generating OPTGP sampler\n",
      "saving output to  ./flux_results/flux_sampling//flux_sample_WT_750_Relaxed_loopless_FVA_100kT.csv\n",
      "Generating batch 1/2\n",
      "Generating batch 2/2\n",
      "end time:  2023-06-24 14:44:53.309892\n",
      "start time for sampler generation:  2023-06-24 14:44:53.310004\n",
      "Model bounds saved to: ./flux_results/flux_sampling/model_bounds/flux_sample_WT_1500_Relaxed_loopless_FVA_100kT.csv\n",
      "Starting OPTGP sampler:\n",
      "num_samples:  10000\n",
      "Thinning coefficient:  100000\n",
      "generating sampler for model\n",
      "Read LP format model from file /tmp/tmp3gqcc9cb.lp\n",
      "Reading time = 0.02 seconds\n",
      ": 3970 rows, 5564 columns, 23908 nonzeros\n",
      "done generating OPTGP sampler\n",
      "saving output to  ./flux_results/flux_sampling//flux_sample_WT_1500_Relaxed_loopless_FVA_100kT.csv\n",
      "Generating batch 1/2\n",
      "Generating batch 2/2\n",
      "end time:  2023-06-25 02:08:16.767567\n",
      "start time for sampler generation:  2023-06-25 02:08:16.769354\n",
      "Model bounds saved to: ./flux_results/flux_sampling/model_bounds/flux_sample_TR_250_Relaxed_loopless_FVA_100kT.csv\n",
      "Starting OPTGP sampler:\n",
      "num_samples:  10000\n",
      "Thinning coefficient:  100000\n",
      "generating sampler for model\n",
      "Read LP format model from file /tmp/tmp8rih7glk.lp\n",
      "Reading time = 0.01 seconds\n",
      ": 3975 rows, 2489 columns, 10287 nonzeros\n",
      "done generating OPTGP sampler\n",
      "saving output to  ./flux_results/flux_sampling//flux_sample_TR_250_Relaxed_loopless_FVA_100kT.csv\n",
      "Generating batch 1/2\n",
      "Generating batch 2/2\n",
      "end time:  2023-06-25 10:00:45.460292\n",
      "start time for sampler generation:  2023-06-25 10:00:45.460400\n",
      "Model bounds saved to: ./flux_results/flux_sampling/model_bounds/flux_sample_TR_750_Relaxed_loopless_FVA_100kT.csv\n",
      "Starting OPTGP sampler:\n",
      "num_samples:  10000\n",
      "Thinning coefficient:  100000\n",
      "generating sampler for model\n",
      "Read LP format model from file /tmp/tmpl8puda25.lp\n",
      "Reading time = 0.01 seconds\n",
      ": 3975 rows, 2375 columns, 9805 nonzeros\n",
      "done generating OPTGP sampler\n",
      "saving output to  ./flux_results/flux_sampling//flux_sample_TR_750_Relaxed_loopless_FVA_100kT.csv\n",
      "Generating batch 1/2\n",
      "Generating batch 2/2\n",
      "end time:  2023-06-25 17:39:11.311713\n",
      "start time for sampler generation:  2023-06-25 17:39:11.311822\n",
      "Model bounds saved to: ./flux_results/flux_sampling/model_bounds/flux_sample_TR_1500_Relaxed_loopless_FVA_100kT.csv\n",
      "Starting OPTGP sampler:\n",
      "num_samples:  10000\n",
      "Thinning coefficient:  100000\n",
      "generating sampler for model\n",
      "Read LP format model from file /tmp/tmphac9t6wx.lp\n",
      "Reading time = 0.01 seconds\n",
      ": 3975 rows, 2623 columns, 10917 nonzeros\n",
      "done generating OPTGP sampler\n",
      "saving output to  ./flux_results/flux_sampling//flux_sample_TR_1500_Relaxed_loopless_FVA_100kT.csv\n",
      "Generating batch 1/2\n",
      "Generating batch 2/2\n",
      "end time:  2023-06-26 02:17:08.374505\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "\n",
    "#Parametrize models per type by generating model instance\n",
    "\n",
    "print('Generating parametrized models for flux sampling')\n",
    "#Let's check if it works as a separate instance per WT and TR?\n",
    "with wt_model as wt_model:\n",
    "    WT_250 =  parametrize_model(wt_model, 225,275,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/WT_250.csv') #Done\n",
    "    WT_750 = parametrize_model(wt_model, 725, 775,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/WT_750.csv')\n",
    "    WT_1500 = parametrize_model(wt_model, 1475, 1525,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/WT_1500.csv')\n",
    "\n",
    "    TR_250 = parametrize_model(wt_model, 225, 275,co2=22.2, if_trans=True, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/TR_250.csv')\n",
    "    TR_750 = parametrize_model(wt_model, 725, 775,co2=22.2, if_trans=True, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/TR_750.csv')\n",
    "    TR_1500 = parametrize_model(wt_model, 1475, 1525,co2=22.2, if_trans=True, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/TR_1500.csv')\n",
    "\n",
    "#Generate list of models for flux sampling\n",
    "sampling_list = [WT_250, WT_750, WT_1500, TR_250, TR_750, TR_1500]\n",
    "\n",
    "print('generating flux samples for parametrized models')\n",
    "for model in sampling_list:\n",
    "    print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "    model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "    name_for_file = str('flux_sample_'+model_name+'_Relaxed_loopless_FVA_100kT.csv')\n",
    "    #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "    save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "    \n",
    "    #Parametrize OPTGP sampler\n",
    "    num_samples =10000\n",
    "    thinning = 100000\n",
    "    \n",
    "    print('Starting OPTGP sampler:')\n",
    "    print('num_samples: ', num_samples)\n",
    "    print('Thinning coefficient: ', thinning)\n",
    "    generate_flux_samples(model, num_samples =num_samples, nproj=1, batch_size=5000, thinning=thinning, output_filename=name_for_file)\n",
    "    del model #Deletes model instance to free up memory \n",
    "    print('end time: ', datetime.datetime.now())\n",
    "\n",
    "#This outputs a set of bounds that we can reuse to re-parametrize a model instead of re-running the parametrization script again.\n",
    "#June 24, 2023 \n",
    "\n",
    "#For some reason the Trans model returns an infeasible solution. I'll check specifically what the problem is \n",
    "#I checked and some reactions cause numerical issues. I can circumvent that by rerunning the loopless FVA function on the problematic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cdc65e-133f-46a3-a87a-3bc887d52604",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating parametrized models for flux sampling\n",
      "start time for parametrize_model():  2023-06-28 05:44:25.687128\n",
      "Read LP format model from file /tmp/tmp6khjn0eg.lp\n",
      "Reading time = 0.02 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "computing Loopless FVA to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting FVA constraints to model and checking for feasibility\n",
      "Checking done. Length of reactions that cause infeasibility issues:  0\n",
      "Model bounds saved to: ./flux_results/flux_sampling/model_bounds/for_debugging/WT_750_rerun.csv.csv\n",
      "printing model objective:\n",
      "<Solution 0.335 at 0x7fe5f2a06ad0>\n",
      "reactions number (before pruning):  4940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  1266\n",
      "final model objective (Final feasibility check):\n",
      "<Solution 0.335 at 0x7fe5eaa43640>\n",
      "end time for parametrize_model():  2023-06-28 06:10:33.728157\n",
      "start time for parametrize_model():  2023-06-28 06:10:33.728273\n",
      "Read LP format model from file /tmp/tmpp7yay8cd.lp\n",
      "Reading time = 0.02 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "computing Loopless FVA to model\n",
      "setting FVA constraints to model and checking for feasibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBPSs_M causes infeasible status/0 objective!\n",
      "ADK1s_BS causes infeasible status/0 objective!\n",
      "ATGDs_BS causes infeasible status/0 objective!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPDPKs_BS causes infeasible status/0 objective!\n",
      "Checking done. Length of reactions that cause infeasibility issues:  4\n",
      "Model bounds saved to: ./flux_results/flux_sampling/model_bounds/for_debugging/.WT_1500_rerun.csv.csv\n",
      "recomputing list_infeasibles\n",
      "setting bounds for rerun reaction CBPSs_M. Bounds: 0.04026502599276045 | 0.044589595265394986\n",
      "setting bounds for rerun reaction ADK1s_BS. Bounds: 0.008145471855317235 | 4.1991471343587\n",
      "setting bounds for rerun reaction ATGDs_BS. Bounds: 0.004072735927660217 | 0.004510158435508107\n",
      "setting bounds for rerun reaction RPDPKs_BS. Bounds: 0.004072735927659998 | 0.004510158435508099\n",
      "printing model objective:\n",
      "<Solution 0.465 at 0x7fe615f89600>\n",
      "reactions number (before pruning):  4940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  1157\n",
      "final model objective (Final feasibility check):\n",
      "<Solution 0.465 at 0x7fe62c9130d0>\n",
      "end time for parametrize_model():  2023-06-28 06:39:00.783052\n",
      "generating flux samples for parametrized models\n",
      "start time for sampler generation:  2023-06-28 06:39:00.801422\n",
      "Model bounds saved to: ./flux_results/flux_sampling/model_bounds/flux_sample_WT_750_Relaxed_loopless_FVA_100kT_reran.csv\n",
      "Starting OPTGP sampler:\n",
      "num_samples:  10000\n",
      "Thinning coefficient:  100000\n",
      "generating sampler for model\n",
      "Read LP format model from file /tmp/tmp8mblswfa.lp\n",
      "Reading time = 0.01 seconds\n",
      ": 3970 rows, 2538 columns, 10428 nonzeros\n",
      "done generating OPTGP sampler\n",
      "saving output to  ./flux_results/flux_sampling//flux_sample_WT_750_Relaxed_loopless_FVA_100kT_reran.csv\n",
      "Generating batch 1/2\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "\n",
    "#Need to Rerun WT750 and WT1500 due to internal looping issues. Fixed the parametrization script to catch any unexpected errors in the run. We will not be using any previous rerun results for this\n",
    "\n",
    "#Parametrize models per type by generating model instance\n",
    "\n",
    "print('Generating parametrized models for flux sampling')\n",
    "#Let's check if it works as a separate instance per WT and TR?\n",
    "with wt_model as wt_model:\n",
    "    WT_750 = parametrize_model(wt_model, 725, 775,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True, intermediate_fva_results='WT_750_rerun.csv')\n",
    "    WT_1500 = parametrize_model(wt_model, 1475, 1525,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True, intermediate_fva_results='.WT_1500_rerun.csv')\n",
    "\n",
    "#Generate list of models for flux sampling\n",
    "sampling_list = [WT_750, WT_1500]\n",
    "\n",
    "print('generating flux samples for parametrized models')\n",
    "for model in sampling_list:\n",
    "    print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "    model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "    name_for_file = str('flux_sample_'+model_name+'_Relaxed_loopless_FVA_100kT_reran.csv')\n",
    "    #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "    save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "    \n",
    "    #Parametrize OPTGP sampler\n",
    "    num_samples =10000\n",
    "    thinning = 100000\n",
    "    \n",
    "    print('Starting OPTGP sampler:')\n",
    "    print('num_samples: ', num_samples)\n",
    "    print('Thinning coefficient: ', thinning)\n",
    "    generate_flux_samples(model, num_samples =num_samples, nproj=1, batch_size=5000, thinning=thinning, output_filename=name_for_file)\n",
    "    del model #Deletes model instance to free up memory \n",
    "    print('end time: ', datetime.datetime.now())\n",
    "    \n",
    "    \n",
    "#No more unbounded reactions ///\n",
    "\n",
    "#Flux sampling done. Everything seems in order now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac3faa42-8ec1-4733-b76c-9d6290125013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating parametrized models for flux sampling\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'parametrize_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#Let's check if it works as a separate instance per WT and TR?\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m wt_model \u001b[38;5;28;01mas\u001b[39;00m wt_model:\n\u001b[0;32m---> 11\u001b[0m     WT_250 \u001b[38;5;241m=\u001b[39m  \u001b[43mparametrize_model\u001b[49m(wt_model, \u001b[38;5;241m225\u001b[39m,\u001b[38;5;241m275\u001b[39m,co2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m29\u001b[39m, if_trans\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, frac_optimum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.90\u001b[39m, loopless\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pruning\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m     WT_750 \u001b[38;5;241m=\u001b[39m parametrize_model(wt_model, \u001b[38;5;241m725\u001b[39m, \u001b[38;5;241m775\u001b[39m,co2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m29\u001b[39m, if_trans\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, frac_optimum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.90\u001b[39m, loopless\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pruning\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m     WT_1500 \u001b[38;5;241m=\u001b[39m parametrize_model(wt_model, \u001b[38;5;241m1475\u001b[39m, \u001b[38;5;241m1525\u001b[39m,co2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m29\u001b[39m, if_trans\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, frac_optimum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.90\u001b[39m, loopless\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pruning\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parametrize_model' is not defined"
     ]
    }
   ],
   "source": [
    "#JULY 28 2023\n",
    "#Rerunning the sampler script due to an issue with Reaction encoding in the original model.\n",
    "\n",
    "%timeit\n",
    "\n",
    "#Parametrize models per type by generating model instance\n",
    "\n",
    "print('Generating parametrized models for flux sampling')\n",
    "#Let's check if it works as a separate instance per WT and TR?\n",
    "with wt_model as wt_model:\n",
    "    WT_250 =  parametrize_model(wt_model, 225,275,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True)\n",
    "    WT_750 = parametrize_model(wt_model, 725, 775,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True)\n",
    "    WT_1500 = parametrize_model(wt_model, 1475, 1525,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True)\n",
    "\n",
    "    TR_250 = parametrize_model(wt_model, 225, 275,co2=22.2, if_trans=True, frac_optimum=0.90, loopless=True, pruning=True)\n",
    "    TR_750 = parametrize_model(wt_model, 725, 775,co2=22.2, if_trans=True, frac_optimum=0.90, loopless=True, pruning=True)\n",
    "    TR_1500 = parametrize_model(wt_model, 1475, 1525,co2=22.2, if_trans=True, frac_optimum=0.90, loopless=True, pruning=True)\n",
    "\n",
    "#Generate list of models for flux sampling\n",
    "sampling_list = [WT_250, WT_750, WT_1500, TR_250, TR_750, TR_1500]\n",
    "\n",
    "print('generating flux samples for parametrized models')\n",
    "for model in sampling_list:\n",
    "    print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "    model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "    name_for_file = str('flux_sample_'+model_name+'_updated_model_cons.csv')\n",
    "    #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "    save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "    \n",
    "    #Parametrize OPTGP sampler\n",
    "    num_samples =10000\n",
    "    thinning = 100000\n",
    "    \n",
    "    print('Starting OPTGP sampler:')\n",
    "    print('num_samples: ', num_samples)\n",
    "    print('Thinning coefficient: ', thinning)\n",
    "    generate_flux_samples(model, num_samples =num_samples, nproj=1, batch_size=10000, thinning=thinning, output_filename=name_for_file)\n",
    "    del model #Deletes model instance to free up memory \n",
    "    print('end time: ', datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8c8ac6c-8ffa-44a7-892b-fbaceb9ea854",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time for parametrize_model():  2023-06-24 03:21:53.218962\n",
      "Read LP format model from file /tmp/tmpe0x678go.lp\n",
      "Reading time = 0.02 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "reading previous FVA bounds\n",
      "setting FVA bounds and checking feasibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPSII_430(u)_BS causes infeasible status!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPSII_550(u)_BS causes infeasible status!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPSII_690(u)_BS causes infeasible status!\n",
      "recomputing list_infeasibles\n",
      "Before blocked_reactions()\n",
      "<Solution 0.115 at 0x7f39f007da80>\n",
      "reactions number (before pruning):  4948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  1239\n",
      "<Solution 0.115 at 0x7f39f3953700>\n",
      "start time for parametrize_model():  2023-06-24 03:24:32.183864\n",
      "Read LP format model from file /tmp/tmpz967a_m0.lp\n",
      "Reading time = 0.02 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "reading previous FVA bounds\n",
      "setting FVA bounds and checking feasibility\n",
      "ATGDs_BS causes infeasible status!\n",
      "recomputing list_infeasibles\n",
      "Before blocked_reactions()\n",
      "<Solution 0.317 at 0x7f39edb764d0>\n",
      "reactions number (before pruning):  4948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  1182\n",
      "<Solution 0.317 at 0x7f39eff67ca0>\n",
      "start time for parametrize_model():  2023-06-24 03:27:14.455676\n",
      "Read LP format model from file /tmp/tmp7935vzd6.lp\n",
      "Reading time = 0.01 seconds\n",
      ": 3956 rows, 9880 columns, 42914 nonzeros\n",
      "reading previous FVA bounds\n",
      "setting FVA bounds and checking feasibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPSII_690(u)_M causes infeasible status!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPSII_570(u)_BS causes infeasible status!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPSII_630(u)_BS causes infeasible status!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPSII_690(u)_BS causes infeasible status!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADK1s_BS causes infeasible status!\n",
      "ATGDs_BS causes infeasible status!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASNNc_BS causes infeasible status!\n",
      "RPDPKs_BS causes infeasible status!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DVCHLOR430s_BS causes infeasible status!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DM_Phloem_BS causes infeasible status!\n",
      "recomputing list_infeasibles\n",
      "Before blocked_reactions()\n",
      "<Solution 0.320 at 0x7f39ea3db9d0>\n",
      "reactions number (before pruning):  4948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/articulatus/anaconda3/envs/RiceMM/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactions number (after pruning):  1306\n",
      "<Solution 0.320 at 0x7f3a31fc9db0>\n"
     ]
    }
   ],
   "source": [
    "#This function is a prototype for the above and the changes are incorporated into the main parametrization function above.\n",
    "\n",
    "\n",
    "def check_model_feasibility(model, ppfd_low, ppfd_high, co2,if_trans, pruning,frac_optimum=1, fva_bounds_file='', intermediate_fva_results=''):\n",
    "    \n",
    "    print('start time for parametrize_model(): ' ,datetime.datetime.now())\n",
    "\n",
    "    #Generates a parametrized model which returns the constrained model as a callable object.\n",
    "    \n",
    "    #Copy model \n",
    "    model_instance = model.copy()\n",
    "    \n",
    "    model_instance.tolerance = 1e-9\n",
    "                                                                                                                                                                                                                                \n",
    "    model_instance.medium = define_model_medium(model_instance, co2=co2, o2=inf, ppfd=inf, h=inf, nh4=inf, no3=inf)\n",
    "    turn_off_cofac_cycles(model_instance)\n",
    "    add_tissue_constraints(model_instance)\n",
    "    add_enzyme_constraints(model_instance)\n",
    "\n",
    "    #Adds NGAM (Computed as an average between the high and low instead of directly constraining it to the model, w/c makes the problem non-linear)\n",
    "    add_ngam_cons(model_instance, (ppfd_high+ppfd_low)/2)\n",
    "    \n",
    "    #Constrain PPFD range to indicated value\n",
    "    model_instance.reactions.get_by_id('EX_photonVis(e)').bounds = (-1*ppfd_high, -1*ppfd_low)\n",
    "    \n",
    "\n",
    "    #Check if trans then add constraints if true\n",
    "    if if_trans==True:\n",
    "        add_trans_reactions(model_instance)\n",
    "        # add_trans_constraints(model_instance)\n",
    "    \n",
    "    \n",
    "    #Readd objective coefficient, maybe it'll work?\n",
    "    model_instance.reactions.get_by_id('DM_Phloem_BS').objective_coefficient = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''Run FVA to preprocess the model to fix reaction reversibilities as well as to ensure that there are no \"extreme\" fluxes in the final sampling\n",
    "     Perform Flux Variability Analysis (FVA)\n",
    "        This step constrains the upper and lower bounds to the detected \"Maximal\" and \"minimal\" fluxes given an objective\n",
    "        The default fraction of optimum will be implemented\n",
    "    Will implement pFBA factor to constrain the model to 110% of the detected lowest flux '''\n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "    #flux_variability_analysis produces a Pandas Dataframe that can be taken apart and applied to the model_instance as direct bounds. \n",
    "    \n",
    "    list_infeasibles = list()\n",
    "    if fva_bounds_file:\n",
    "        print('reading previous FVA bounds')\n",
    "        fva_result = pd.read_csv(fva_bounds_file, index_col=0)\n",
    "        fva_result.columns = ['minimum', 'maximum']\n",
    "        \n",
    "        \n",
    "        #Modify the above such that it also include unbounded reactions\n",
    "        \n",
    "    print('setting FVA bounds and checking feasibility')\n",
    "    for reaction_id, bounds in fva_result.iterrows():\n",
    "        reaction = model_instance.reactions.get_by_id(reaction_id)        \n",
    "        \n",
    "        #Append the reaction to the reactions to rerun if it is not present in the FVA bounds\n",
    "        if reaction_id not in model_instance.reactions:\n",
    "            list_infeasibles.append()\n",
    "#         if bounds.isnull().any():\n",
    "#             print(f'{reaction_id} has NaNs!')\n",
    "#             list_infeasibles.append(model_instance.reactions.get_by_id(reaction_id))\n",
    "#             continue\n",
    "\n",
    "\n",
    "    #Removing the NaNs breaks the model. What I should probably do instead is generate another set of fva_results (without the Loopless constraint?)\n",
    "\n",
    "        old_bounds = reaction.bounds\n",
    "        \n",
    "        # Check which is higher or lower to avoid Value errors\n",
    "        lower_bound = float(min(bounds['minimum'], bounds['maximum']))\n",
    "        upper_bound = float(max(bounds['minimum'], bounds['maximum']))\n",
    "        reaction.bounds = (lower_bound, upper_bound)\n",
    "        \n",
    "        solution = model_instance.slim_optimize()\n",
    "        status= model_instance.optimize().status\n",
    "        #Revert model to previous flux bounds\n",
    "        if status=='infeasible' or solution==0:\n",
    "            print(f'{reaction_id} causes infeasible status!')\n",
    "            reaction.bounds=old_bounds\n",
    "            list_infeasibles.append(reaction)\n",
    "            continue\n",
    "            \n",
    "\n",
    "        #Rerun FVA\n",
    "    if len(list_infeasibles) != 0:\n",
    "        print('recomputing list_infeasibles')\n",
    "        fva_non_loopless =  cobra.flux_analysis.flux_variability_analysis(model_instance, reaction_list=list_infeasibles, loopless=True ,fraction_of_optimum=frac_optimum-0.05, pfba_factor=1.1, processes=7)\n",
    "\n",
    "        for reaction_id, bounds in fva_non_loopless.iterrows():\n",
    "            reaction = model_instance.reactions.get_by_id(reaction_id)        \n",
    "            # Check which is higher or lower to avoid Value errors\n",
    "            lower_bound = float(min(bounds['minimum'], bounds['maximum']))\n",
    "            upper_bound = float(max(bounds['minimum'], bounds['maximum']))\n",
    "            reaction.bounds = (lower_bound, upper_bound) #Add reaction bounds to the model from the new FVA results\n",
    "\n",
    "\n",
    "        if pruning==True:\n",
    "            print('Before blocked_reactions()')\n",
    "            print(model_instance.optimize())\n",
    "            blocked_reactions = cobra.flux_analysis.find_blocked_reactions(model_instance)\n",
    "            print('reactions number (before pruning): ', len(model_instance.reactions))\n",
    "        # model_instance.remove_reactions(filter_list)\n",
    "            model_instance.remove_reactions(blocked_reactions)\n",
    "            print('reactions number (after pruning): ', len(model_instance.reactions))\n",
    "        \n",
    "    \n",
    "    \n",
    "    print(model_instance.optimize())\n",
    "    \n",
    "    return(list_infeasibles)\n",
    "    \n",
    "TR_250 = check_model_feasibility(wt_model, 225, 275,co2=22.2, pruning=True, if_trans=True,frac_optimum=0.90, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/TR_250.csv')\n",
    "TR_750 = check_model_feasibility(wt_model, 725, 775,co2=22.2, pruning=True,if_trans=True,frac_optimum=0.90, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/TR_750.csv')\n",
    "TR_1500 = check_model_feasibility(wt_model, 1475, 1525,co2=22.2, pruning=True, if_trans=True,frac_optimum=0.9, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/TR_1500.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48eaa1f-4bdf-49aa-abac-3916cc46f03d",
   "metadata": {},
   "source": [
    "Reactions with issues:\n",
    "- ATGDs, for some reason"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16042782-0618-482a-a861-60d2b9d755c9",
   "metadata": {},
   "source": [
    "The fix now returns a solution. Let's check if the Loopless=True works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14514c16-6e44-4b85-b092-be0439cfc79e",
   "metadata": {},
   "source": [
    "Notes: \n",
    "- Flux bounds for FVA show infeasibility for Trans parametrized models. Maybe we could instead prune to model beforehand before computing loopless FVA?\n",
    "- Other constraints \n",
    "\n",
    "-One of the Photon decomposition reactions cause infeasibility issues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b247e7-3b5d-4d11-86cf-1ef0d2341c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# with wt_model as wt_model:\n",
    "#     WT_250 =  parametrize_model(wt_model, 225,275,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/WT_250.csv') #Done\n",
    "#     WT_750 = parametrize_model(wt_model, 725, 775,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/.csv')\n",
    "#     WT_1500 = parametrize_model(wt_model, 1475, 1525,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/WT_1500.csv')\n",
    "\n",
    "#     TR_250 = parametrize_model(wt_model, 225, 275,co2=22.2, if_trans=True, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/flux_sample_TR_250_Relaxed_loopless_FVA_100kT.csv')\n",
    "#     TR_750 = parametrize_model(wt_model, 725, 775,co2=22.2, if_trans=True, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/flux_sample_TR_750_Relaxed_loopless_FVA_100kT.csv')\n",
    "#     TR_1500 = parametrize_model(wt_model, 1475, 1525,co2=22.2, if_trans=True, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/flux_sample_TR_1500_Relaxed_loopless_FVA_100kT.csv')\n",
    "\n",
    "    \n",
    "# sampling_list = [WT_250, WT_750, WT_1500, TR_250, TR_750, TR_1500]\n",
    "\n",
    "# for model in sampling_list:\n",
    "#     name_for_file = str('flux_sample_'+model_name+'_Relaxed_loopless_FVA_100kT_reran.csv')\n",
    "#     model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "#     cobra.io.save_json_model(model, filename=,\n",
    "                             \n",
    "# for model in sampling_list:\n",
    "#     print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "#     model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "#     name_for_file = str('flux_sample_'+model_name+'_Relaxed_loopless_FVA_100kT_reran.csv')\n",
    "#     #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "#     save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "    \n",
    "#     #Parametrize OPTGP sampler\n",
    "#     num_samples =10000\n",
    "#     thinning = 100000\n",
    "    \n",
    "#     print('Starting OPTGP sampler:')\n",
    "#     print('num_samples: ', num_samples)\n",
    "#     print('Thinning coefficient: ', thinning)\n",
    "#     generate_flux_samples(model, num_samples =num_samples, nproj=1, batch_size=5000, thinning=thinning, output_filename=name_for_file)\n",
    "#     del model #Deletes model instance to free up memory \n",
    "#     print('end time: ', datetime.datetime.now())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c99d230-c4fc-4f05-a56e-1eb70ffd2331",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# WT_750 = parametrize_model(wt_model, 725, 775,co2=29, if_trans=False, frac_optimum=0.90, loopless=True, pruning=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/Modified-Loopless-FVA/WT_750.csv')\n",
    "\n",
    "\n",
    "# #Generate list of models for flux sampling\n",
    "# sampling_list = [WT_750]\n",
    "\n",
    "# print('generating flux samples for parametrized models')\n",
    "# for model in sampling_list:\n",
    "#     print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "#     model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "#     name_for_file = str('flux_sample_'+model_name+'_Relaxed_loopless_FVA_Test.csv')\n",
    "#     #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "#     save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "    \n",
    "#     #Parametrize OPTGP sampler\n",
    "#     num_samples =10000\n",
    "#     thinning = 100000\n",
    "    \n",
    "#     print('Starting OPTGP sampler:')\n",
    "#     print('num_samples: ', num_samples)\n",
    "#     print('Thinning coefficient: ', thinning)\n",
    "#     generate_flux_samples(model, num_samples =num_samples, batch_size=5000, thinning=thinning, output_filename=name_for_file)\n",
    "#     del model #Deletes model instance to free up memory \n",
    "#     print('end time: ', datetime.datetime.now())\n",
    "    \n",
    "    \n",
    "# #Apparently the pruning function causes the model to become numerically unstable. Bakit kaa?\n",
    "# #This set of functiosns work\n",
    "\n",
    "# #This outputs a set of bounds that we can reuse to re-parametrize a model instead of re-running the parametrization script again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fcbe37-4dad-497b-95cc-0d3fa27a326e",
   "metadata": {},
   "source": [
    "The following scripts are nott used but were used for prototyping as I was looking for a way to implement Loopless-FVA without destroying the sample distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd4bc9-740b-4566-8ffe-d8c52fb606ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # %timeit\n",
    "# # #Include the FVA bounds file\n",
    "\n",
    "# # #Parametrize models per type by generating model instance\n",
    "# # print('Generating parametrized models for flux sampling')\n",
    "# WT_250 =  parametrize_model(wt_model, 225,275,co2=29, if_trans=False, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_WT_250.csv')\n",
    "# WT_750 = parametrize_model(wt_model, 725, 775,co2=29, if_trans=False, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_WT_750.csv')\n",
    "# WT_1500 = parametrize_model(wt_model, 1475, 1525,co2=29, if_trans=False, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_WT_1500.csv')\n",
    "\n",
    "# TR_250 = parametrize_model(wt_model, 225, 275,co2=22.2, if_trans=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_TR_250.csv')\n",
    "# TR_750 = parametrize_model(wt_model, 725, 775,co2=22.2, if_trans=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_TR_750.csv')\n",
    "# TR_1500 = parametrize_model(wt_model, 1475, 1525,co2=22.2, if_trans=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_TR_1500.csv')\n",
    "\n",
    "# #Generate list of models for flux sampling\n",
    "# sampling_list = [WT_250, WT_750, WT_1500, TR_250, TR_750, TR_1500]\n",
    "\n",
    "# print('generating flux samples for parametrized models')\n",
    "# for model in sampling_list:\n",
    "#     print('start time for sampler generation: ' ,datetime.datetime.now())\n",
    "#     model_name = str([k for k, v in locals().items() if v == model][0])\n",
    "#     name_for_file = str('flux_sample_'+model_name+'_Loopless_FVA_35kT')\n",
    "    \n",
    "#     #Output the flux bounds of the model to ./fva_bounds/name_for_file\n",
    "#     save_model_bounds(model, filename=name_for_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print('Starting OPTGP sampler:')\n",
    "#     generate_flux_samples(model, num_samples =5000, batch_size=2500, thinning=35000, output_filename=name_for_file)\n",
    "#     del model #Deletes model instance to free up memory \n",
    "#     print('end time: ', datetime.datetime.now())\n",
    "\n",
    "# #This outputs a set of bounds that we can reuse to re-parametrize a model instead of re-running the parametrization script again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db0e55-545d-4198-b5b6-e2e6ba7a02d4",
   "metadata": {},
   "source": [
    "The second part of this script is for post-processing the DFs obtained via flux sampling using the CycleFreeFlux algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1f6f42-2496-40eb-9a02-fa0f7a15f0f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Let's try using CCF to post-process the samples that I've already obtained \n",
    "# #First generate the model again\n",
    "\n",
    "# WT_250 =  parametrize_model(wt_model, 225,275,co2=29, if_trans=False, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_WT_250.csv')\n",
    "# WT_750 = parametrize_model(wt_model, 725, 775,co2=29, if_trans=False, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_WT_750.csv')\n",
    "# WT_1500 = parametrize_model(wt_model, 1475, 1525,co2=29, if_trans=False, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_WT_1500.csv')\n",
    "\n",
    "\n",
    "# TR_250 = parametrize_model(wt_model, 225, 275,co2=22.2, if_trans=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_TR_250.csv')\n",
    "# TR_750 = parametrize_model(wt_model, 725, 775,co2=22.2, if_trans=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_TR_750.csv')\n",
    "# TR_1500 = parametrize_model(wt_model, 1475, 1525,co2=22.2, if_trans=True, fva_bounds_file='./flux_results/flux_sampling/model_bounds/4th iteration-35kT, pFBA-FVA/flux_sample_TR_1500.csv')\n",
    "# wt_250_df = pd.read_csv('./flux_results/flux_sampling/4th_iteration_35kthinning/flux_sample_WT_250.csv')\n",
    "# wt_750_df = pd.read_csv('./flux_results/flux_sampling/4th_iteration_35kthinning/flux_sample_WT_750.csv')\n",
    "# wt_1500_df = pd.read_csv('./flux_results/flux_sampling/4th_iteration_35kthinning/flux_sample_WT_1500.csv')\n",
    "# tr_250_df = pd.read_csv('./flux_results/flux_sampling/4th_iteration_35kthinning/flux_sample_TR_250.csv')\n",
    "# tr_750_df = pd.read_csv('./flux_results/flux_sampling/4th_iteration_35kthinning/flux_sample_TR_750.csv')\n",
    "# tr_1500_df = pd.read_csv('./flux_results/flux_sampling/4th_iteration_35kthinning/flux_sample_TR_1500.csv')\n",
    "\n",
    "# #Define lists\n",
    "\n",
    "\n",
    "# sampling_list = [WT_250, WT_750, WT_1500, TR_250, TR_750, TR_1500]\n",
    "\n",
    "# df_list = [wt_250_df,\n",
    "# wt_750_df,\n",
    "# wt_1500_df,\n",
    "# tr_250_df,\n",
    "# tr_750_df,\n",
    "# tr_1500_df\n",
    "# ]\n",
    "\n",
    "# model_names = ['wt_250',\n",
    "# 'wt_750',\n",
    "# 'wt_1500',\n",
    "# 'tr_250',\n",
    "# 'tr_750',\n",
    "# 'tr_1500'\n",
    "#               ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8933ed40-a293-4137-90a5-f22f91d6119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from multiprocessing import Pool\n",
    "# from tqdm import tqdm\n",
    "# import cobra.flux_analysis.loopless\n",
    "\n",
    "# def apply_loopless_sampling(dataframe, model):\n",
    "#     # Create an empty list to store the flux solutions\n",
    "#     flux_solution_list = []\n",
    "\n",
    "#     # Generate a dictionary of flux solutions for each row in the dataframe\n",
    "#     for index, row in tqdm(dataframe.iterrows(), total=len(dataframe), desc=\"Processing rows\"):\n",
    "#         flux_solutions = {}\n",
    "\n",
    "#         for col in dataframe.columns:\n",
    "#             reaction = col\n",
    "#             # Get the value of the cell in the current row and column\n",
    "#             flux = row[col]\n",
    "\n",
    "#             # Add the reaction and flux to the dictionary\n",
    "#             flux_solutions[reaction] = flux\n",
    "\n",
    "#         # Run the \"loopless_solution\" function on the flux solutions dictionary\n",
    "#         loopless = loopless_solution(model, flux_solutions)\n",
    "\n",
    "#         # Append the loopless flux solutions to the list\n",
    "#         flux_solution_list.append(loopless.fluxes)\n",
    "\n",
    "#     # Create a DataFrame from the list of flux solutions\n",
    "#     flux_solution_df = pd.DataFrame(flux_solution_list, columns=dataframe.columns)\n",
    "\n",
    "#     # Reset the indices to numeric values\n",
    "#     flux_solution_df = flux_solution_df.reset_index(drop=True)\n",
    "\n",
    "#     return flux_solution_df\n",
    "\n",
    "\n",
    "# def loopless_solution(model, flux_solutions):\n",
    "\n",
    "#     loopless = cobra.flux_analysis.loopless.loopless_solution(model, flux_solutions)\n",
    "#     return loopless\n",
    "\n",
    "# def post_process_dfs():\n",
    "\n",
    "#     for i  in range(len(sampling_list)):\n",
    "#         model = sampling_list[i]\n",
    "#         df = df_list[i]\n",
    "#         model_name = model_names[i]\n",
    "\n",
    "#         directory = './flux_results/flux_sampling/4th_iteration_35kthinning/with_CCF/'\n",
    "\n",
    "#         if not os.path.exists(directory):\n",
    "#             print('writing dir')\n",
    "#             os.makedirs(directory)\n",
    "\n",
    "\n",
    "#         name_for_file = str('flux_sample_'+model_name+'_Loopless_FVA_35kT_CCF')\n",
    "\n",
    "\n",
    "\n",
    "#         print(f'working on {model_name}')\n",
    "        \n",
    "        \n",
    "#         ccf_sampling = apply_loopless_sampling(df, model)\n",
    "\n",
    "#         #Save post-processed samples to directory\n",
    "#         filepath = os.path.join(directory, name_for_file)\n",
    "#         ccf_sampling.to_csv(filepath, index=False)\n",
    "\n",
    "#         # print(f\"postprocessed flux samples saved to: {filepath}\")\n",
    "\n",
    "#         del model, df, model_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da2c4ab-ca43-4510-87eb-5a1b58aa424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# post_process_dfs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b10e5-c885-4c13-81c9-911f892789cc",
   "metadata": {},
   "source": [
    "Notes: needed to repeat sampling due to the following:\n",
    "- sampling matrices are too large to load, compensate with the use of thinning instead. Use specifications from Hermann et al (2020) which uses instead a thinning coefficient of 10000 instead of keeping all samples. My original parameters were n = 50000, batch size = 2000 and thinning = 500. \n",
    "- Maybe I should use a thinning coefficient of 100000 instead? Since my model has a number of dimensions one exponent higher than the previously benchmarked Arnold Model\n",
    "    - I've decided to run my model with a thinning coefficient of 25000. Hopefully autocorrelation and convergence wouldn't be much of an issue. Total samples would be equal in turn to 1.25e8 individual sampling points. \n",
    "\n",
    "- I needed to reparametrize samples considering that the objective function doesn't apply in flux sampling. INstead of adding an objective coefficient all demand reactions that output biomass are turned off except for \"DM_Phloem_BS\". What I need to do instead is re-parametrize it to allow photoassimilates to exit at that reaction rather than to others.\n",
    "- I'll save the format to \".npz\" instead of \"csv\" since I'm running out of memory whenever I'm loading it out of this script. I think the output of the model is sparse enough that I can instead use this format instead.\n",
    "    - Actually I can save my csv to a normal csv once since I can just adjust the thinning number instead of keeping all samples.\n",
    "\n",
    "- It is still a question whether my samples are uncorrelated or not. I will run the diagnostic tests after I finish running the rest of the scripts.\n",
    "\n",
    "\n",
    "\n",
    "Note: May 17 2023\n",
    "Flux sampling script was interrupted @ TR750 and was rerun at that point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae799577-6b2a-444f-9f90-aa72715e0ec2",
   "metadata": {},
   "source": [
    "Notes: \n",
    "OPTGP Is shown to be faster than ACHR and also converges faster\n",
    "\n",
    "Let's try with a 10 samples first with 10 batches\n",
    "\n",
    "I think the model is too large to be loaded into the flux sampler. \n",
    "\n",
    "It initialized after 30 minutes, let's try sampling na. \n",
    "\n",
    "It takes 1-2 hours at most to generate 2000 samples with a thinning coefficient of 10000. Extrapolating from that, we need probably 4-6 hours to generate 5000 samples with a TC of 20000. To keep things tractable I'll keep the thinning coefficient at 10000. I can just add more samples if needed.\n",
    "\n",
    "\n",
    "Things to add to the paper:\n",
    "\n",
    "\n",
    "Flux sampling is another constraints-based technique used for characterizing the null space of a given stoichiometric model, providing us insights on the flux distributions of a given metabolic model without the explicit definition of a given cellular objective. Not only does this technique offer advantages over conventional FBA and FVA where it allows researchers to determine the feasibility of solutions within a given defined range, as well as the distribution of these fluxes provided the model constaints.. The latter, in turn, allows statistical analysis to determine whether any given fluxes exist within a single probability distribution or not. This, in turn, allows a more direct comparison of fluxes and to adequately sample a solution space provided the constraints implemented in the model.\n",
    "\n",
    "The same constraints have been implemented as with the previous set-ups but with a modification with regards to how the objective functions are concerned. Unlike in pFBA where we can set a particular reaction as an objective, no such setting exists for flux sampling. Thus, this setup is in turn reliant on explicitly defined constraints that would define the n reaction-dimensional solution space. To parametrize this, we have turned off all biomass-related demands such as Coleoptile Biomass, Straw_Biomass and the \"DM_Phloem_M\" reaction to force the model to output flux to the \"DM_Phloem_BS\" reaction. Additionally, the model is constrained in a similar manner as with the previous pFBA setups that we had done to benchmark and assess our model's performance.\n",
    "\n",
    "THe benefits of using Flux Sampling compared to other methods such as FVA in characterizing a solution space is that:\n",
    "a. We may establish confidence intervals with the use of statistical tests to fully characterize a given solution space and whether\n",
    "b. Rather than simply generating representative fluxes showing the maximum and minimum amount of possible flux towards a particular reaction, flux sampling allows summary statistics to be generated, including the probability distribution of each particular reaction. \n",
    "c. Lastly, flux sampling allows a detailed comparison of the interdependence of each particular reaction, showing which reactions are coupled to each other in a positive and negative fashion. This is done\n",
    "\n",
    "Three setups per parametrized model were initialized, each with a representative light treatment of 250, 750 and 1500 PPFD with a defined range of +-25, respectively. The NGAM reactions were instead set at a static value at each representative light point detailed above. A total of 6 treatments were initialized to represent both the WT and Trans models at the selected light points. \n",
    "\n",
    "The sampling algorithm used was the OPTGP (optimized general parallel) sampler from the Cobrapy.sampling package. The sampler was parametrized to generate 5000 samples with a thinning coefficient of 25000, representing 1.25x10^8 sampling points, and was multithreaded into 7 processes each. Run times varied from between 3-6 hours per model parametrized, which was expected based on the number of reactions in the parametrized model.\n",
    "\n",
    "\n",
    "After the generation of individual sampling points, convergence statistics were done to assess the level of autocorrelation as well as to assess whether the samplers have sufficiently converged to a singular value. The former is done with the use of the \"acf\" function to assess the level of autocorrelation on each given column, while the latter is assessed with the use of two specific methods -- the Gelman-Rubin and the Geweke statistics. These are two methods that we will use to assess whether the number of sampling points is sufficient to ensure adequate convergence of each reaction in the model. Reactions that have not converged sufficiently will be indicated.\n",
    "\n",
    "After the assessment of autocorrelation and convergence, each of the pairs between light treatments (225-725, 725-1475, 225-1475) and between models (WT and Trans) are subjected to pairwise Kruskal-Wallis tests to assess which reaction pairs are derived from the same distribution. It is a non-parametric rank-based test test suitable for comparing outputs where there are no assumed distributions behind a population, and has been used in a similar fashion in previous flux sampling setups that involve Plant Metabolism  (Herrmann et al., 2019).  \n",
    "\n",
    "This procedure, in turn, allows us to deduce in finer detail which reactions in particular are positively correlated with CO2 flux into the BS cell's Rubisco reaction. In the previous pFBA experiment we were able to demonstrate a similar approach to this by performing a sensitivity analysis on Glycine Decarboxylase, and had demonstrated the negative relationship between M cell GLYDHD and BS Cell GLYDHD.\n",
    "\n",
    "Lastly, we can afterwards assess which fluxes are coupled by iterating over the list of fluxes in a single flux sample matrix and computing the spearman correlations between the pairwise comparisons. From here we can assess which particular reactions are positively or negatively correlated or not. A particular focus will then be held. Further Downstream analysis includes determination of reactions that are positively or negatively coupled with each other and corroborating this fact on whether the reaction is disrupted in the \"Trans\" parametrized model.  \n",
    "\n",
    "\n",
    "\n",
    "May 19, 2023\n",
    "Some observations on the fluxes obtained from initial flux sampling runs:\n",
    "- It seems it doesn't maximize CO2 assimilation as with pFBA. \n",
    "- It features some reactions with infeasibly large fluxes, particularly those expected to have flux cycling.\n",
    "\n",
    "I asked the Gitter group on what are their thoughts on how to approach this.\n",
    "\n",
    "One solution I think is this:\n",
    "- Reparametrize a model first and generate FVA solutions to \"pre-process\" the model, and in turn add directionality and bound constraints to the model to reduce its solution space further.\n",
    "- Try readding the objective function for photoassimilate generation as well as the pfba objective, as well as add the \"cyclefreeflux\" function by Desouki et al (2015).\n",
    "\n",
    "\n",
    "\n",
    "I am currently testing the Latter.\n",
    "\n",
    "May 20, 2023\n",
    "\n",
    "The latter does not work since it applies MILP, I think. It returns the following error:\n",
    "    \n",
    "    TypeError: Sampling does not work with integer problems.\n",
    "\n",
    "I will instead to the former instead. I've also implemented pruning to remove any unused reactions and metabolites based on the find_blocked_reactions() function of FVA. This will further constrain the model to sort of \"Contextualise\" it. \n",
    "\n",
    "\n",
    "May 20, 2023\n",
    "\n",
    "Based on the Geweke Statistic, and with a z-score of 1.96 (indicating 0.95 confidence  interval) most of the samples have converged on a single statistic. Based on the Gelman Rubin statistic however all of the reactions have not converged to a singular solution. Why?\n",
    "\n",
    "I've rerun the diagnostic scripts in R using Coda and have produced a more reliable measure of convergence and autocorrelation. In both cases only \n",
    "\n",
    "I'll test 5000x25000 samples with the reduced and pFVA-constrained models. I think sampling will be faster considering that I've pruned the samples as well as reduced the solution space by a lot. \n",
    "\n",
    "\n",
    "Flux sampling convergence statistics are based on the methods highlighted by Hermmann et al (2019) and by Fallahi et al (2020). It says that we shouldn't use the normal Gelman-Rubin statistic and instead use the Brooks-Gelman formulation instead.\n",
    "\n",
    "However, for both cases I've instead used the Raftery-Lewis statistic and \n",
    "the Geweke Diagnostic to assess convergences for all parameters. I decided to re-run instead the two last samples considering that they both have significant amounts of reactions that haven't converged based on the RL statistic and the GW statistic.\n",
    "\n",
    "For the RL statistic both 250 and 750 parametrized samplers have converged, although the Geweke diagnostic only reports a convergence rate of around 70 percent. In 1500 the convergence rate falls to 40 percent only which necessitates the re-run scenario. AFterwards I can simply re-run the scripts and re-assess my results. In the meantime however I can analyze both 250 and 750 scenarios as well the highb light scenarios particularly those with significantly varying distributions\n",
    "\n",
    "\n",
    "June 13, 2023\n",
    "\n",
    "I have rerun both WT andTR 1500 to validate if both have converged. If it hasn't I'll report the results as-is and include it in the discussion.\n",
    "\n",
    "June 15, 2023\n",
    "\n",
    "I have an idea in order to ensure convergence as well as to reduce runtimes.\n",
    "My idea is to remove all reactions that are not foundd in the model to 0 in order to reduce the nullspace of the model. This will be based on the initial runs for the flux sampling runs. \n",
    "\n",
    "Afterwards I need to compare their distributions based dun sa mga previous runs to determine if pareho yung distribution. If it is the same or virtually the samme I will use it because I can ensure that it has a higher convergence rate than the one with lower samples.\n",
    "\n",
    "If in case this works then it should return the same distribution and my samples would've converged faster. Furthermore there isn't need to go for breadth considering that my parametrizations are already fixed. Hopefully it can converge faster but since I've changed the thinning constant to 100k it may change the distribution.\n",
    "\n",
    "June 15 2023\n",
    "\n",
    "    Filtering and Increasing the thinning doesn't work apparently. It reduced the convergence rate of my reactions by almost 20 percent -- very alarming. What I should do instead is to increase the thinning coefficient to something more ok (around 35000) while still being relatively fast enough.\n",
    "\n",
    "    However I'll be re-running my sampling attempt in order to fix some errors with H2O cycling. (Change H2O flux to be unidirectional towards M cell to reflect transpiration mechanism. Before what happened was that )\n",
    "\n",
    "    Furthermore I fixed the flux bounds for Photon flux. Apparently I had a typo dun sa upper bounds nung TR_1500 which caused it to have 25 lesser flux than normal.\n",
    "\n",
    "    Hopefully at the end of this ok na siya. Wala na kong problem after nito -- analysis na lang.\n",
    "\n",
    "\n",
    "June 17, 2023\n",
    "\n",
    "I just discovered how inflated the flux values are for high light conditions, which indicate that there is significant looping in some of my solutions, which I need to reassess considering how central they are to my model, particularly yung reactions involving Malate.\n",
    "\n",
    "I can try to add Loopless FVA then compare the results with the normal runs. Kahit paspasan lang.\n",
    "\n",
    "\n",
    "# #Notes: June 17\n",
    "# #Adding the \"Loopless FVA\" parameter to the pre-processing step does not work and generates an infeasible solution. It causes the solver to become stuck.\n",
    "\n",
    "# #Note: it takes 30 minutes to implement Loopless FVA to the model. Upon checking yung mga flux bounds it reduces the max and min values to something closer to their pFBA counterparts. \n",
    "# #I'll try to rerun my pipeline to accomodate that.\n",
    "# #Note: Loopless FVA produces NaNs in the flux bounds of some reactions. Need to remove that.\n",
    "\n",
    "\n",
    "June 19, 2023:\n",
    "\n",
    "I think I've finally optimized my Sampling runs. I just need to rerun my scripts kahit 25000 thinning lang since increasing it didn't really affect yung convergence rates.\n",
    "\n",
    "\n",
    "Things I have tested (So far)\n",
    "- Filtering out reactions before sampling -- Convergence rates lower almost 20 percent accorss the board.\n",
    "- 10000 Thinning\n",
    "- 25000 Thinning\n",
    "- 35000 Thinning -- little improvement in convergence rates, in fact it lessened percent converged \n",
    "- Using add_loopless() function -- doesn't work, turns the model to an MILP problem which breaks Sampling\n",
    "- Loopless FVA to define reaction bounds == works so far but it breaks during actual sampling (cannot generate warmup points due to overconstrained model).\n",
    "- Using _add_cyclefree_flux() -- doesn't work, breaks the model and causes numerical instability.\n",
    "- LOopless FVA with \"relaxed option\" for NaNs --- I think this method works. Wala na kong nakikitang loops. However this method runs really slow (~2 hours)\n",
    "\n",
    "June 20, 2023\n",
    "- I have problems regarding sampling right now. Sigh. I don't even know the issue behind it rn it just breaks\n",
    "- I know now -- apparently using the loopless option overconstrains the model and prevents it from generating warmup points using the sampler. I didn't see that it works. Maybe it'll work if I modify the parametrization to a fraction of the optima instead?\n",
    "- What I can do is probably to post-process my flux samples using the \"loopless_solution\" method highlighted in Desouki et al's paper.\n",
    "    - This method works. I checked the values for CSm_M and it does deflate the values significantly.\n",
    "    - It looks like it might work -- however it is fairly slow when run in series. I'll try to run them in parallel\n",
    "        - Multiprocess now works but it keeps doing i/o operations on the models. Can it be modified to just do a single I/O operation?\n",
    "            It becomes stuck if I try it\n",
    "            \n",
    "                It's such a hassle to use multiprocess. I'll just run it on a single thread tutal mabilis lang naman. I'm wasting time on how to run it on a multithread e kaya naman ng isang thread.\n",
    "\n",
    "\n",
    "June 22, 2023\n",
    "\n",
    "- CycleFreeFlux destroys the uniform distribution of my flux solutions, preventing me from inferring any information based dun sa distributions nung fluxes. Therefore this shoul \n",
    "Pipeline breakdown:\n",
    "\n",
    "\n",
    "June 24, 2023\n",
    "\n",
    "I've revised the script so that it properly bypasses infeasibility issues now. Apparently the previous iteration didn't exactly resolve it. However, I've already computed the samples for WT_250 so I can skip that now -- it didn't have too many feasibility issues so I could skip over that.,\n",
    "\n",
    "Load CSVs to a memory saving format first\n",
    "\n",
    "1.\n",
    "Run convergence statistics on each and generate plots to assess total convergence stats for each CSV. These will include tests such as the \n",
    "Raftery-Lewis statistic and the Geweke statistics to assess both autocorrelation as well as assess convergence.\n",
    "\n",
    "Afterwards get only the flux names of those reactions that have converged\n",
    "Run pairwise Kruskal-wallis tests per CSV using the above list of converged reactions\n",
    "Identify each reaction with significant and non-significant distributions each\n",
    "\n",
    "June 28, 2023\n",
    "\n",
    "Need to rerun WT_750 and WT1500 due to numerical isseus. I'm not sure why it wasn't caught by the script but I have modified it \n",
    "\n",
    "\n",
    "\n",
    "Generate histograms/probability densities for relevant reactions with significantly different distributions with WT and Trans models.\n",
    "2. Flux coupling analysis\n",
    "Check which fluxes are coupled with each otehr and identify which fluxes are then related to each other, particularly Carbon Fixation reactions in the BS cell such as Rubisco and the DM_Phloem reactions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b412192-58d7-4665-b013-58b6a313e2fa",
   "metadata": {},
   "source": [
    "June 23, 2023\n",
    "Model still returns infeasible solution for the trans parametrized models. What to do?\n",
    "\n",
    "Implemented a solution that would catch all exceptions in the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
