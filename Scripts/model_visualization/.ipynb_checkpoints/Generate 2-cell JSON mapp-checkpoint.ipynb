{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b772cbc-5bd2-4f47-ab20-c0c6d4499a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import escher\n",
    "import json\n",
    "import cobra\n",
    "import path\n",
    "import jupyter\n",
    "from escher import Builder\n",
    "\n",
    "# Change working directory to the desired absolute path\n",
    "os.chdir(\"/home/articulatus/git_repos/RiceMM/\")\n",
    "\n",
    "# Append the \"src\" directory to the system path\n",
    "sys.path.append(\"./src\")\n",
    "\n",
    "# Import the required module\n",
    "import model_manipulation as mm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f5fb07",
   "metadata": {},
   "source": [
    "Note: This notebook makes use of the Escher-FBA env which is different from the base Env of this repo (RiceMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df9af91-08db-4d96-a2b4-2d46434af475",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10008, 1173)\n",
      "(10008, 1116)\n",
      "(10008, 752)\n",
      "(10008, 1177)\n",
      "(10008, 1206)\n",
      "(10008, 1185)\n"
     ]
    }
   ],
   "source": [
    "#First generate jsons out of \n",
    "\n",
    "#Load dataset\n",
    "wt_250 = mm.load_csv_and_cleanup('./flux_results/flux_sampling/8th_attempt_fixed_transporter_issues/10k_samples/WT_250.csv' ,tol=1e-7)\n",
    "wt_750 = mm.load_csv_and_cleanup('./flux_results/flux_sampling/8th_attempt_fixed_transporter_issues/10k_samples/WT_750.csv' ,tol=1e-7)\n",
    "wt_1500 = mm.load_csv_and_cleanup('./flux_results/flux_sampling/8th_attempt_fixed_transporter_issues/10k_samples/WT_1500.csv',tol=1e-7)\n",
    "tr_250 = mm.load_csv_and_cleanup('./flux_results/flux_sampling/8th_attempt_fixed_transporter_issues/10k_samples/TR_250.csv',tol=1e-7)\n",
    "tr_750 = mm.load_csv_and_cleanup('./flux_results/flux_sampling/8th_attempt_fixed_transporter_issues/10k_samples/TR_750.csv', tol=1e-7)\n",
    "tr_1500 = mm.load_csv_and_cleanup('./flux_results/flux_sampling/8th_attempt_fixed_transporter_issues/10k_samples/TR_1500.csv',tol=1e-7)\n",
    "\n",
    "df_list = [wt_250, wt_750, wt_1500, tr_250, tr_750, tr_1500]\n",
    "names = ['wt_250', 'wt_750', 'wt_1500', 'tr_250', 'tr_750', 'tr_1500']\n",
    "wt_list = [wt_250, wt_750, wt_1500]\n",
    "tr_list = [tr_250, tr_750, tr_1500]\n",
    "_250_list = [wt_250,tr_250]\n",
    "_750_list = [wt_750,tr_750]\n",
    "_1500_list=[wt_1500,tr_1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3636d978-d787-4c2b-bd4a-2d7eb4fc75ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json file saved to ./JSON_maps/reaction_data/wt_250.json\n",
      "json file saved to ./JSON_maps/reaction_data/wt_750.json\n",
      "json file saved to ./JSON_maps/reaction_data/wt_1500.json\n",
      "json file saved to ./JSON_maps/reaction_data/tr_250.json\n",
      "json file saved to ./JSON_maps/reaction_data/tr_750.json\n",
      "json file saved to ./JSON_maps/reaction_data/tr_1500.json\n",
      "json file saved to ./JSON_maps/reaction_data/wt_tr_250.json\n",
      "json file saved to ./JSON_maps/reaction_data/wt_tr_750.json\n",
      "json file saved to ./JSON_maps/reaction_data/wt_tr_1500.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# def calculate_common_column_means(dataframes):\n",
    "#     #This function is for generating a list of dictionaries corresponding to each dataframe listed\n",
    "#     if len(dataframes) == 1:\n",
    "#         all_means_dict = {}\n",
    "#         for df in dataframes:\n",
    "#             for col in df.columns:\n",
    "#                 if col not in all_means_dict:\n",
    "#                     all_means_dict[col] = []\n",
    "#                 all_means_dict[col].append(df[col].mean())\n",
    "#         return all_means_dict\n",
    "\n",
    "#     else: #For multiple comparisons\n",
    "#         # Find common columns among all dataframes\n",
    "#         common_columns = set(dataframes[0].columns)\n",
    "#         for df in dataframes[1:]:\n",
    "#             common_columns &= set(df.columns)\n",
    "\n",
    "#         # Calculate means for each common column\n",
    "#         means_list = []\n",
    "#         for df in dataframes:\n",
    "#             means_dict = {}\n",
    "#             for col in common_columns:\n",
    "#                 column_mean = df[col].mean()\n",
    "#                 means_dict[col] = column_mean\n",
    "#             means_list.append(means_dict)\n",
    "\n",
    "#         return means_list\n",
    "\n",
    "def calculate_common_column_means(dataframes):\n",
    "    # This function is for generating a list of dictionaries corresponding to each dataframe listed\n",
    "    if len(dataframes) == 1:\n",
    "        all_means_dict = {}\n",
    "        for df in dataframes:\n",
    "            for col in df.columns:\n",
    "                if col not in all_means_dict:\n",
    "                    all_means_dict[col] = []\n",
    "                mean_value = df[col].mean()\n",
    "                mean_value_sci = format(mean_value, \".4e\")  # Convert to scientific notation with 4 significant figures\n",
    "                all_means_dict[col].append(mean_value_sci)\n",
    "        return all_means_dict\n",
    "    else:  # For multiple comparisons\n",
    "        # Find common columns among all dataframes\n",
    "        common_columns = set(dataframes[0].columns)\n",
    "        for df in dataframes[1:]:\n",
    "            common_columns &= set(df.columns)\n",
    "\n",
    "        # Calculate means for each common column\n",
    "        means_list = []\n",
    "        for df in dataframes:\n",
    "            means_dict = {}\n",
    "            for col in common_columns:\n",
    "                column_mean = df[col].mean()\n",
    "                column_mean_sci = format(column_mean, \".4e\")  # Convert to scientific notation with 4 significant figures\n",
    "                means_dict[col] = column_mean_sci\n",
    "            means_list.append(means_dict)\n",
    "\n",
    "        return means_list\n",
    "\n",
    "\n",
    "#Afterwards convert the objects to jsons then save to a json file\n",
    "#First the individual dataframes\n",
    "def generate_jsons_from_flux_means(dataframe_list, filename, directory):\n",
    "    #Generate directory if it does not exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    filepath = f'{directory}{filename}.json'\n",
    "    \n",
    "    #Calculate mean_dfs using the script above (automatically handles multiple comparisons)\n",
    "    mean_dfs = calculate_common_column_means(dataframe_list)\n",
    "          \n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(mean_dfs, f)\n",
    "\n",
    "    print(f'json file saved to {filepath}')\n",
    "\n",
    "    \n",
    "def load_json_as_dict(json_file_path):\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        loaded_dict = json.load(json_file)\n",
    "    return loaded_dict\n",
    "\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    #Generate jsons for each singular dataframe\n",
    "    directory = './JSON_maps/reaction_data/'\n",
    "    for i in range(len(df_list)):\n",
    "        df = [df_list[i]] #convert it to a 2 dim list so it is read by the function\n",
    "        name = names[i]\n",
    "        generate_jsons_from_flux_means(df, name, directory)\n",
    "        \n",
    "    \n",
    "    #Generate jsons for each flux comparison\n",
    "    generate_jsons_from_flux_means(_250_list, 'wt_tr_250',directory)\n",
    "    generate_jsons_from_flux_means(_750_list, 'wt_tr_750',directory)\n",
    "    \n",
    "    generate_jsons_from_flux_means(_1500_list, 'wt_tr_1500',directory)\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e9e61c6-1588-4441-a704-b7e4bf533fae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Now let's try loading the data to escher-FBA\n",
    "\n",
    "#Load JSON map\n",
    "#Load model file\n",
    "json_map = './JSON_maps/Rebuilt-M-BS map w malate shuttle.json'\n",
    "trans_model = cobra.io.load_json_model('./model/ios2164_2cell_w-trans.json')\n",
    "wt_tr_250 = load_json_as_dict('./JSON_maps/reaction_data/wt_tr_250.json')\n",
    "# wt_tr_750 = load_json_as_dict('./JSON_maps/reaction_data/wt_tr_750.json')\n",
    "# wt_tr_1500 = load_json_as_dict('./JSON_maps/reaction_data/wt_tr_1500.json')\n",
    "\n",
    "\n",
    "test =escher.Builder(map_json=json_map, model=trans_model, reaction_data= wt_tr_250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "defeaef0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "Jupyter.keyboard_manager.disable()\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "Jupyter.keyboard_manager.disable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3658a354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf42aad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ad67bfb59e4a52be8ac0873b97ea46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Builder(allow_building_duplicate_reactions=False, and_method_in_gene_reaction_rule='mean', cofactors=['atp', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1caef17",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
