{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a656bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T11:08:41.205406Z",
     "start_time": "2023-03-23T11:08:39.074105Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "import cobra\n",
    "import cplex \n",
    "import libsbml\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xlsxwriter\n",
    "import path \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from itertools import combinations\n",
    "from scipy.stats import kruskal, mannwhitneyu\n",
    "import multiprocessing\n",
    "from itertools import combinations, product\n",
    "from multiprocessing import Pool\n",
    "from sklearn.decomposition import PCA\n",
    "import mplcursors\n",
    "\n",
    "\n",
    "from sklearn.linear_model  import LinearRegression\n",
    "\n",
    "#Change working dir first, ty ChatGPT, much loves\n",
    "cwd = os.getcwd()\n",
    "# Split the path into a list of directories\n",
    "directories = cwd.split(os.sep)\n",
    "# Remove the last two directories from the list\n",
    "directories = directories[:-2]\n",
    "# Join the directories back into a path\n",
    "new_cwd = os.sep.join(directories)\n",
    "# Change the current working directory to the new path\n",
    "os.chdir(new_cwd)\n",
    "\n",
    "sys.path.append(\"./src/\")\n",
    "\n",
    "import model_initialize as mi\n",
    "import model_manipulation as mm\n",
    "\n",
    "\n",
    "#Set solver to gurobi\n",
    "config = cobra.Configuration()\n",
    "config.solver = 'glpk'\n",
    "\n",
    "#Read 2-cell model\n",
    "wt_model = cobra.io.read_sbml_model(\"./model/ios2164_2cell.xml\")\n",
    "trans_model = cobra.io.read_sbml_model(\"./model/ios2164_2cell.xml\")\n",
    "#Estimate inf\n",
    "inf = 1e6\n",
    "\n",
    "\n",
    "#Add trans reactions to trans_model\n",
    "mi.add_trans_reactions(trans_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4b7ca3-4c3d-4250-98f8-d84c422a5a39",
   "metadata": {},
   "source": [
    "Pipeline breakdown:\n",
    "\n",
    "Load CSVs to a memory saving format first\n",
    "\n",
    "1.\n",
    "Run convergence statistics on each and generate plots to assess total convergence stats for each CSV. These will include tests such as the Geweke statistic. \n",
    "Afterwards get only the flux names of those reactions that have converged\n",
    "Run pairwise Kruskal-wallis tests per CSV using the above list of converged reactions\n",
    "Identify each reaction with significant and non-significant distributions each\n",
    "\n",
    "Generate histograms/probability densities for relevant reactions with significantly different distributions with WT and Trans models\n",
    "\n",
    "2. Flux coupling analysis\n",
    "Check which fluxes are coupled with each otehr and identify which fluxes are then related to each other, particularly Carbon Fixation reactions in the BS cell such as Rubisco and the DM_Phloem reactions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "505994c4-1e2d-442d-b90e-e269414aecd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2502, 1172)\n",
      "(2502, 1118)\n",
      "(2502, 752)\n",
      "(2502, 1177)\n",
      "(2502, 1203)\n",
      "(2502, 1185)\n"
     ]
    }
   ],
   "source": [
    "#Test the script on one CSV\n",
    "\n",
    "wt_250 = load_csv_and_cleanup('./flux_results/flux_sampling/8th attempt - fixed_transporter_issues/2k_samples/WT_250.csv' ,tol=1e-7)\n",
    "wt_750 = load_csv_and_cleanup('./flux_results/flux_sampling/8th attempt - fixed_transporter_issues/2k_samples/WT_750.csv' ,tol=1e-7)\n",
    "wt_1500 = load_csv_and_cleanup('./flux_results/flux_sampling/8th attempt - fixed_transporter_issues/2k_samples/WT_1500.csv',tol=1e-7)\n",
    "tr_250 = load_csv_and_cleanup('./flux_results/flux_sampling/8th attempt - fixed_transporter_issues/2k_samples/TR_250.csv',tol=1e-7)\n",
    "tr_750 = load_csv_and_cleanup('./flux_results/flux_sampling/8th attempt - fixed_transporter_issues/2k_samples/TR_750.csv', tol=1e-7)\n",
    "tr_1500 = load_csv_and_cleanup('./flux_results/flux_sampling/8th attempt - fixed_transporter_issues/2k_samples/TR_1500.csv',tol=1e-7)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "df_list = [wt_250, wt_750, wt_1500, tr_250, tr_750, tr_1500]\n",
    "names = ['wt_250', 'wt_750', 'wt_1500', 'tr_250', 'tr_750', 'tr_1500']\n",
    "wt_list = [wt_250, wt_750, wt_1500]\n",
    "tr_list = [tr_250, tr_750, tr_1500]\n",
    "_250_list = [wt_250,tr_250]\n",
    "_750_list = [wt_750,tr_750]\n",
    "_1500_list=[wt_1500,tr_1500]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b114d6a-5391-407a-a90b-fed340154990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm for computing cellular economies\n",
    "#Get large dataframe first\n",
    "\n",
    "#Get reaction means for each reaction column\n",
    "#Melt all dataframes first to long format \n",
    "\n",
    "#Get metabolites with atp/nadh and nadph in all compartments//\n",
    "#Get reactions involving said metabolite //\n",
    "\n",
    "#Get all fluxes from the dataframe corresponding to the dataframe with their respective names, scaled with their respective flux coefficients//\n",
    "#Annotate this dataframe using subsystems //\n",
    "#Summarize the dataframe then generate a barplot showing distribution of fluxes per subsystem //\n",
    "\n",
    "#Additional analysis:\n",
    "#Show relative consumption of ATP, NADP an NADPH per compartment\n",
    "#Show relative consumption and plot these in lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "id": "4258088a-f921-4bb9-b78d-1ba998e271ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These functions are for generating PCA plots and other corollary analyses\n",
    "\n",
    "\n",
    "def load_csv_and_cleanup(filename, tol=1e-7):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Remove columns with a mean below tolerance\n",
    "    mean_values = df.mean()\n",
    "    columns_to_remove = mean_values[abs(mean_values) < tol].index\n",
    "    df = df.drop(columns=columns_to_remove)\n",
    "\n",
    "    # Fix the indices\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(df.shape)\n",
    "\n",
    "    return df    \n",
    "\n",
    "\n",
    "\n",
    "def get_aggregate_reactions_mets(model=trans_model, mets_to_search=''):\n",
    "    '''\n",
    "    This function looks for reactions in the model that contain specific metabolites.\n",
    "    '''\n",
    "    if type(mets_to_search) != list:\n",
    "        print('mets not in list form')\n",
    "        return None\n",
    "    # This codeblock gets all the metabolites in all compartments\n",
    "    met_list = list()\n",
    "    for mets in model.metabolites:\n",
    "        for i in mets_to_search:\n",
    "            if i in mets.id:\n",
    "                if mets.id.startswith(i):\n",
    "                    met_list.append(mets)\n",
    "\n",
    "    # This codeblock gets all the reactions that have the metabolite in their reaction\n",
    "    rxn_list = list()\n",
    "    for mets in met_list:\n",
    "        for rxns in model.reactions:\n",
    "            if mets in rxns.metabolites:\n",
    "                rxn_list.append(rxns.id)\n",
    "                \n",
    "    # Output a dictionary with 'met_list' as keys and 'rxn_list' as values\n",
    "    met_rxn_dict = {met.id: [rxn for rxn in rxn_list if met in model.reactions.get_by_id(rxn).metabolites]\n",
    "                    for met in met_list}\n",
    "\n",
    "    return met_rxn_dict\n",
    "            \n",
    "\n",
    "\n",
    "def merge_and_average_dataframes(dataframes, names):\n",
    "    merged_df = pd.DataFrame()\n",
    "    \n",
    "    for i, df in enumerate(dataframes):\n",
    "        # Get the corresponding name from the names list\n",
    "        df_name = names[i]\n",
    "        \n",
    "        # Add a new column with the dataframe name\n",
    "        df['sample'] = df_name\n",
    "        \n",
    "        # Merge dataframes\n",
    "        if merged_df.empty:\n",
    "            merged_df = df\n",
    "        else:\n",
    "            merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "    \n",
    "    # Remove NAs\n",
    "    merged_df = merged_df.fillna(0)\n",
    "    \n",
    "    # Compute the means for each column\n",
    "    means = merged_df.groupby('sample').mean().reset_index()\n",
    "    \n",
    "    # Melt the dataframe to create a long format\n",
    "    melted_df = pd.melt(means, id_vars=['sample'], var_name='reaction_id', value_name='mean_fluxes')\n",
    "    \n",
    "    # Split 'sample' column into 'sample' and 'ppfd'\n",
    "    melted_df[['sample', 'ppfd']] = melted_df['sample'].str.split('_', expand=True)# I think I can remove this isntead\n",
    "    \n",
    "    \n",
    "    return melted_df\n",
    "    \n",
    "from itertools import chain\n",
    "\n",
    "def calculate_adjusted_fluxes(merged_df, rxn_dict, filter='', sign='',percent=False,sum_by_subsystem=False,model=trans_model, tol=1e-7):\n",
    "    # Flatten the list of reaction IDs in rxn_dict values\n",
    "    all_rxn_ids = list(chain.from_iterable(rxn_dict.values()))\n",
    "        \n",
    "        \n",
    "    # Sort 'ppfd' in increasing order\n",
    "    merged_df = merged_df.sort_values(by='sample', ascending=True)\n",
    "    \n",
    "    \n",
    "    # Calculate the adjusted fluxes for each reaction based on the coefficient \n",
    "    for met_id, rxn_list in rxn_dict.items():\n",
    "        # Get metabolite first from model\n",
    "        met = model.metabolites.get_by_id(met_id)\n",
    "        # Iterate over the reactions in the rxn_list\n",
    "        for rxn_id in rxn_list:\n",
    "            try:\n",
    "                coef = model.reactions.get_by_id(rxn_id).get_coefficient(met)\n",
    "                merged_df.loc[merged_df['reaction_id'] == rxn_id, 'mean_fluxes'] *= coef\n",
    "            except KeyError:\n",
    "                print(f'{rxn_id} not in dataframe')\n",
    "                continue\n",
    "\n",
    "    # Drop reactions not present in any rxn_list\n",
    "    merged_df = merged_df[merged_df['reaction_id'].isin(all_rxn_ids)]\n",
    "\n",
    "    # Drop reactions below or equal to 1e-7 and reset index\n",
    "    merged_df = merged_df[abs(merged_df['mean_fluxes']) > tol]\n",
    "    merged_df = merged_df.reset_index(drop=True)\n",
    "\n",
    "    # Add subsystems of reactions\n",
    "    subsystems = []\n",
    "    for rxn_id in merged_df['reaction_id']:\n",
    "        try:\n",
    "            subsystem = model.reactions.get_by_id(rxn_id).notes['SUBSYSTEM']\n",
    "            subsystems.append(subsystem)\n",
    "        except KeyError:\n",
    "            subsystems.append(None)\n",
    "    \n",
    "    merged_df['subsystem'] = subsystems\n",
    "\n",
    "    # Drop rows with 'Transport' subsystem\n",
    "    merged_df = merged_df[~merged_df['subsystem'].str.contains('Transport', na=False)]\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # return merged_df\n",
    "    \n",
    "    if filter != '':\n",
    "        #Filters dataset if you want specific compartments or subsystems only\n",
    "        merged_df = merged_df[merged_df['reaction_id'].str.contains(filter)]\n",
    "        \n",
    "    # merged_df=merged_df.set_index(['sample'])\n",
    "    \n",
    "    # merged_df.loc[abs(merged_df['mean_fluxes']) < 1, 'reaction_id'] = 'others'\n",
    "    \n",
    "    # merged_df = merged_df.groupby(['sample', 'reaction_id', 'subsystem'])['mean_fluxes'].sum().reset_index()\n",
    "    \n",
    "        #Filter plot based on whether you're looking for positive (generation) or negative (consumption)\n",
    "    if sign=='+':\n",
    "        merged_df = merged_df[merged_df['mean_fluxes']>0]\n",
    "\n",
    "    elif sign =='-':\n",
    "        merged_df = merged_df[merged_df['mean_fluxes']<0]\n",
    "\n",
    "    \n",
    "\n",
    "    if sum_by_subsystem == True:\n",
    "        # Group by 'subsystem' and compute the sum of 'mean_fluxes' for each subsystem\n",
    "        summary_df = merged_df.groupby(['sample', 'ppfd','subsystem'])['mean_fluxes'].sum().reset_index()\n",
    "\n",
    "        # # # Aggregate reactions with less than 0.1 mean_fluxes values to 'others'\n",
    "        merged_df.loc[abs(merged_df['mean_fluxes']) < 0.1, 'subsystem'] = 'others'\n",
    "        summary_df = merged_df.groupby(['sample', 'ppfd','subsystem'])['mean_fluxes'].sum().reset_index()\n",
    "\n",
    "                # Convert the column to numeric and sort in ascending order\n",
    "        summary_df['ppfd'] = pd.to_numeric(summary_df['ppfd'])\n",
    "        summary_df = summary_df.sort_values(by='ppfd', ascending=True)\n",
    "        \n",
    "        return summary_df\n",
    "\n",
    "    \n",
    "    else:    \n",
    "        return merged_df\n",
    "\n",
    "    \n",
    "def generate_economy_plot(processed_df, if_relabunds=False,title='',group_var='sample', ingroup='ppfd', yvar='mean_fluxes',cmap='subsystem',directory='./plots/budget_plots/'):    \n",
    "    #Title names\n",
    "    titles=['WT model', 'TR model']\n",
    "    \n",
    "    # Get all unique subsystems\n",
    "    \n",
    "    \n",
    "    # Assuming `processed_df` is your DataFrame and `cmap` is the column name\n",
    "    unique_subsys = processed_df[cmap].unique()\n",
    "\n",
    "    # Generate a colormap with the same length as unique_subsys\n",
    "    colors = plt.cm.tab20.colors[:len(unique_subsys)]\n",
    "\n",
    "    # colors = sns.palplot(sns.color_palette('tab20',len(unique_subsys)))\n",
    "    # Construct the colormap dictionary\n",
    "    colormap = dict(zip(unique_subsys, colors))\n",
    "    \n",
    "\n",
    "    fig,axes=plt.subplots(ncols=2, nrows=1, figsize=(10,10), sharey=True)\n",
    "    plt.subplots_adjust(hspace=0)  # Remove vertical spacing between subplots\n",
    "\n",
    "    for i, g in enumerate(processed_df.groupby(group_var)):\n",
    "        \n",
    "        ax=axes[i]\n",
    "        \n",
    "        \n",
    "        g= sns.barplot(data=g[1],\n",
    "                         x=ingroup,\n",
    "                         y='mean_fluxes',\n",
    "                         hue=cmap,\n",
    "                         palette=colormap, # so first bars stay on top,\n",
    "                        dodge=False, ax=ax)\n",
    "        ax.set_xlabel('')\n",
    "        \n",
    "        if i==0:\n",
    "            ax.set_ylabel('Reaction fluxes (umol m2/s)')\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "        ax.set_title(titles[i])\n",
    "        ax.axhline(y=0, linewidth=2, linestyle='--', color='black')\n",
    "        ax.legend('')\n",
    "        ax.margins(x=0)  # Reduce the space between bars within each plot\n",
    "\n",
    "    \n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    plt.suptitle(f'{title} Budget plot', fontsize=16, y=1.00)\n",
    "\n",
    "    # Create a common legend for all subplots at the bottom of the figure\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=2, bbox_to_anchor=(0.5, -0.2), bbox_transform=fig.transFigure)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #Save model to dir\n",
    "\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    filename=f'{title}.png'\n",
    "        \n",
    "    plot_path = os.path.join(directory, filename)\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "id": "68dc5a7f-3a23-428a-b529-12a9c4cea9ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1082], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m         adj_df \u001b[38;5;241m=\u001b[39m calculate_adjusted_fluxes(df_all, rxn_list, sum_by_subsystem\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m         generate_economy_plot(adj_df, title\u001b[38;5;241m=\u001b[39mval)\n\u001b[0;32m---> 40\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_args\u001b[49m\u001b[43m)\u001b[49m                                 \n",
      "Cell \u001b[0;32mIn[1082], line 38\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(df_list, met_dict, model, names, stratified)\u001b[0m\n\u001b[1;32m     36\u001b[0m rxn_list\u001b[38;5;241m=\u001b[39mget_aggregate_reactions_mets(model, [key])\n\u001b[1;32m     37\u001b[0m adj_df \u001b[38;5;241m=\u001b[39m calculate_adjusted_fluxes(df_all, rxn_list, sum_by_subsystem\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 38\u001b[0m \u001b[43mgenerate_economy_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1081], line 184\u001b[0m, in \u001b[0;36mgenerate_economy_plot\u001b[0;34m(processed_df, if_relabunds, title, group_var, ingroup, yvar, cmap, directory)\u001b[0m\n\u001b[1;32m    182\u001b[0m colors \u001b[38;5;241m=\u001b[39m sns\u001b[38;5;241m.\u001b[39mpalplot(sns\u001b[38;5;241m.\u001b[39mcolor_palette(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtab20\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mlen\u001b[39m(unique_subsys)))\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# Construct the colormap dictionary\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m colormap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munique_subsys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolors\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    187\u001b[0m fig,axes\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39msubplots(ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m), sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    188\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplots_adjust(hspace\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Remove vertical spacing between subplots\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test_df = merge_and_average_dataframes(df_list, names)\n",
    "\n",
    "\n",
    "# #Get lists of all reactions in the model\n",
    "# nadph_list = get_aggregate_reactions_mets(trans_model, ['nadph_'])\n",
    "# atp_list =get_aggregate_reactions_mets(trans_model, ['atp_'])\n",
    "# nad_list = get_aggregate_reactions_mets(trans_model, ['nadh_'])\n",
    "# mal_list = get_aggregate_reactions_mets(trans_model, ['mal-L_'])\n",
    "\n",
    "# co2_list = get_aggregate_reactions_mets(trans_model, ['co2_'])\n",
    "\n",
    "# #\n",
    "# nadph = calculate_adjusted_fluxes(test_df, nadph_list, sum_by_subsystem=True, filter='',sign='')\n",
    "# atp = calculate_adjusted_fluxes(test_df, atp_list, sum_by_subsystem=True, filter='', sign='')\n",
    "# nad = calculate_adjusted_fluxes(test_df, nad_list, sum_by_subsystem=True, filter='', sign='')\n",
    "# mal= calculate_adjusted_fluxes(test_df, mal_list, sum_by_subsystem=True, filter='', sign='')\n",
    "\n",
    "# generate_economy_plot(nadph, title='NADPH budget plot',filename='NADPH')\n",
    "\n",
    "# generate_economy_plot(atp, title='ATP budget plot', filename='ATP')\n",
    "\n",
    "# generate_economy_plot(nad, title='NAD budget plot', filename='NADH')\n",
    "# generate_economy_plot(mal, title='Malate Budget plot', filename='Mal-L')\n",
    "\n",
    "\n",
    "met_list = ['nadph_','atp_','nadh_','mal-L_','co2_','o2_', 'dhap_', 'h2o_', 'nh4_']\n",
    "title_list = ['NADPH','ATP','NADH', 'L-malate', 'CO2', 'O2', 'DHAP', 'H2O', 'NH4']\n",
    "main_args = dict(zip(met_list, title_list))\n",
    "\n",
    "def main(df_list,met_dict, model=trans_model,names=names, stratified=''):\n",
    "    \n",
    "    #Generate main df\n",
    "    df_all = merge_and_average_dataframes(df_list, names)\n",
    "    \n",
    "    for key, val in met_dict.items():\n",
    "        rxn_list=get_aggregate_reactions_mets(model, [key])\n",
    "        adj_df = calculate_adjusted_fluxes(df_all, rxn_list, sum_by_subsystem=True)\n",
    "        generate_economy_plot(adj_df, title=val)\n",
    "\n",
    "main(df_list, main_args)                                 \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "id": "30d4f925-5a4b-4db8-9695-9fc58f73034e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Reaction identifier</strong></td><td>FRORc_M</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Name</strong></td><td>2-trans,6-trans-farnesol:NADP+ 1-oxidoreductase</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>0x7f88dd367460</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Stoichiometry</strong></td>\n",
       "                <td>\n",
       "                    <p style='text-align:right'>frnsol_c0 + nadp_c0 --> frnsl_c0 + h_c0 + nadph_c0</p>\n",
       "                    <p style='text-align:right'>(2Z,6E)-Farnesol + Nicotinamide adenine dinucleotide phosphate --> Farnesal + H+ + Nicotinamide adenine dinucleotide phosphate - reduced</p>\n",
       "                </td>\n",
       "            </tr><tr>\n",
       "                <td><strong>GPR</strong></td><td>LOC_Os03g08624</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Lower bound</strong></td><td>0.0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Upper bound</strong></td><td>1000000.0</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<Reaction FRORc_M at 0x7f88dd367460>"
      ]
     },
     "execution_count": 1090,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_model.reactions.FRORc_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "id": "30330000-0f08-4e8f-a47d-bbaf0a175953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Reaction identifier</strong></td><td>FRNCTIc_M</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Name</strong></td><td>(2E,6E)-farnesol 2-cis-trans-isomerase</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>0x7f88dd367250</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Stoichiometry</strong></td>\n",
       "                <td>\n",
       "                    <p style='text-align:right'>frnsl_c0 <=> frnsol_c0</p>\n",
       "                    <p style='text-align:right'>Farnesal <=> (2Z,6E)-Farnesol</p>\n",
       "                </td>\n",
       "            </tr><tr>\n",
       "                <td><strong>GPR</strong></td><td></td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Lower bound</strong></td><td>-1000000.0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Upper bound</strong></td><td>1000000.0</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<Reaction FRNCTIc_M at 0x7f88dd367250>"
      ]
     },
     "execution_count": 1089,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_model.reactions.FRNCTIc_M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33300af5-bc08-456d-a695-1643ca5a7ad5",
   "metadata": {},
   "source": [
    "Notes;\n",
    "Analysis shows most of the ATP consumption is correctly indicated (i.e. dedicated towards Calvin Cycle) as well as ATP production w/c is from Photosynthesis. Minor fluxes comes from Mitochondrial metabolism and glycolysis.\n",
    "\n",
    "I might be able to get more concordant results if I rescale the fluxes at the dataframe level rather than at the means level."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
